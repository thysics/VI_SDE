{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from functorch import vmap\n",
    "import numpy as np\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d7a52",
   "metadata": {},
   "source": [
    "**Class: OU processes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OU_vector:\n",
    "    def __init__(self, t0, t1, z0, alpha, beta, sigma, dN, D, timegrid='True'):\n",
    "        self.t0 = t0\n",
    "        self.t1 = t1\n",
    "        self.z0 = z0\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \"\"\"\n",
    "            check whether every element in sigma is positive\n",
    "        \"\"\"\n",
    "        assert all(beta > 0), \"beta should be positive\"    \n",
    "        self.beta = beta\n",
    "        assert all(sigma > 0), \"variance should be positive\"\n",
    "        self.sigma = sigma\n",
    "        self.D = D\n",
    "        if timegrid == 'True':\n",
    "            self.pts = torch.linspace(t0, t1, dN).repeat(D, 1)\n",
    "        else:\n",
    "            self.pts = torch.sort(torch.cat([(t1 - t0) * torch.rand(D, dN-2) + t0, torch.tensor([self.t0, self.t1]).repeat(D,1)], axis=1), axis=1)[0]\n",
    "        self.trj, self.dt = self.simulate()\n",
    "        \n",
    "    def simulate(self):\n",
    "        \"\"\"\n",
    "            Simulate an OU process on a set of discrete points\n",
    "                Make sure to match the dimension of each object;\n",
    "                    note that memoryview of torch/python object flattens\n",
    "        \"\"\"\n",
    "        output = torch.empty(self.pts.shape)\n",
    "        output[:, 0] = self.z0.flatten()\n",
    "        interval = self.pts[:, 1:] - self.pts[:, :-1]\n",
    "        for t in range(1, self.pts.shape[1]):\n",
    "            dt = interval[:, t-1].reshape(-1, 1)\n",
    "            mean = self.alpha + (output[:, t-1].reshape(-1,1) - self.alpha) * np.exp(-1 * self.beta * dt)\n",
    "            var = np.sqrt((self.sigma ** 2) * (1 - np.exp(-2 * self.beta * dt)) / (2 * self.beta))\n",
    "            if self.D > 1:\n",
    "                output[:, t] = torch.from_numpy(ss.multivariate_normal.rvs(mean = mean.flatten(), cov = torch.diag(var.flatten())))\n",
    "            else:\n",
    "                assert var > 0, \"variance is negative, sd:%.3f interval: %.3f\" % (var, interval[t-1] )\n",
    "                output[:, t] = ss.norm.rvs(loc = mean, scale = np.sqrt(var))\n",
    "        return output, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8138ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score:\n",
    "    def __init__(self, ou):\n",
    "        self.ou = ou\n",
    "        \n",
    "    def compute_score(self, alpha, beta):\n",
    "        \"\"\"\n",
    "            Compute the value of the score function at given parameters\n",
    "            return a dictionary matching each parameter to its gradient\n",
    "        \"\"\"\n",
    "        # Hyperparameter\n",
    "        sigma = self.ou.sigma\n",
    "        \n",
    "        # Parameters\n",
    "        assert all(beta > 0), \"beta should be positive\"\n",
    "        alpha = Variable(alpha, requires_grad = True)\n",
    "        beta = Variable(beta, requires_grad = True)\n",
    "        \n",
    "        dt = self.ou.dt\n",
    "        X = self.ou.trj\n",
    "        \n",
    "        def compute_transition(X, dt, alpha, beta, sigma):\n",
    "            \"\"\"\n",
    "            Compute the likelihood based on the transition density of the (simulated) path\n",
    "            \"\"\"\n",
    "#             print(\"sigma = \", sigma.shape, \"beta = \", beta.shape, \"dt = \", dt.shape)\n",
    "#             print(\"log sigma = \", torch.log(sigma), \"log beta = \", torch.log(beta), \"rest = \", torch.log(1 - torch.exp(-2 * beta * dt)) )\n",
    "            term1 = -0.5 * (2 * torch.log(sigma) - torch.log(beta) + torch.log(1 - torch.exp(-2 * beta * dt)))\n",
    "            term2 = beta * (X[:, 1:] - alpha - (X[:, :-1] - alpha) * torch.exp(-1 * beta * dt)) ** 2 \n",
    "            term3 = (sigma ** 2) * (1 - torch.exp(-2 * beta * dt))\n",
    "#             print(\"term1 = \", term1, \"term2 = \", term2, \"term3 = \", term3)\n",
    "            return torch.sum(term1 - term2/term3, axis=1)\n",
    "        \n",
    "        LL = compute_transition(X, dt, alpha, beta, sigma)\n",
    "#         print(LL.data.numpy())\n",
    "#         print(\"D = \", self.ou.D)\n",
    "        LL.backward(torch.tensor([1.]).repeat(self.ou.D))\n",
    "         \n",
    "        return {\"alpha\": alpha.grad.detach().clone(), 'beta':beta.grad.detach().clone(), \"LL\": LL.data.numpy()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
