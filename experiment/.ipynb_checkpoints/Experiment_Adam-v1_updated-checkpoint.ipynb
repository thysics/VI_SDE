{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591c0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "from functorch import vmap\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043b84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../vp_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de3b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_tou_v4_updated import tOU, tou_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b69b9",
   "metadata": {},
   "source": [
    "This code applies variational inference based on time-dependent OU processes to the observations drawn from the double well system SDE, as defined below. Note that we have chosen observational noise, i.e. variance of Gaussian noise and SDE variance to be 0.64 and 0.01 repectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22728a",
   "metadata": {},
   "source": [
    "m(t) = $\\alpha$t + $m_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6d11b",
   "metadata": {},
   "source": [
    "1. Simulate prior process, i.e. double-well system whose SDE is given by\n",
    "\n",
    "$dX_{t} = 4X_{t}(1-X^{2}_{t})dt + \\sigma dW_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1791ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../EX03_DW_Model', 'rb') as f:\n",
    "    prior = pickle.load(f)\n",
    "    likelihood = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8faa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_drift (s, x_s):\n",
    "    return 4 * x_s * (1 - (x_s ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bd214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sde_pts, true_sde_trj = prior[0], prior[1]\n",
    "obs, obs_time = likelihood[0], likelihood[1]\n",
    "sde_sigma = 0.8 # Variance is higher than the original example\n",
    "obs_sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ca55c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot paths\n",
    "plt.plot(true_sde_pts,true_sde_trj)\n",
    "plt.plot(obs_time, obs, \"rx\")\n",
    "plt.xlabel(\"t\", fontsize=14)\n",
    "plt.ylabel(\"X\", fontsize=14)\n",
    "plt.title(\"Sample paths\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f40f9",
   "metadata": {},
   "source": [
    "Variational inference: KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff800a",
   "metadata": {},
   "source": [
    "2. Implement Variational inference based on $\\textbf{time-inhomogeneous}$ OU process with SDE:\n",
    "\n",
    "$$dX_{t} = [-\\frac{a}{at+b}X_{t} + (ct+d)] dt + \\sigma^{2} dW_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6d84b",
   "metadata": {},
   "source": [
    "$$\\mathbb{E}_{P^{Z}}[\\log\\exp{\\frac{dP^{X}}{dP^{Z}}(Z)] = \\frac{1}{2}\\mathbb{E}_{P^{Z}}[\\int_{t_{0}}}^{t_{1}}|\\frac{4Z_{t}(1-Z^{2}_{t}) + \\frac{a}{at+b}Z_{t} - (ct+d)}{\\sigma}|^{2}dt]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063c5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBO:\n",
    "    \"\"\"\n",
    "        ELBO with\n",
    "            variational process (q): time-inhomogeneous OU process\n",
    "            prior process (p): double-well system\n",
    "            \n",
    "        This class computes: - KL(q|p) + NLL(y|z)  where z \\sim q\n",
    "    \"\"\"\n",
    "    def __init__(self, ou):\n",
    "        self.ou = ou\n",
    "        \n",
    "        self.alpha = ou.alpha\n",
    "        self.beta = ou.beta\n",
    "        self.r = ou.r\n",
    "        \n",
    "        self.sigma = ou.sigma\n",
    "        \n",
    "\n",
    "    def KL(self, prior_drift):\n",
    "        \"\"\"\n",
    "            This function requires the function corresponding to prior drift function\n",
    "        \"\"\"\n",
    "        # Save parameter specification from ou class\n",
    "        alpha, beta, r, sigma = self.alpha, self.beta, self.r, self.sigma\n",
    "        m0 = self.ou.trj[:, 0].reshape(-1, 1)\n",
    "        \n",
    "        def B(s, beta):\n",
    "            return (s+1) ** beta\n",
    "        \n",
    "        def m(s):\n",
    "            return alpha * (B(s, beta) - 1) + m0\n",
    "            \n",
    "        def m_(s):\n",
    "            return alpha * beta * B(s, beta-1)\n",
    "        \n",
    "        t = self.ou.pts - self.ou.pts[:, 0].reshape(-1, 1)\n",
    "        \n",
    "        # Evaluate the drift function of the approximating processes\n",
    "        g_of_x = -r * (self.ou.trj - m(t)) + m_(t)\n",
    "        \n",
    "        # Evaluate the drift function of the model (prior process)\n",
    "        f_of_x = prior_drift(t, self.ou.trj)\n",
    "        \n",
    "        # Compute the term inside the KL divergence\n",
    "        \n",
    "        F_of_X = abs(((f_of_x - g_of_x) / sigma) ** 2)\n",
    "        \n",
    "        dt = t[:, -1] - t[:, 0]\n",
    "        \n",
    "        return 0.5 * torch.sum(F_of_X, axis=1).reshape(-1, 1) / F_of_X.shape[1] * dt.reshape(-1, 1)\n",
    "            \n",
    "    def log_prob(self, obs, obs_sigma):\n",
    "        \"\"\"\n",
    "            Compute the log-likelihood\n",
    "            likelihood function is normal density N(obs, var)\n",
    "            obs.shape = D * 1 (D: # of sample)\n",
    "        \"\"\"\n",
    "        def log_pdf(obs, z, obs_sigma):\n",
    "            return ss.norm.logpdf(obs, loc=z, scale=obs_sigma)\n",
    "            \n",
    "        return torch.from_numpy(log_pdf(obs, self.ou.trj[:, -1].reshape(-1, 1), obs_sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0859993",
   "metadata": {},
   "source": [
    "**Variational inference: a piece-wise approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d17552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7deb3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_estimate(s0, sK, current_pars, sigma, obs, obs_sigma, init_dist, M):\n",
    "    \"\"\"\n",
    "        Returns stochastic estimates of the gradient of the ELBO with respect to parameters including\n",
    "            alpha, r, beta\n",
    "        \n",
    "        M: # of Monte Carlo samples\n",
    "        \n",
    "    \"\"\"\n",
    "    assert obs.shape[0] == 1, \"observation must be 1-d torch.array\"\n",
    "    \n",
    "    # Number of time points drawn between s0 and sK\n",
    "    K = 200\n",
    "    \n",
    "    # Reshape every parameter into (M,1) torch.array\n",
    "    SIGMA = sigma.repeat(M, 1)\n",
    "    OBS = obs.repeat(M, 1)\n",
    "    # Simulate sample path\n",
    "    # Note that z0 = m0\n",
    "    \n",
    "    pars = {key:val.repeat(M, 1) for key,val in current_pars.items()}\n",
    "    \n",
    "    vi = tOU(t0=s0, t1=sK, parameters = pars, sde_sigma=SIGMA, init_dist = init_dist, timegrid = 'False', dN=K)\n",
    "\n",
    "    # Compute the ELBO \n",
    "    elbo = ELBO(vi)\n",
    "    score_func = tou_gradient(vi.pts, vi.trj, pars, SIGMA, init_dist)\n",
    "    f_of_x = -elbo.log_prob(OBS, obs_sigma) + elbo.KL(prior_drift)\n",
    "    \n",
    "    # Variational objective\n",
    "    vi_obj = {'NELBO': torch.nanmean(f_of_x).item(), 'KL': torch.nanmean(elbo.KL(prior_drift)).item(), 'NLL': -1 * torch.nanmean(elbo.log_prob(OBS, obs_sigma)).item() }\n",
    "    \n",
    "    return {key: torch.nanmean(f_of_x * score_func[key]) for key in pars.keys()}, vi_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63551dc",
   "metadata": {},
   "source": [
    "Sanity check\n",
    "\n",
    "Examine the distribution of score function estimates of the gradient of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395078f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Normal(loc=0, scale=1.)\n",
    "t0 = torch.tensor(1.)\n",
    "t1 = torch.tensor(2.)\n",
    "sigma = torch.tensor([1.]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27459ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha': torch.tensor([0.15]).reshape(-1, 1), \\\n",
    "             'beta': torch.tensor([0.8]).reshape(-1, 1), \\\n",
    "             'r': torch.tensor([3.05]).reshape(-1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624116dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pts = torch.tensor([1.0]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tou = tOU(t0, t1, parameters, sigma, init_dist=init_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = {key:[] for key in parameters.keys()}\n",
    "\n",
    "for i in range(500):\n",
    "    grads, elbo_estimate = score_estimate(t0, t1, parameters, sigma, obs[0], obs_sigma, init_pts, 2000)\n",
    "    for key in grads.keys():\n",
    "        estimates[key].append(grads[key].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "par_names = list(estimates.keys())\n",
    "\n",
    "for j, ax in enumerate(axs.ravel()):\n",
    "    if j < 3:\n",
    "        ax.hist(estimates[par_names[j]], bins=30)\n",
    "        ax.axvline(np.mean(estimates[par_names[j]]), linestyle='dashed', color='black')\n",
    "        ax.set_title(par_names[j])\n",
    "        ax.set_xlabel(\"Gradient estimate\")\n",
    "        ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47bedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee86c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamStep(g_t, m_t, v_t, beta_1, beta_2, t):\n",
    "    \"\"\"\n",
    "        compute bias corrected moments\n",
    "    \"\"\"\n",
    "#     print(g_t, m_t, v_t, beta_1, beta_2, t)\n",
    "    m_t_next = beta_1 * m_t + (1 - beta_1) * g_t\n",
    "    v_t_next = beta_2 * v_t + (1 - beta_2) * g_t ** 2\n",
    "    \n",
    "    m_t_corrected = m_t_next / (1 - (beta_1 ** t))\n",
    "    v_t_corrected = v_t_next / (1 - (beta_2 ** t))\n",
    "    \n",
    "#     print(m_t_corrected, v_t_corrected)\n",
    "    return m_t_corrected, v_t_corrected\n",
    "\n",
    "def AdamGrad(current_pars, current_grad, prev_moments,  beta_1, beta_2, learning_rate = 0.01, smooth_term = 1e-8):\n",
    "    assert type(current_pars) == type(current_grad) == type(prev_moments) == dict, \"Current_grad must be a dict\"\n",
    "    \"\"\"\n",
    "        Perform one-step Adam gradient descent\n",
    "    \"\"\"\n",
    "    new_pars = {}\n",
    "    for key in current_pars.keys():\n",
    "        if key == 'r':\n",
    "            m_t, v_t = AdamStep(current_grad[key], prev_moments[key][0], prev_moments[key][1], beta_1, beta_2, prev_moments['t'])\n",
    "            new_pars[key] = current_pars[key] - learning_rate / np.sqrt(v_t + smooth_term) * m_t\n",
    "            value = new_pars[key]\n",
    "            while value <= 0:\n",
    "                value = current_pars[key] - learning_rate / np.sqrt(v_t + smooth_term) * m_t\n",
    "                learning_rate *= 0.5\n",
    "            new_pars[key] = value\n",
    "            \n",
    "        else:\n",
    "            m_t, v_t = AdamStep(current_grad[key], prev_moments[key][0], prev_moments[key][1], beta_1, beta_2, prev_moments['t'])\n",
    "            new_pars[key] = current_pars[key] - learning_rate / np.sqrt(v_t + smooth_term) * m_t\n",
    "        \n",
    "        # Save moments for next iteration    \n",
    "        prev_moments[key][0] = m_t\n",
    "        prev_moments[key][1] = v_t\n",
    "    \n",
    "    prev_moments['t'] += 1\n",
    "    \n",
    "    return new_pars\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d864af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_of_X ( init_pts, pts, parameters ):\n",
    "    \"\"\"\n",
    "        Return mean of the process (which has analytical expression)\n",
    "    \"\"\"\n",
    "\n",
    "    alpha = parameters['alpha']\n",
    "    beta = parameters['beta']\n",
    "    r = parameters['r']\n",
    "    \n",
    "    return alpha * ((pts + 1) ** beta - 1) + init_pts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac348db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def V_of_X (pts, parameters, prev_parameters, sde_sigma):\n",
    "    \"\"\"\n",
    "        Return standard deviation of the process (from its analytical expression)\n",
    "    \"\"\"\n",
    "    r = parameters['r']\n",
    "    \n",
    "    if prev_parameters == False:\n",
    "        # for the first time step, we compute the variance given the initial point is fixed\n",
    "        return torch.sqrt(0.5 * sde_sigma * sde_sigma / r * (1 - torch.exp(-2 * r * pts)))\n",
    "    \n",
    "    else:\n",
    "        # for subsequent time steps, we compute the variance given the initial state is a random variable from approximate posterior\n",
    "        prev_r = prev_parameters['r']\n",
    "\n",
    "        v_0 = 0.5 * sde_sigma * sde_sigma / prev_r\n",
    "\n",
    "        return torch.sqrt(0.5 * sde_sigma * sde_sigma / r * (1 - torch.exp(-2 * r * pts) * (2*r/(sde_sigma * sde_sigma) * v_0 - 1 )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615146f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PostMoment(t0, tT, parameters, prev_parameters, sde_sigma, init_pts, vN):\n",
    "    \"\"\"\n",
    "        Returns approximate posterior's mean and standard deviation\n",
    "    \"\"\"\n",
    "    # Get time-grid between s0 and sK\n",
    "    \n",
    "    t = torch.linspace(0, (tT-t0).item(), vN+2)[1:].reshape(-1, 1)\n",
    "    mean = E_of_X(init_pts, t, parameters)\n",
    "    std = V_of_X(t, parameters, prev_parameters, sde_sigma)\n",
    "\n",
    "    return t.flatten(), mean.flatten(), std.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeed2c1",
   "metadata": {},
   "source": [
    "**To be added: 1. parameter update history, 2. elbo, KL, and loglikelihood estimate, 3. randomizing initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5dc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimize(sde_sigma, obs, obs_time, obs_sigma, M, IT, vN, learning_rate,  init_state = \"Random\", Optimizer=\"Adam\", beta_1 = 0.9, beta_2 = 0.999, smooth_term = 1e-8, FIX_PAR=False):\n",
    "    \"\"\"\n",
    "        vN: # of time points between in each obs interval on which mean of the approximate posterior process will be evaluated\n",
    "    \"\"\"\n",
    "    assert type(sde_sigma) == torch.Tensor, \"SDE sigma must be a torch.Tensor\"\n",
    "    assert type(obs) == torch.Tensor, \"obs must be a torch.Tensor\"\n",
    "\n",
    "    N_of_Pars = 3\n",
    "    \n",
    "    T = obs.shape[0]\n",
    "    \n",
    "    v_N = T * (vN+1) - vN\n",
    "    \n",
    "    VP_PTS = np.zeros(v_N)\n",
    "    VP_MEAN = np.zeros(v_N)\n",
    "    VP_STD = np.zeros(v_N)\n",
    "    \n",
    "    # Intialize the state at the first observation\n",
    "    init_mean = obs[0]\n",
    "    VP_MEAN[0] = init_mean\n",
    "    \n",
    "    past_grad = {'alpha':np.zeros((T-1, IT)), 'beta':np.zeros((T-1, IT)), 'r':np.zeros((T-1, IT))}\n",
    "    past_pars = {'alpha':np.zeros((T-1, IT)), 'beta':np.zeros((T-1, IT)), 'r': np.zeros((T-1, IT))}\n",
    "    past_vi = {'NELBO':np.zeros((T-1, IT)), 'KL':np.zeros((T-1, IT)), 'NLL':np.zeros((T-1, IT))}\n",
    "    \n",
    "    for t in tq.tqdm(range(1, T)):\n",
    "        s0 = obs_time[t-1]\n",
    "        sK = obs_time[t]\n",
    "        \n",
    "        if init_state == 'Random':\n",
    "            if t == 1:\n",
    "                init_dist = init_mean\n",
    "            else:\n",
    "                init_dist = Normal(loc=init_mean, scale= init_std)\n",
    "        else:\n",
    "            init_dist = init_mean\n",
    "            \n",
    "        # Initialize a set of parameters\n",
    "        current_pars = {key:torch.randn(1) for key in past_grad.keys() if key != 'r'}\n",
    "        current_pars['r'] = torch.tensor(5.)\n",
    "\n",
    "        if Optimizer == \"Adam\":\n",
    "            prev_moments = {key:[0, 0] for key in current_pars.keys()}\n",
    "            prev_moments['t'] = 1\n",
    "            \n",
    "#    past_grad = {key:torch.tensor([0.01]) for key in current_pars.keys()}\n",
    "    \n",
    "        for i in range(IT):\n",
    "            if (i % (IT/2) == 0):\n",
    "                for key in current_pars.keys():\n",
    "                    print(str(i) +\"/ \" + key + \": \"+ str(current_pars[key].item()) )\n",
    "                    \n",
    "            # Take gradient descent algorithm based on AdaGrad\n",
    "            \n",
    "            # Obtain stochastic estimate of the gradients based on score function estimator\n",
    "            current_grad, vi_objective = score_estimate(s0, sK, current_pars, sde_sigma, obs[t], obs_sigma, init_dist, M)\n",
    "            \n",
    "            for key in vi_objective.keys():\n",
    "                past_vi[key][t-1, i] = vi_objective[key]\n",
    "            \n",
    "            print(str(i) +\"/ \" + \"Negative ELBO: \"+ str(vi_objective['NELBO']))\n",
    "            \n",
    "#             if vi_objective['ELBO'] < 20:\n",
    "#                 break\n",
    "            # Take one gradient step based on the AdaGrad\n",
    "            if Optimizer == \"Adam\":\n",
    "                current_pars = AdamGrad(current_pars, current_grad, prev_moments, beta_1, beta_2, learning_rate, smooth_term)\n",
    "                \n",
    "            else:\n",
    "                current_pars = Grad_Descent(current_pars, current_grad, learning_rate)\n",
    "            \n",
    "            if FIX_PAR != False:\n",
    "                for key in FIX_PAR.keys():\n",
    "                    current_pars[key] = FIX_PAR[key]\n",
    "            \n",
    "            for key in current_grad.keys():\n",
    "                past_grad[key][t-1, i] = current_grad[key].item()\n",
    "                past_pars[key][t-1, i] = current_pars[key].item()\n",
    "            \n",
    "        if t == 1:\n",
    "            prev_pars = False\n",
    "            \n",
    "        # Obtain moments of approximating processes (note that their forms are tractable)\n",
    "        vp_pts, vp_mean, vp_std = get_PostMoment(s0, sK, current_pars, prev_pars, sde_sigma, init_mean, vN)\n",
    "        VP_PTS[(vN+1)*(t-1)+1:(vN+1)*t+1] = obs_time[t-1] + vp_pts\n",
    "        VP_MEAN[(vN+1)*(t-1)+1:(vN+1)*t+1] = vp_mean\n",
    "        VP_STD[(vN+1)*(t-1)+1:(vN+1)*t+1] = vp_std\n",
    "        \n",
    "        init_mean = vp_mean[-1]\n",
    "        init_std = vp_std[-1]\n",
    "        \n",
    "        if t > 1:\n",
    "            prev_pars = current_pars\n",
    "        \n",
    "        print(\"observation: \" + str(obs[t].item()) + \" variational mean: \" + str(init_mean.item()))\n",
    "    return VP_PTS, VP_MEAN, VP_STD, past_pars, past_grad, past_vi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9de054",
   "metadata": {},
   "source": [
    "Examine the convergence of parameters / model fit across different initializations/number_of_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e135ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX_PAR = {'a':torch.tensor([1.])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f934414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                   | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                                                                                                   | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/ alpha: 1.1435823440551758\n",
      "0/ beta: -1.4297938346862793\n",
      "0/ r: 5.0\n",
      "0/ Negative ELBO: 14.237044829605024\n",
      "1/ Negative ELBO: 12.101061814313585\n",
      "2/ Negative ELBO: 10.166018449540436\n",
      "3/ Negative ELBO: 7.991965422642188\n",
      "4/ Negative ELBO: 6.396687217538405\n",
      "5/ Negative ELBO: 5.479493660145358\n",
      "6/ Negative ELBO: 4.301380479275816\n",
      "7/ Negative ELBO: 3.3722322395338935\n",
      "8/ Negative ELBO: 2.57897719722441\n",
      "9/ Negative ELBO: 2.5118422923604413\n",
      "10/ Negative ELBO: 2.1918087939917865\n",
      "11/ Negative ELBO: 2.385277916657199\n",
      "12/ Negative ELBO: 2.6056711081975266\n",
      "13/ Negative ELBO: 2.5498581934030238\n",
      "14/ Negative ELBO: 2.4147692031399846\n",
      "15/ Negative ELBO: 2.3772970541600054\n",
      "16/ Negative ELBO: 2.634344496401728\n",
      "17/ Negative ELBO: 2.3312368682670295\n",
      "18/ Negative ELBO: 2.292485250374938\n",
      "19/ Negative ELBO: 1.9703174888418784\n",
      "20/ Negative ELBO: 2.1114306479798737\n",
      "21/ Negative ELBO: 2.128538738791908\n",
      "22/ Negative ELBO: 2.78434808013137\n",
      "23/ Negative ELBO: 2.5816278678133386\n",
      "24/ Negative ELBO: 2.243471563793069\n",
      "25/ alpha: 0.48109591007232666\n",
      "25/ beta: -0.7683886885643005\n",
      "25/ r: 6.295075835295744\n",
      "25/ Negative ELBO: 2.076067205220177\n",
      "26/ Negative ELBO: 2.0968731164164183\n",
      "27/ Negative ELBO: 1.8459073755661373\n",
      "28/ Negative ELBO: 1.999654000156448\n",
      "29/ Negative ELBO: 2.794533368867785\n",
      "30/ Negative ELBO: 2.6080601137504993\n",
      "31/ Negative ELBO: 2.0325465000342797\n",
      "32/ Negative ELBO: 1.855630069966195\n",
      "33/ Negative ELBO: 1.8556002317912095\n",
      "34/ Negative ELBO: 2.093708784178063\n",
      "35/ Negative ELBO: 2.4016023615887123\n",
      "36/ Negative ELBO: 2.262335419140855\n",
      "37/ Negative ELBO: 1.9548056291673483\n",
      "38/ Negative ELBO: 1.903545754776125\n",
      "39/ Negative ELBO: 1.8173005145310817\n",
      "40/ Negative ELBO: 1.9542763796079847\n",
      "41/ Negative ELBO: 2.1872710722398216\n",
      "42/ Negative ELBO: 1.864698665576439\n",
      "43/ Negative ELBO: 1.4527619290008267\n",
      "44/ Negative ELBO: 1.6671568851649068\n",
      "45/ Negative ELBO: 1.755704241330112\n",
      "46/ Negative ELBO: 2.2096031386752606\n",
      "47/ Negative ELBO: 2.009556593500448\n",
      "48/ Negative ELBO: 1.610712601321849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|███████████████████████████████▍                                                                                                                                                                                                                           | 1/8 [00:04<00:29,  4.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/ Negative ELBO: 1.7498258799412743\n",
      "observation: 0.7418740051633642 variational mean: 0.8262216140253298\n",
      "0/ alpha: 0.41769567131996155\n",
      "0/ beta: 0.21874606609344482\n",
      "0/ r: 5.0\n",
      "0/ Negative ELBO: 162.2737849489851\n",
      "1/ Negative ELBO: 154.92829192601775\n",
      "2/ Negative ELBO: 153.22890132159847\n",
      "3/ Negative ELBO: 150.3886357386479\n",
      "4/ Negative ELBO: 148.5537598344248\n",
      "5/ Negative ELBO: 148.79255012635042\n",
      "6/ Negative ELBO: 144.14013809193125\n",
      "7/ Negative ELBO: 144.61257471458046\n",
      "8/ Negative ELBO: 144.18795843210265\n",
      "9/ Negative ELBO: 139.75868693523697\n",
      "10/ Negative ELBO: 135.31392759340088\n",
      "11/ Negative ELBO: 132.77541661408873\n",
      "12/ Negative ELBO: 130.93978561039526\n",
      "13/ Negative ELBO: 125.15796730086986\n",
      "14/ Negative ELBO: 120.5020248976047\n",
      "15/ Negative ELBO: 117.37661447384325\n",
      "16/ Negative ELBO: 114.52628061400735\n",
      "17/ Negative ELBO: 108.5325902921845\n",
      "18/ Negative ELBO: 105.37999655570161\n",
      "19/ Negative ELBO: 99.8001343422049\n",
      "20/ Negative ELBO: 93.41227887294033\n",
      "21/ Negative ELBO: 88.67530192405631\n",
      "22/ Negative ELBO: 84.62303989679262\n",
      "23/ Negative ELBO: 80.04026599326792\n",
      "24/ Negative ELBO: 75.36102237572517\n",
      "25/ alpha: 1.0396091938018799\n",
      "25/ beta: -1.1002928018569946\n",
      "25/ r: 6.439700793929833\n",
      "25/ Negative ELBO: 69.96260559972045\n",
      "26/ Negative ELBO: 63.729462315047286\n",
      "27/ Negative ELBO: 62.02285821206068\n",
      "28/ Negative ELBO: 55.76041503550483\n",
      "29/ Negative ELBO: 52.05043072083057\n",
      "30/ Negative ELBO: 48.02857111106347\n",
      "31/ Negative ELBO: 44.4016466621649\n",
      "32/ Negative ELBO: 39.97848751925556\n",
      "33/ Negative ELBO: 35.13711814587186\n",
      "34/ Negative ELBO: 32.70622704537301\n",
      "35/ Negative ELBO: 29.136828373153893\n",
      "36/ Negative ELBO: 26.315777739405352\n",
      "37/ Negative ELBO: 22.712388004352057\n",
      "38/ Negative ELBO: 19.82205526368918\n",
      "39/ Negative ELBO: 16.852044213947355\n",
      "40/ Negative ELBO: 15.211851534095219\n",
      "41/ Negative ELBO: 13.728407392701168\n",
      "42/ Negative ELBO: 11.931541043470931\n",
      "43/ Negative ELBO: 10.818574378249858\n",
      "44/ Negative ELBO: 9.65067267200305\n",
      "45/ Negative ELBO: 9.398801115810885\n",
      "46/ Negative ELBO: 9.224831886907008\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for it in tq.tqdm([50]):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars, vp__grads, vp__obj = Optimize(torch.tensor([sde_sigma]),\\\n",
    "                                                      obs, obs_time, obs_sigma, \\\n",
    "                                                      init_state=\"Random\", M=1500, \\\n",
    "#                                                       FIX_PAR = FIX_PAR,\n",
    "                                                               \\\n",
    "                                                      IT=it, vN=150, learning_rate=0.05, \\\n",
    "                                                      Optimizer=\"Adam\", beta_1 = 0.35, beta_2 = 0.01)\n",
    "    output.append([vp__pts, vp__mean, vp__std, vp__pars, vp__grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37475611",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "par_names = ['alpha', 'beta', 'r']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=P, figsize=(20, 5))\n",
    "        for j, ax in enumerate(ax.ravel()):\n",
    "            ax.plot(vp__pars[par_names[j]][t, :])\n",
    "            ax.set_title(par_names[j] + \" at time interval: %d\" % t)\n",
    "            ax.set_xlabel(\"Iterations\")\n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ecb81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "par_names = ['alpha', 'beta', 'r']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        for j in range(len(par_names)):\n",
    "            ax1.plot(vp__pars[par_names[j]][t, :], label=par_names[j])\n",
    "            ax1.set_title(par_names[j] + \" at time interval: %d\" % t)\n",
    "            ax1.set_xlabel(\"Iterations\")\n",
    "            ax1.set_ylabel(\"parameter value\")\n",
    "            ax1.legend()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(vp__obj['NELBO'][t], label='Negative ELBO', color='black')\n",
    "            ax2.set_ylabel(\"NELBO\", color='black')\n",
    "#             ax2.axhline(-20, linestyle='dashed', color='grey')\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9763aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vp__pts.T, vp__mean.T, color='black')\n",
    "    plt.fill_between(vp__pts, vp__mean + vp__std, vp__mean - vp__std, alpha=0.3, color='grey')\n",
    "    plt.plot(true_sde_pts, true_sde_trj, alpha=0.2)\n",
    "    plt.plot(obs_time, obs, 'rx')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(r\"X_{t}\")\n",
    "    title = \"approximating processes / iteration: \" + name\n",
    "    plt.title(title)\n",
    "    file_name = \"Adam_\" + \"approx_process_\" + \"iteration_\" + name\n",
    "#     plt.savefig(\"figures/\" + file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ebd89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "obj_names = ['NELBO', 'KL', 'NLL']\n",
    "for item, name in zip(output, it_names):\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        plt.plot(figsize=(8, 6))\n",
    "        for j in range(len(obj_names)):\n",
    "            plt.plot(vp__obj[obj_names[j]][t], label=obj_names[j])\n",
    "            plt.title(obj_names[j] + \" at time interval: %d\" % t)\n",
    "            plt.xlabel(\"Iterations\")\n",
    "#             ax1.set_ylabel(obj_names[j])\n",
    "            plt.legend()\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115064b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp_grads = item[4]\n",
    "    for t in range(T-1):\n",
    "        plt.figure(figsize=(10,5))\n",
    "\n",
    "        for key in vp_grads.keys():\n",
    "            plt.plot(vp_grads[key][t], label=key, alpha=0.8)\n",
    "            plt.ylabel(\"Gradient\")\n",
    "            plt.xlabel(\"Iterations\")\n",
    "#             plt.axhline(np.mean(vp_grads[key][t]), linestyle='dashed', label=str(np.mean(vp_grads[key]).round(2)))\n",
    "            plt.legend()\n",
    "\n",
    "        file_name = \"time\" + str(t) + \": Adam_\" + \"gradient_update_history/ \" + \"iteration_\" + name\n",
    "        plt.title(file_name)\n",
    "#     plt.savefig(\"figures/\" + file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89ca1b",
   "metadata": {},
   "source": [
    "Fix $\\alpha$ and optimize the other paramters, $\\beta, r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_pars = {'alpha': torch.tensor(1.)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for it in tq.tqdm([50]):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars, vp__grads, vp__obj = Optimize(torch.tensor([sde_sigma]),\\\n",
    "                                                      obs, obs_time, obs_sigma, \\\n",
    "                                                      init_state=\"Random\", M=1500, \\\n",
    "                                                      FIX_PAR = fix_pars,\n",
    "                                                               \\\n",
    "                                                      IT=it, vN=150, learning_rate=0.05, \\\n",
    "                                                      Optimizer=\"Adam\", beta_1 = 0.3, beta_2 = 0.01)\n",
    "    output.append([vp__pts, vp__mean, vp__std, vp__pars, vp__grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66a039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "par_names = ['alpha', 'beta', 'r']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        for j in range(len(par_names)):\n",
    "            ax1.plot(vp__pars[par_names[j]][t, :], label=par_names[j])\n",
    "            ax1.set_title(par_names[j] + \" at time interval: %d\" % t)\n",
    "            ax1.set_xlabel(\"Iterations\")\n",
    "            ax1.set_ylabel(\"parameter value\")\n",
    "            ax1.legend()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(vp__obj['NELBO'][t], label='Negative ELBO', color='black')\n",
    "            ax2.set_ylabel(\"NELBO\", color='black')\n",
    "#             ax2.axhline(-20, linestyle='dashed', color='grey')\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vp__pts.T, vp__mean.T, color='black')\n",
    "    plt.fill_between(vp__pts, vp__mean + vp__std, vp__mean - vp__std, alpha=0.3, color='grey')\n",
    "    plt.plot(true_sde_pts, true_sde_trj, alpha=0.2)\n",
    "    plt.plot(obs_time, obs, 'rx')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(r\"X_{t}\")\n",
    "    title = \"approximating processes / iteration: \" + name\n",
    "    plt.title(title)\n",
    "    file_name = \"Adam_\" + \"approx_process_\" + \"iteration_\" + name\n",
    "#     plt.savefig(\"figures/\" + file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302eb3c",
   "metadata": {},
   "source": [
    "FIX $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_pars = {'beta': torch.tensor(1.)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for it in tq.tqdm([50]):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars, vp__grads, vp__obj = Optimize(torch.tensor([sde_sigma]),\\\n",
    "                                                      obs, obs_time, obs_sigma, \\\n",
    "                                                      init_state=\"Random\", M=1500, \\\n",
    "                                                      FIX_PAR = fix_pars,\n",
    "                                                               \\\n",
    "                                                      IT=it, vN=150, learning_rate=0.05, \\\n",
    "                                                      Optimizer=\"Adam\", beta_1 = 0.3, beta_2 = 0.01)\n",
    "    output.append([vp__pts, vp__mean, vp__std, vp__pars, vp__grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddef74b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "par_names = ['alpha', 'beta', 'r']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        for j in range(len(par_names)):\n",
    "            ax1.plot(vp__pars[par_names[j]][t, :], label=par_names[j])\n",
    "            ax1.set_title(par_names[j] + \" at time interval: %d\" % t)\n",
    "            ax1.set_xlabel(\"Iterations\")\n",
    "            ax1.set_ylabel(\"parameter value\")\n",
    "            ax1.legend()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(vp__obj['NELBO'][t], label='Negative ELBO', color='black')\n",
    "            ax2.set_ylabel(\"NELBO\", color='black')\n",
    "#             ax2.axhline(-20, linestyle='dashed', color='grey')\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vp__pts.T, vp__mean.T, color='black')\n",
    "    plt.fill_between(vp__pts, vp__mean + vp__std, vp__mean - vp__std, alpha=0.3, color='grey')\n",
    "    plt.plot(true_sde_pts, true_sde_trj, alpha=0.2)\n",
    "    plt.plot(obs_time, obs, 'rx')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(r\"X_{t}\")\n",
    "    title = \"approximating processes / iteration: \" + name\n",
    "    plt.title(title)\n",
    "    file_name = \"Adam_\" + \"approx_process_\" + \"iteration_\" + name\n",
    "#     plt.savefig(\"figures/\" + file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ebe1b",
   "metadata": {},
   "source": [
    "FIX $\\alpha, \\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_pars = {'beta': torch.tensor(1.), 'alpha':torch.tensor(2.)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for it in tq.tqdm([50]):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars, vp__grads, vp__obj = Optimize(torch.tensor([sde_sigma]),\\\n",
    "                                                      obs, obs_time, obs_sigma, \\\n",
    "                                                      init_state=\"Random\", M=1500, \\\n",
    "                                                      FIX_PAR = fix_pars,\n",
    "                                                               \\\n",
    "                                                      IT=it, vN=150, learning_rate=0.05, \\\n",
    "                                                      Optimizer=\"Adam\", beta_1 = 0.1, beta_2 = 0.01)\n",
    "    output.append([vp__pts, vp__mean, vp__std, vp__pars, vp__grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e67479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "par_names = ['alpha', 'beta', 'r']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        for j in range(len(par_names)):\n",
    "            ax1.plot(vp__pars[par_names[j]][t, :], label=par_names[j])\n",
    "            ax1.set_title(par_names[j] + \" at time interval: %d\" % t)\n",
    "            ax1.set_xlabel(\"Iterations\")\n",
    "            ax1.set_ylabel(\"parameter value\")\n",
    "            ax1.legend()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(vp__obj['NELBO'][t], label='Negative ELBO', color='black')\n",
    "            ax2.set_ylabel(\"NELBO\", color='black')\n",
    "#             ax2.axhline(-20, linestyle='dashed', color='grey')\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vp__pts.T, vp__mean.T, color='black')\n",
    "    plt.fill_between(vp__pts, vp__mean + vp__std, vp__mean - vp__std, alpha=0.3, color='grey')\n",
    "    plt.plot(true_sde_pts, true_sde_trj, alpha=0.2)\n",
    "    plt.plot(obs_time, obs, 'rx')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(r\"X_{t}\")\n",
    "    title = \"approximating processes / iteration: \" + name\n",
    "    plt.title(title)\n",
    "    file_name = \"Adam_\" + \"approx_process_\" + \"iteration_\" + name\n",
    "#     plt.savefig(\"figures/\" + file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aac117",
   "metadata": {},
   "source": [
    "what if we reduce the time step by factor of 50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba6c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for it in tq.tqdm([50]):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars, vp__grads, vp__obj = Optimize(torch.tensor([sde_sigma]),\\\n",
    "                                                      obs, obs_time/50, obs_sigma, \\\n",
    "                                                      init_state=\"Random\", M=1500, \\\n",
    "#                                                       FIX_PAR = fix_pars,\n",
    "#                                                                \\\n",
    "                                                      IT=it, vN=150, learning_rate=0.15, \\\n",
    "                                                      Optimizer=\"Adam\", beta_1 = 0.5, beta_2 = 0.01)\n",
    "    output.append([vp__pts, vp__mean, vp__std, vp__pars, vp__grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f478320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "par_names = ['alpha', 'beta', 'r']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        for j in range(len(par_names)):\n",
    "            ax1.plot(vp__pars[par_names[j]][t, :], label=par_names[j])\n",
    "            ax1.set_title(par_names[j] + \" at time interval: %d\" % t)\n",
    "            ax1.set_xlabel(\"Iterations\")\n",
    "            ax1.set_ylabel(\"parameter value\")\n",
    "            ax1.legend()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(-1 * vp__obj['NELBO'][t], label='Negative ELBO', color='black')\n",
    "            ax2.set_ylabel(\"NELBO\", color='black')\n",
    "#             ax2.axhline(-20, linestyle='dashed', color='grey')\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34dc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "for item, name in zip(output, it_names):\n",
    "    vp__pts, vp__mean, vp__std, vp__pars = item[0], item[1], item[2], item[3]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vp__pts.T, vp__mean.T, color='black')\n",
    "    plt.fill_between(vp__pts, vp__mean + vp__std, vp__mean - vp__std, alpha=0.3, color='grey')\n",
    "    plt.plot(true_sde_pts/50, true_sde_trj, alpha=0.2)\n",
    "    plt.plot(obs_time/50, obs, 'rx')\n",
    "    title = \"approximating processes / iteration: \" + name\n",
    "    plt.title(title)\n",
    "    file_name = \"Adam_\" + \"approx_process_\" + \"iteration_\" + name\n",
    "#     plt.savefig(\"figures/\" + file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eec33b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it_names = ['50']\n",
    "obj_names = ['NELBO', 'KL', 'NLL']\n",
    "for item, name in zip(output, it_names):\n",
    "    P, T, IT = len(par_names), obs_time.shape[0], 30\n",
    "\n",
    "    for t in range(T-1):\n",
    "        plt.plot(figsize=(8, 6))\n",
    "        for j in range(len(obj_names)):\n",
    "            plt.plot(vp__obj[obj_names[j]][t], label=obj_names[j])\n",
    "            plt.title(obj_names[j] + \" at time interval: %d\" % t)\n",
    "            plt.xlabel(\"Iterations\")\n",
    "#             ax1.set_ylabel(obj_names[j])\n",
    "            plt.legend()\n",
    "            \n",
    "        title = \"Adam_\" + \"time_\" + str(t) + \"_iteration_\" + name\n",
    "#         plt.savefig(\"figures/\" + title)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
