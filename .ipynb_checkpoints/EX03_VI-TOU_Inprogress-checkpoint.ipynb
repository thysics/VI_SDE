{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591c0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from functorch import vmap\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043b84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'vp_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de3b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_ou import OU, ou_gradient\n",
    "from class_tou import tOU, tou_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b69b9",
   "metadata": {},
   "source": [
    "This code applies variational inference based on time-dependent OU processes to the observations drawn from the double well system SDE, as defined below. Note that we have chosen observational noise, i.e. variance of Gaussian noise and SDE variance to be 0.64 and 0.01 repectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22728a",
   "metadata": {},
   "source": [
    "m(t) = $\\alpha$t + $m_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6d11b",
   "metadata": {},
   "source": [
    "1. Simulate prior process, i.e. double-well system whose SDE is given by\n",
    "\n",
    "$dX_{t} = 4X_{t}(1-X^{2}_{t})dt + \\sigma dW_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366eb03f",
   "metadata": {},
   "source": [
    "**Generate observations from Gaussian likelihood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caf6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time step the SDE: dot X = -mu X + sigma xi, by Euler's method.\n",
    "\n",
    "# Problem setup. \n",
    "# Set model and numerical parameters, and the initial condition.\n",
    "# These are the lines the user might want to vary.\n",
    "tf = 8\n",
    "Nsteps = 800\n",
    "Npaths = 1\n",
    "X0 = 1\n",
    "sde_sigma = 0.8 # Variance is higher than the original example\n",
    "obs_sigma = 0.1\n",
    "\n",
    "# Generate the time grid and solution array\n",
    "t, dt = np.linspace(0,tf,Nsteps+1,retstep=True)\n",
    "X = np.zeros((Nsteps+1,Npaths))\n",
    "root_dt = np.sqrt(dt)\n",
    "  \n",
    "# Time step starting from initial condition\n",
    "X[0,:] = X0;\n",
    "for n in range(Nsteps):\n",
    "    F_of_X = 4 * X[n,:] * (1 - (X[n,:] ** 2))\n",
    "    X[n+1,:] =  X[n,:] + dt * F_of_X + sde_sigma * root_dt * np.random.randn(Npaths)\n",
    "\n",
    "# Observations with Gaussian noise\n",
    "obs = np.random.normal(loc = X[::100], scale = obs_sigma)\n",
    "obs_time = t[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d16c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_drift (s, x_s):\n",
    "    return 4 * x_s * (1 - (x_s ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18582d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sde_pts = torch.from_numpy(t)\n",
    "true_sde_trj = torch.from_numpy(X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6d1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.from_numpy(obs)\n",
    "obs_time = torch.from_numpy(obs_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ca55c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot paths\n",
    "plt.plot(t,X)\n",
    "plt.plot(t[::100], obs, \"rx\")\n",
    "plt.xlabel(\"t\", fontsize=14)\n",
    "plt.ylabel(\"X\", fontsize=14)\n",
    "plt.title(\"Sample paths\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f40f9",
   "metadata": {},
   "source": [
    "Variational inference: KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff800a",
   "metadata": {},
   "source": [
    "2. Implement Variational inference based on $\\textbf{time-inhomogeneous}$ OU process with SDE:\n",
    "\n",
    "$$dZ_t = [-r(Z_t - m(t)) + m'(t)]dt + \\sigma dW_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6d84b",
   "metadata": {},
   "source": [
    "$$\\log\\exp{\\frac{dP^{X}}{dP^{Z}}(Z) = \\int_{t_{0}}}^{t_{1}}\\frac{4Z_{t}(1-Z^{2}_{t}) + r(Z_{t}-m(t))-m'(t)}{\\sigma^{2}}dZ_{t} - \\frac{1}{2}\\int_{t_{0}}^{t_{1}}\\frac{16Z^{2}_{t}(1-Z^{2}_{t})^{2} - (-r(Z_{t} - m(t)) + m'(t))^{2}}{\\sigma^{2}}dt$$\n",
    "\n",
    "where the relevant functions\n",
    "\n",
    "$$m(t) = \\alpha (B(t, \\beta) - 1) + m_{0}$$\n",
    "\n",
    "$$m'(t) = \\alpha \\beta B(t, \\beta - 1)$$\n",
    "\n",
    "$$B(s, \\beta) = (s + 1)^{\\beta}$$\n",
    "\n",
    "Please note that $E(Z_t) = m(t)$. Here we consider a variational process with a $\\textbf{linear mean function}$, i.e. $\\beta = 1$, which results in $m(t) = \\alpha t + m_{0}$. Our variational parameters, thus, include $r, \\alpha, m_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063c5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBO:\n",
    "    \"\"\"\n",
    "        ELBO with\n",
    "            variational process (q): time-inhomogeneous OU process\n",
    "            prior process (p): double-well system\n",
    "            \n",
    "        This class computes: - KL(q|p) + NLL(y|z)  where z \\sim q\n",
    "    \"\"\"\n",
    "    def __init__(self, ou):\n",
    "        self.ou = ou\n",
    "        self.alpha = ou.alpha\n",
    "        self.beta = ou.beta\n",
    "        self.sigma = torch.tensor(ou.sigma)\n",
    "        self.r = ou.r\n",
    "        self.m0 = ou.m0\n",
    "    \n",
    "    def KL(self, prior_drift):\n",
    "        # Save parameter specification from ou class\n",
    "        alpha, beta, sigma, r, m0 = self.alpha, self.beta, self.sigma, self.r, self.m0\n",
    "        \n",
    "        def B(s, beta):\n",
    "            return (s+1) ** beta\n",
    "        \n",
    "        def m(s):\n",
    "            return alpha * (B(s, beta) - 1) + m0\n",
    "            \n",
    "        def m_(s):\n",
    "            return alpha * beta * B(s, beta-1)\n",
    "        \n",
    "        t = self.ou.pts - self.ou.pts[:, 0].reshape(-1, 1)\n",
    "        \n",
    "        # Evaluate the drift function of the approximating processes\n",
    "        g_of_x = -r * (self.ou.trj - m(t)) + m_(t)\n",
    "        \n",
    "        # Evaluate the drift function of the model (prior process)\n",
    "        f_of_x = prior_drift(t, self.ou.trj)\n",
    "        \n",
    "        # Compute the term inside the KL divergence\n",
    "        \n",
    "        F_of_X = abs(((f_of_x - g_of_x) / sigma) ** 2)\n",
    "        \n",
    "        return 0.5 * torch.trapezoid(F_of_X, x=t).reshape(-1, 1)\n",
    "        \n",
    "    \n",
    "#     def KL_Riemann(self):\n",
    "#         \"\"\"\n",
    "#             1. Compute the Riemann approximation to integral in KL divergence\n",
    "            \n",
    "#         \"\"\"\n",
    "#         # Save parameter specification from ou class\n",
    "#         alpha, beta, sigma, r, m0 = self.alpha, self.beta, self.sigma, self.r, self.m0\n",
    "        \n",
    "            \n",
    "#         def B(s, beta):\n",
    "#             return (s+1) ** beta\n",
    "        \n",
    "#         def m(s):\n",
    "#             return alpha * (B(s, beta) - 1) + m0\n",
    "            \n",
    "#         def m_(s):\n",
    "#             return alpha * beta * B(s, beta-1)\n",
    "        \n",
    "#         t = self.ou.pts - self.ou.pts[:, 0].reshape(-1, 1) \n",
    "        \n",
    "#         # Obtain integral term (via Riemann approximation, e.g. trapezoid)\n",
    "        \n",
    "# #         func = lambda s, z: 16 * (z**6) - 32 * (z**4) + (16-(r**2))*(z**2) \\\n",
    "# #                 - 2*r*alpha*beta*z*(B(s, beta-1) - (beta - 1) * B(s, beta-2)) - 12 * (sigma ** 2) * (z ** 2) \\\n",
    "# #                 + (2*r*z + r*alpha*(B(s, beta) - 1) + r*m0 + alpha*beta*B(s, beta-1)) * (r * alpha * (B(s, beta) - 1) + r*m0 + \\\n",
    "# #                                                                                 alpha * beta * B(s, beta-1))\n",
    "#         def integral(s, z):\n",
    "#             return (16 * z * z * (1 - z * z) ** 2) - ((-r * (z - m(s)) + m_(s)) ** 2)\n",
    "    \n",
    "#         num = integral(t, self.ou.trj)\n",
    "\n",
    "#         return -0.5 * torch.trapezoid(num, x=t).reshape(-1, 1) / (sigma * sigma)\n",
    "# #         return -0.5 * torch.trapezoid(num, x=self.ou.pts).reshape(-1, 1) / (sigma ** 2)\n",
    "    \n",
    "#     def KL_Ito(self):\n",
    "#         \"\"\"\n",
    "#             2. Compute the rest\n",
    "#         \"\"\"\n",
    "\n",
    "#         alpha, beta, sigma, r, m0 = self.alpha, self.beta, self.sigma, self.r, self.m0\n",
    "#         D = alpha.shape[0]\n",
    "        \n",
    "#         z0 = self.ou.z0\n",
    "\n",
    "#         z1 = self.ou.trj[:, -1].reshape(D, 1)\n",
    "        \n",
    "#         t = self.ou.pts - self.ou.pts[:, 0].reshape(-1, 1)\n",
    "\n",
    "#         t0 = t[:, 0]\n",
    "#         t1 = t[:, -1]\n",
    "        \n",
    "                \n",
    "#         def m(s):\n",
    "#             return alpha * (B(s, beta) - 1) + m0\n",
    "            \n",
    "#         def m_(s):\n",
    "#             return alpha * beta * B(s, beta-1)\n",
    "        \n",
    "#         def B(s, beta):\n",
    "#             return (s+1) ** beta\n",
    "        \n",
    "# #         def A(s, u):\n",
    "# #             return (-1 * (u ** 4) + 0.5 * (4+r) * (u ** 2) - u * r * (alpha*((s+1) ** beta - 1) + m0 - alpha*beta*((s+1) ** (beta-1))))\n",
    "#         def A(s, u):\n",
    "#             return (-1 * u ** 4 + 0.5 * (4 + r) * u * u - (r * m(s) + m_(s)) * u) / (sigma * sigma)\n",
    "                \n",
    "#         def integral_01(t0, t1):\n",
    "#             return r * alpha * B(t1, beta) + alpha * beta * B(t1, beta-1) - r * alpha * B(t0, beta) - alpha * beta * B(t0, beta-1)\n",
    "        \n",
    "#         return A(t1, z1) - A(t0, z0) + integral_01(t0, t1) / (sigma * sigma) - 0.5 * (4 + r) * (t1 - t0) + 6 * torch.trapezoid(self.ou.trj ** 2, x=t)\n",
    "# #         return (A(t1, z1) - A(t0, z0)) / (sigma ** 2) - 0.5 * (t1 - t0) * (r+4)\n",
    "    \n",
    "    def log_prob(self, obs, obs_sigma):\n",
    "        \"\"\"\n",
    "            Compute the log-likelihood\n",
    "            likelihood function is normal density N(obs, var)\n",
    "            obs.shape = D * 1 (D: # of sample)\n",
    "        \"\"\"\n",
    "        def log_pdf(obs, z, obs_sigma):\n",
    "            return ss.norm.logpdf(obs, loc=z, scale=obs_sigma)\n",
    "            \n",
    "        return torch.from_numpy(log_pdf(obs, self.ou.trj[:, -1].reshape(-1, 1), obs_sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0859993",
   "metadata": {},
   "source": [
    "**Variational inference: a piece-wise approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d17552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48fde07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/var/folders/2c/_gzbr1y51ws47zfknhxm868h0000gr/T/ipykernel_61384/830024755.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.sigma = torch.tensor(ou.sigma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  [0.00374589] m0 =  [0.34457231] r =  [4.9446993]\n",
      "tensor([[7.0852],\n",
      "        [2.2110],\n",
      "        [6.6151],\n",
      "        [4.8550],\n",
      "        [5.1384],\n",
      "        [4.5933],\n",
      "        [3.1282],\n",
      "        [7.4760],\n",
      "        [4.6860],\n",
      "        [5.6371],\n",
      "        [4.5820],\n",
      "        [2.9294],\n",
      "        [4.1800],\n",
      "        [4.1076],\n",
      "        [3.1669],\n",
      "        [4.7327],\n",
      "        [2.7601],\n",
      "        [3.3136],\n",
      "        [3.9192],\n",
      "        [5.1771],\n",
      "        [2.7279],\n",
      "        [3.2851],\n",
      "        [3.7295],\n",
      "        [6.8005],\n",
      "        [2.7120],\n",
      "        [3.4034],\n",
      "        [2.8021],\n",
      "        [5.7228],\n",
      "        [4.2545],\n",
      "        [4.4470],\n",
      "        [5.6449],\n",
      "        [4.5902],\n",
      "        [7.0459],\n",
      "        [4.0355],\n",
      "        [1.9571],\n",
      "        [3.2974],\n",
      "        [4.5246],\n",
      "        [6.3822],\n",
      "        [4.5804],\n",
      "        [4.4299],\n",
      "        [4.6425],\n",
      "        [7.2497],\n",
      "        [4.5835],\n",
      "        [2.4946],\n",
      "        [3.9905],\n",
      "        [3.3814],\n",
      "        [3.6390],\n",
      "        [4.1103],\n",
      "        [5.6831],\n",
      "        [3.3833]], dtype=torch.float64)\n",
      "(Neg) elbo =  44.27270449558412\n",
      "tensor([[4.8460],\n",
      "        [3.0006],\n",
      "        [3.8375],\n",
      "        [4.9650],\n",
      "        [4.2433],\n",
      "        [2.6809],\n",
      "        [2.4011],\n",
      "        [4.4816],\n",
      "        [5.4733],\n",
      "        [4.3369],\n",
      "        [3.6702],\n",
      "        [3.4174],\n",
      "        [3.6504],\n",
      "        [2.4373],\n",
      "        [3.7568],\n",
      "        [3.7198],\n",
      "        [3.1483],\n",
      "        [2.7860],\n",
      "        [2.8791],\n",
      "        [3.5627],\n",
      "        [3.5704],\n",
      "        [6.9421],\n",
      "        [5.6468],\n",
      "        [4.1752],\n",
      "        [4.6165],\n",
      "        [5.1923],\n",
      "        [2.3997],\n",
      "        [4.8931],\n",
      "        [5.6701],\n",
      "        [6.9164],\n",
      "        [6.8628],\n",
      "        [3.0845],\n",
      "        [4.5118],\n",
      "        [4.6084],\n",
      "        [3.6794],\n",
      "        [3.3090],\n",
      "        [3.6638],\n",
      "        [2.4619],\n",
      "        [3.6022],\n",
      "        [2.7581],\n",
      "        [3.7395],\n",
      "        [3.7065],\n",
      "        [3.7726],\n",
      "        [4.2604],\n",
      "        [2.5163],\n",
      "        [4.7945],\n",
      "        [4.4035],\n",
      "        [3.3377],\n",
      "        [5.2191],\n",
      "        [3.0518]], dtype=torch.float64)\n",
      "tensor([[4.6900],\n",
      "        [2.9589],\n",
      "        [3.6167],\n",
      "        [4.0741],\n",
      "        [5.7851],\n",
      "        [4.0159],\n",
      "        [4.6902],\n",
      "        [4.6738],\n",
      "        [5.2421],\n",
      "        [2.4191],\n",
      "        [3.6864],\n",
      "        [3.1885],\n",
      "        [3.2354],\n",
      "        [5.8993],\n",
      "        [2.7601],\n",
      "        [5.2296],\n",
      "        [4.8152],\n",
      "        [4.0261],\n",
      "        [3.2047],\n",
      "        [6.0862],\n",
      "        [3.6632],\n",
      "        [5.5772],\n",
      "        [2.9416],\n",
      "        [4.0794],\n",
      "        [3.1722],\n",
      "        [3.4253],\n",
      "        [3.7013],\n",
      "        [5.9854],\n",
      "        [3.7402],\n",
      "        [2.4703],\n",
      "        [2.5305],\n",
      "        [4.7761],\n",
      "        [5.3582],\n",
      "        [3.6745],\n",
      "        [2.9788],\n",
      "        [4.6853],\n",
      "        [2.7237],\n",
      "        [4.6450],\n",
      "        [3.2104],\n",
      "        [2.3100],\n",
      "        [3.9612],\n",
      "        [7.5066],\n",
      "        [5.4013],\n",
      "        [2.2392],\n",
      "        [4.5862],\n",
      "        [3.8446],\n",
      "        [5.5868],\n",
      "        [3.9835],\n",
      "        [3.7165],\n",
      "        [3.7312]], dtype=torch.float64)\n",
      "tensor([[4.2023],\n",
      "        [5.5356],\n",
      "        [3.6661],\n",
      "        [1.5274],\n",
      "        [5.6137],\n",
      "        [3.4929],\n",
      "        [5.5949],\n",
      "        [3.6561],\n",
      "        [3.8326],\n",
      "        [4.9212],\n",
      "        [4.4700],\n",
      "        [5.9882],\n",
      "        [4.0602],\n",
      "        [2.8056],\n",
      "        [4.5604],\n",
      "        [1.7772],\n",
      "        [6.1422],\n",
      "        [4.6256],\n",
      "        [5.2608],\n",
      "        [2.1790],\n",
      "        [3.0198],\n",
      "        [3.2610],\n",
      "        [3.2420],\n",
      "        [4.9939],\n",
      "        [3.8183],\n",
      "        [5.1008],\n",
      "        [1.7894],\n",
      "        [4.3143],\n",
      "        [4.7748],\n",
      "        [4.2069],\n",
      "        [3.3884],\n",
      "        [4.8181],\n",
      "        [4.4512],\n",
      "        [4.5893],\n",
      "        [4.1289],\n",
      "        [2.6882],\n",
      "        [5.7399],\n",
      "        [5.1440],\n",
      "        [2.7835],\n",
      "        [2.2347],\n",
      "        [4.1419],\n",
      "        [3.2856],\n",
      "        [5.3873],\n",
      "        [4.8284],\n",
      "        [5.6659],\n",
      "        [2.9628],\n",
      "        [4.4476],\n",
      "        [2.6434],\n",
      "        [2.8807],\n",
      "        [3.8847]], dtype=torch.float64)\n",
      "tensor([[3.6254],\n",
      "        [4.3095],\n",
      "        [2.1685],\n",
      "        [2.9468],\n",
      "        [3.1708],\n",
      "        [4.7799],\n",
      "        [3.5695],\n",
      "        [3.8116],\n",
      "        [5.3530],\n",
      "        [5.6098],\n",
      "        [3.8750],\n",
      "        [1.9342],\n",
      "        [4.3931],\n",
      "        [3.4944],\n",
      "        [4.1788],\n",
      "        [1.9387],\n",
      "        [3.6815],\n",
      "        [2.0280],\n",
      "        [2.7813],\n",
      "        [4.3067],\n",
      "        [4.9347],\n",
      "        [5.2081],\n",
      "        [3.2143],\n",
      "        [1.8716],\n",
      "        [3.8574],\n",
      "        [4.2905],\n",
      "        [2.9796],\n",
      "        [3.4061],\n",
      "        [7.1908],\n",
      "        [2.1415],\n",
      "        [3.5057],\n",
      "        [6.1048],\n",
      "        [4.6055],\n",
      "        [3.6348],\n",
      "        [6.0839],\n",
      "        [2.2133],\n",
      "        [4.1596],\n",
      "        [4.8249],\n",
      "        [3.7100],\n",
      "        [2.6665],\n",
      "        [3.0540],\n",
      "        [2.6491],\n",
      "        [3.6411],\n",
      "        [3.1460],\n",
      "        [5.5959],\n",
      "        [3.7318],\n",
      "        [2.3255],\n",
      "        [4.8745],\n",
      "        [4.4238],\n",
      "        [2.0910]], dtype=torch.float64)\n",
      "tensor([[2.9991],\n",
      "        [2.5318],\n",
      "        [3.9113],\n",
      "        [4.2600],\n",
      "        [2.5845],\n",
      "        [5.6180],\n",
      "        [4.7789],\n",
      "        [5.1415],\n",
      "        [3.8861],\n",
      "        [3.9336],\n",
      "        [2.2026],\n",
      "        [5.0512],\n",
      "        [1.9475],\n",
      "        [5.7727],\n",
      "        [3.6478],\n",
      "        [3.6190],\n",
      "        [6.6835],\n",
      "        [3.2609],\n",
      "        [3.1920],\n",
      "        [5.5803],\n",
      "        [3.4833],\n",
      "        [4.7264],\n",
      "        [2.9059],\n",
      "        [3.1002],\n",
      "        [4.7263],\n",
      "        [4.4950],\n",
      "        [3.4272],\n",
      "        [3.7462],\n",
      "        [5.7045],\n",
      "        [2.4588],\n",
      "        [3.8901],\n",
      "        [3.4993],\n",
      "        [6.4213],\n",
      "        [3.6714],\n",
      "        [2.8240],\n",
      "        [3.5323],\n",
      "        [4.3616],\n",
      "        [3.6082],\n",
      "        [3.0334],\n",
      "        [2.1419],\n",
      "        [3.2023],\n",
      "        [3.5149],\n",
      "        [4.5153],\n",
      "        [4.1051],\n",
      "        [4.5419],\n",
      "        [3.0947],\n",
      "        [3.5250],\n",
      "        [2.9559],\n",
      "        [3.2031],\n",
      "        [4.4794]], dtype=torch.float64)\n",
      "tensor([[3.0167],\n",
      "        [3.2912],\n",
      "        [3.4545],\n",
      "        [5.5399],\n",
      "        [3.4692],\n",
      "        [3.2906],\n",
      "        [3.6213],\n",
      "        [2.1770],\n",
      "        [5.0318],\n",
      "        [3.2567],\n",
      "        [3.1851],\n",
      "        [3.1146],\n",
      "        [5.6276],\n",
      "        [5.8128],\n",
      "        [3.6182],\n",
      "        [3.2679],\n",
      "        [5.4554],\n",
      "        [5.8757],\n",
      "        [5.5393],\n",
      "        [5.1510],\n",
      "        [3.0202],\n",
      "        [3.3316],\n",
      "        [4.8094],\n",
      "        [4.0194],\n",
      "        [3.5528],\n",
      "        [5.4001],\n",
      "        [5.3763],\n",
      "        [2.0981],\n",
      "        [2.9492],\n",
      "        [2.8754],\n",
      "        [6.0459],\n",
      "        [2.9201],\n",
      "        [4.5692],\n",
      "        [2.9591],\n",
      "        [2.0100],\n",
      "        [5.5451],\n",
      "        [3.4840],\n",
      "        [4.0613],\n",
      "        [2.5807],\n",
      "        [5.1737],\n",
      "        [6.4401],\n",
      "        [4.0702],\n",
      "        [3.5075],\n",
      "        [3.9228],\n",
      "        [2.6519],\n",
      "        [2.0646],\n",
      "        [3.1220],\n",
      "        [2.4513],\n",
      "        [5.5157],\n",
      "        [2.9562]], dtype=torch.float64)\n",
      "tensor([[3.5695],\n",
      "        [3.5023],\n",
      "        [4.3907],\n",
      "        [3.7603],\n",
      "        [3.8558],\n",
      "        [3.6211],\n",
      "        [3.4129],\n",
      "        [4.5240],\n",
      "        [3.8541],\n",
      "        [2.6325],\n",
      "        [4.0804],\n",
      "        [4.0949],\n",
      "        [2.3114],\n",
      "        [4.9174],\n",
      "        [3.1914],\n",
      "        [2.4418],\n",
      "        [2.9438],\n",
      "        [1.9616],\n",
      "        [4.9988],\n",
      "        [2.8309],\n",
      "        [3.8572],\n",
      "        [4.0831],\n",
      "        [4.4788],\n",
      "        [3.1909],\n",
      "        [5.5615],\n",
      "        [4.8978],\n",
      "        [4.2761],\n",
      "        [4.2396],\n",
      "        [3.1353],\n",
      "        [3.7738],\n",
      "        [2.7868],\n",
      "        [4.0783],\n",
      "        [3.8685],\n",
      "        [2.2311],\n",
      "        [3.6807],\n",
      "        [3.1179],\n",
      "        [2.2125],\n",
      "        [4.8264],\n",
      "        [3.6761],\n",
      "        [3.9305],\n",
      "        [5.5550],\n",
      "        [4.0349],\n",
      "        [2.0143],\n",
      "        [3.4211],\n",
      "        [4.0828],\n",
      "        [5.5411],\n",
      "        [3.8339],\n",
      "        [2.4725],\n",
      "        [5.4733],\n",
      "        [2.3042]], dtype=torch.float64)\n",
      "tensor([[2.2472],\n",
      "        [3.7670],\n",
      "        [5.0251],\n",
      "        [3.7675],\n",
      "        [3.5836],\n",
      "        [4.6203],\n",
      "        [4.9494],\n",
      "        [3.7652],\n",
      "        [5.3450],\n",
      "        [3.0222],\n",
      "        [3.8097],\n",
      "        [2.8656],\n",
      "        [5.7650],\n",
      "        [4.6678],\n",
      "        [3.2437],\n",
      "        [2.7347],\n",
      "        [3.7911],\n",
      "        [2.8683],\n",
      "        [1.9335],\n",
      "        [1.4950],\n",
      "        [4.7382],\n",
      "        [3.4045],\n",
      "        [2.6128],\n",
      "        [3.1307],\n",
      "        [4.1859],\n",
      "        [3.5920],\n",
      "        [2.7818],\n",
      "        [4.8006],\n",
      "        [5.3716],\n",
      "        [3.2783],\n",
      "        [3.3589],\n",
      "        [4.2811],\n",
      "        [3.2086],\n",
      "        [4.5330],\n",
      "        [5.5689],\n",
      "        [4.4359],\n",
      "        [3.2293],\n",
      "        [4.4408],\n",
      "        [5.2728],\n",
      "        [4.6463],\n",
      "        [2.2641],\n",
      "        [4.8171],\n",
      "        [1.7098],\n",
      "        [3.1536],\n",
      "        [2.7799],\n",
      "        [4.5579],\n",
      "        [4.0496],\n",
      "        [4.7938],\n",
      "        [4.2010],\n",
      "        [3.1309]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.9488],\n",
      "        [4.4345],\n",
      "        [2.7476],\n",
      "        [2.9993],\n",
      "        [2.3624],\n",
      "        [4.0789],\n",
      "        [3.7981],\n",
      "        [3.6540],\n",
      "        [2.4069],\n",
      "        [3.7177],\n",
      "        [4.8925],\n",
      "        [2.5828],\n",
      "        [2.9063],\n",
      "        [2.8110],\n",
      "        [4.2042],\n",
      "        [4.8284],\n",
      "        [5.3622],\n",
      "        [5.4509],\n",
      "        [2.6659],\n",
      "        [3.9371],\n",
      "        [3.7964],\n",
      "        [2.4334],\n",
      "        [2.7659],\n",
      "        [4.2419],\n",
      "        [4.6244],\n",
      "        [3.5874],\n",
      "        [3.4123],\n",
      "        [3.3148],\n",
      "        [2.8390],\n",
      "        [3.0027],\n",
      "        [3.8654],\n",
      "        [3.0898],\n",
      "        [4.2165],\n",
      "        [4.2137],\n",
      "        [5.4187],\n",
      "        [2.2500],\n",
      "        [3.5620],\n",
      "        [3.8646],\n",
      "        [3.6841],\n",
      "        [5.8376],\n",
      "        [3.4238],\n",
      "        [3.9633],\n",
      "        [3.1155],\n",
      "        [2.7493],\n",
      "        [2.1174],\n",
      "        [3.5802],\n",
      "        [4.4008],\n",
      "        [3.9858],\n",
      "        [1.7386],\n",
      "        [2.0406]], dtype=torch.float64)\n",
      "tensor([[5.1896],\n",
      "        [1.9948],\n",
      "        [3.2550],\n",
      "        [3.5245],\n",
      "        [6.2598],\n",
      "        [3.7269],\n",
      "        [3.0521],\n",
      "        [4.7809],\n",
      "        [2.3114],\n",
      "        [3.9272],\n",
      "        [4.2582],\n",
      "        [4.5546],\n",
      "        [4.4381],\n",
      "        [4.6514],\n",
      "        [1.8592],\n",
      "        [3.5291],\n",
      "        [5.9286],\n",
      "        [4.7513],\n",
      "        [6.2298],\n",
      "        [3.1231],\n",
      "        [2.7999],\n",
      "        [3.4219],\n",
      "        [1.9486],\n",
      "        [4.1274],\n",
      "        [4.0308],\n",
      "        [2.2053],\n",
      "        [2.9164],\n",
      "        [3.5369],\n",
      "        [2.3242],\n",
      "        [1.8433],\n",
      "        [2.3273],\n",
      "        [4.1131],\n",
      "        [1.5697],\n",
      "        [4.9239],\n",
      "        [5.4487],\n",
      "        [2.3769],\n",
      "        [3.3997],\n",
      "        [6.1210],\n",
      "        [6.3757],\n",
      "        [2.1812],\n",
      "        [2.8379],\n",
      "        [4.2998],\n",
      "        [4.5190],\n",
      "        [2.5981],\n",
      "        [5.0389],\n",
      "        [5.9329],\n",
      "        [5.4382],\n",
      "        [2.8254],\n",
      "        [3.8862],\n",
      "        [4.1785]], dtype=torch.float64)\n",
      "tensor([[4.1528],\n",
      "        [3.3040],\n",
      "        [4.0700],\n",
      "        [3.4523],\n",
      "        [3.7886],\n",
      "        [2.1040],\n",
      "        [4.7800],\n",
      "        [1.9722],\n",
      "        [5.2317],\n",
      "        [3.9155],\n",
      "        [2.3968],\n",
      "        [2.4172],\n",
      "        [4.0850],\n",
      "        [3.4971],\n",
      "        [1.8849],\n",
      "        [3.0903],\n",
      "        [3.8129],\n",
      "        [3.8477],\n",
      "        [5.4543],\n",
      "        [1.7121],\n",
      "        [2.7443],\n",
      "        [4.5018],\n",
      "        [4.1861],\n",
      "        [6.2857],\n",
      "        [3.2174],\n",
      "        [1.8057],\n",
      "        [4.0122],\n",
      "        [3.8096],\n",
      "        [4.4542],\n",
      "        [2.6903],\n",
      "        [2.1991],\n",
      "        [1.9931],\n",
      "        [3.5830],\n",
      "        [4.1604],\n",
      "        [3.8141],\n",
      "        [5.1580],\n",
      "        [3.4057],\n",
      "        [3.9333],\n",
      "        [2.1113],\n",
      "        [3.5273],\n",
      "        [3.1472],\n",
      "        [2.8070],\n",
      "        [5.0142],\n",
      "        [2.5406],\n",
      "        [2.9067],\n",
      "        [3.2401],\n",
      "        [2.0314],\n",
      "        [2.5048],\n",
      "        [3.0139],\n",
      "        [4.5171]], dtype=torch.float64)\n",
      "tensor([[1.4575],\n",
      "        [3.0739],\n",
      "        [2.5229],\n",
      "        [3.2112],\n",
      "        [2.3533],\n",
      "        [4.1337],\n",
      "        [4.1996],\n",
      "        [3.4553],\n",
      "        [2.7387],\n",
      "        [4.5397],\n",
      "        [5.0887],\n",
      "        [1.8545],\n",
      "        [3.6525],\n",
      "        [4.5167],\n",
      "        [4.6779],\n",
      "        [3.5418],\n",
      "        [2.2190],\n",
      "        [3.7350],\n",
      "        [2.9261],\n",
      "        [3.3194],\n",
      "        [2.9099],\n",
      "        [3.3096],\n",
      "        [3.2607],\n",
      "        [3.3268],\n",
      "        [3.2679],\n",
      "        [2.7273],\n",
      "        [2.4717],\n",
      "        [4.8664],\n",
      "        [3.0381],\n",
      "        [2.8387],\n",
      "        [1.4639],\n",
      "        [4.5935],\n",
      "        [4.0558],\n",
      "        [3.7576],\n",
      "        [5.0411],\n",
      "        [4.9581],\n",
      "        [3.3224],\n",
      "        [5.3246],\n",
      "        [5.9279],\n",
      "        [1.9651],\n",
      "        [1.9588],\n",
      "        [3.5309],\n",
      "        [4.5556],\n",
      "        [4.0976],\n",
      "        [4.2036],\n",
      "        [4.0149],\n",
      "        [3.9396],\n",
      "        [3.7203],\n",
      "        [4.2539],\n",
      "        [2.6765]], dtype=torch.float64)\n",
      "tensor([[3.9972],\n",
      "        [3.9958],\n",
      "        [4.2606],\n",
      "        [5.2132],\n",
      "        [3.3626],\n",
      "        [4.3162],\n",
      "        [3.7245],\n",
      "        [4.8604],\n",
      "        [4.5661],\n",
      "        [2.9431],\n",
      "        [2.0654],\n",
      "        [2.0454],\n",
      "        [3.4508],\n",
      "        [2.1536],\n",
      "        [3.4423],\n",
      "        [2.6551],\n",
      "        [3.6438],\n",
      "        [2.6026],\n",
      "        [3.4326],\n",
      "        [2.9272],\n",
      "        [2.5556],\n",
      "        [1.7009],\n",
      "        [2.7118],\n",
      "        [5.0134],\n",
      "        [2.6641],\n",
      "        [4.4382],\n",
      "        [4.7382],\n",
      "        [5.2569],\n",
      "        [3.9883],\n",
      "        [4.2993],\n",
      "        [2.0759],\n",
      "        [4.0950],\n",
      "        [4.7424],\n",
      "        [4.8160],\n",
      "        [4.1891],\n",
      "        [2.4337],\n",
      "        [2.2476],\n",
      "        [3.8240],\n",
      "        [2.2710],\n",
      "        [4.1392],\n",
      "        [2.8679],\n",
      "        [2.4213],\n",
      "        [2.6235],\n",
      "        [2.3100],\n",
      "        [2.6321],\n",
      "        [3.7141],\n",
      "        [2.9221],\n",
      "        [3.7627],\n",
      "        [3.9043],\n",
      "        [2.0500]], dtype=torch.float64)\n",
      "tensor([[2.9923],\n",
      "        [2.5095],\n",
      "        [4.7543],\n",
      "        [4.3094],\n",
      "        [4.2081],\n",
      "        [2.5116],\n",
      "        [4.1357],\n",
      "        [2.9153],\n",
      "        [3.1803],\n",
      "        [3.5424],\n",
      "        [3.7639],\n",
      "        [3.6698],\n",
      "        [4.0980],\n",
      "        [2.2331],\n",
      "        [1.7164],\n",
      "        [2.1843],\n",
      "        [3.9171],\n",
      "        [2.6581],\n",
      "        [2.0778],\n",
      "        [4.8704],\n",
      "        [4.8627],\n",
      "        [2.7257],\n",
      "        [5.3986],\n",
      "        [3.8915],\n",
      "        [2.1065],\n",
      "        [2.6948],\n",
      "        [2.7466],\n",
      "        [5.0041],\n",
      "        [2.1924],\n",
      "        [4.0291],\n",
      "        [3.6231],\n",
      "        [2.7425],\n",
      "        [3.5312],\n",
      "        [3.9828],\n",
      "        [3.5424],\n",
      "        [3.4386],\n",
      "        [3.3302],\n",
      "        [4.2126],\n",
      "        [3.3765],\n",
      "        [2.4054],\n",
      "        [2.7148],\n",
      "        [2.4758],\n",
      "        [2.0102],\n",
      "        [3.6275],\n",
      "        [3.1930],\n",
      "        [3.3604],\n",
      "        [3.1109],\n",
      "        [5.0168],\n",
      "        [3.6173],\n",
      "        [4.4312]], dtype=torch.float64)\n",
      "tensor([[4.3435],\n",
      "        [2.7929],\n",
      "        [3.6049],\n",
      "        [4.7820],\n",
      "        [2.8222],\n",
      "        [3.7799],\n",
      "        [3.5995],\n",
      "        [4.2758],\n",
      "        [1.9646],\n",
      "        [4.1299],\n",
      "        [2.8153],\n",
      "        [5.5447],\n",
      "        [2.9676],\n",
      "        [6.6072],\n",
      "        [3.1889],\n",
      "        [3.1694],\n",
      "        [2.6976],\n",
      "        [4.0319],\n",
      "        [4.9537],\n",
      "        [3.2821],\n",
      "        [4.3553],\n",
      "        [3.1959],\n",
      "        [3.2544],\n",
      "        [2.3853],\n",
      "        [3.1517],\n",
      "        [2.7599],\n",
      "        [1.5830],\n",
      "        [4.2723],\n",
      "        [3.0881],\n",
      "        [3.8752],\n",
      "        [3.3340],\n",
      "        [3.5990],\n",
      "        [4.8039],\n",
      "        [3.1464],\n",
      "        [3.3124],\n",
      "        [2.9909],\n",
      "        [4.3749],\n",
      "        [5.2411],\n",
      "        [3.9796],\n",
      "        [4.9119],\n",
      "        [2.9603],\n",
      "        [2.5605],\n",
      "        [2.6224],\n",
      "        [3.7294],\n",
      "        [1.9683],\n",
      "        [2.5939],\n",
      "        [1.7731],\n",
      "        [5.0267],\n",
      "        [5.0629],\n",
      "        [4.7154]], dtype=torch.float64)\n",
      "tensor([[2.9771],\n",
      "        [2.4428],\n",
      "        [2.8720],\n",
      "        [4.7451],\n",
      "        [2.4587],\n",
      "        [1.7913],\n",
      "        [3.5534],\n",
      "        [2.5653],\n",
      "        [2.8289],\n",
      "        [2.0821],\n",
      "        [4.4455],\n",
      "        [2.0778],\n",
      "        [2.4002],\n",
      "        [3.3066],\n",
      "        [4.1121],\n",
      "        [3.1020],\n",
      "        [4.1119],\n",
      "        [3.0269],\n",
      "        [2.8395],\n",
      "        [2.3047],\n",
      "        [2.2243],\n",
      "        [1.7562],\n",
      "        [3.8616],\n",
      "        [2.5985],\n",
      "        [5.0357],\n",
      "        [2.6597],\n",
      "        [4.7958],\n",
      "        [4.4373],\n",
      "        [4.2934],\n",
      "        [1.9706],\n",
      "        [4.0139],\n",
      "        [4.7883],\n",
      "        [2.6874],\n",
      "        [4.8343],\n",
      "        [3.4759],\n",
      "        [2.5440],\n",
      "        [3.3222],\n",
      "        [4.8559],\n",
      "        [2.9821],\n",
      "        [4.2110],\n",
      "        [4.6750],\n",
      "        [2.3298],\n",
      "        [3.0444],\n",
      "        [3.9007],\n",
      "        [3.9405],\n",
      "        [3.2056],\n",
      "        [4.5235],\n",
      "        [4.1963],\n",
      "        [6.1316],\n",
      "        [4.9626]], dtype=torch.float64)\n",
      "tensor([[3.7250],\n",
      "        [2.8933],\n",
      "        [4.2326],\n",
      "        [4.7169],\n",
      "        [2.1302],\n",
      "        [3.4851],\n",
      "        [2.5189],\n",
      "        [3.3629],\n",
      "        [4.0092],\n",
      "        [4.7065],\n",
      "        [2.7356],\n",
      "        [2.2119],\n",
      "        [3.2585],\n",
      "        [3.8064],\n",
      "        [2.4909],\n",
      "        [2.9684],\n",
      "        [3.4767],\n",
      "        [2.9523],\n",
      "        [3.1688],\n",
      "        [3.9367],\n",
      "        [4.0750],\n",
      "        [3.6118],\n",
      "        [2.7130],\n",
      "        [3.2923],\n",
      "        [1.7216],\n",
      "        [1.3330],\n",
      "        [3.0727],\n",
      "        [2.0245],\n",
      "        [3.4184],\n",
      "        [3.1468],\n",
      "        [2.1374],\n",
      "        [1.9845],\n",
      "        [4.1380],\n",
      "        [2.3952],\n",
      "        [3.2966],\n",
      "        [3.4801],\n",
      "        [2.3597],\n",
      "        [3.5147],\n",
      "        [3.2642],\n",
      "        [4.7466],\n",
      "        [2.8677],\n",
      "        [1.8110],\n",
      "        [2.1266],\n",
      "        [4.6280],\n",
      "        [3.7713],\n",
      "        [1.9558],\n",
      "        [2.5147],\n",
      "        [3.0405],\n",
      "        [3.4894],\n",
      "        [4.6185]], dtype=torch.float64)\n",
      "tensor([[3.8128],\n",
      "        [3.1001],\n",
      "        [2.7636],\n",
      "        [3.3028],\n",
      "        [3.8400],\n",
      "        [2.6049],\n",
      "        [2.3878],\n",
      "        [4.0391],\n",
      "        [3.7109],\n",
      "        [2.3206],\n",
      "        [3.4006],\n",
      "        [4.3487],\n",
      "        [2.4776],\n",
      "        [2.8281],\n",
      "        [3.2408],\n",
      "        [2.0299],\n",
      "        [1.5602],\n",
      "        [4.1252],\n",
      "        [4.1293],\n",
      "        [3.3255],\n",
      "        [1.7637],\n",
      "        [3.3162],\n",
      "        [1.4889],\n",
      "        [3.2473],\n",
      "        [4.3370],\n",
      "        [4.1134],\n",
      "        [2.5507],\n",
      "        [2.4115],\n",
      "        [3.1289],\n",
      "        [3.6932],\n",
      "        [2.1681],\n",
      "        [2.6175],\n",
      "        [2.6653],\n",
      "        [1.8525],\n",
      "        [2.7112],\n",
      "        [2.3072],\n",
      "        [2.7485],\n",
      "        [3.9615],\n",
      "        [4.1886],\n",
      "        [2.4006],\n",
      "        [2.5108],\n",
      "        [3.6620],\n",
      "        [3.2386],\n",
      "        [3.6985],\n",
      "        [2.4284],\n",
      "        [2.3778],\n",
      "        [2.4958],\n",
      "        [4.9798],\n",
      "        [2.9773],\n",
      "        [3.0291]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2575],\n",
      "        [1.9759],\n",
      "        [2.4947],\n",
      "        [1.2971],\n",
      "        [2.5497],\n",
      "        [1.7045],\n",
      "        [1.7547],\n",
      "        [4.5386],\n",
      "        [2.2304],\n",
      "        [3.3585],\n",
      "        [3.0021],\n",
      "        [4.2576],\n",
      "        [2.5333],\n",
      "        [3.2496],\n",
      "        [2.6418],\n",
      "        [3.5761],\n",
      "        [3.9386],\n",
      "        [3.7352],\n",
      "        [1.4722],\n",
      "        [3.0756],\n",
      "        [2.5835],\n",
      "        [3.4029],\n",
      "        [4.4880],\n",
      "        [3.6980],\n",
      "        [2.7886],\n",
      "        [4.9127],\n",
      "        [3.5435],\n",
      "        [3.5629],\n",
      "        [4.3985],\n",
      "        [2.7222],\n",
      "        [3.1885],\n",
      "        [3.4901],\n",
      "        [2.1178],\n",
      "        [4.1496],\n",
      "        [5.2286],\n",
      "        [2.5707],\n",
      "        [2.6583],\n",
      "        [2.5215],\n",
      "        [2.3457],\n",
      "        [4.5586],\n",
      "        [3.8740],\n",
      "        [2.7469],\n",
      "        [1.9529],\n",
      "        [3.7358],\n",
      "        [2.0395],\n",
      "        [2.5254],\n",
      "        [2.2615],\n",
      "        [1.1973],\n",
      "        [2.3668],\n",
      "        [3.1874]], dtype=torch.float64)\n",
      "tensor([[2.4565],\n",
      "        [2.1411],\n",
      "        [1.8977],\n",
      "        [3.3267],\n",
      "        [2.8078],\n",
      "        [3.5224],\n",
      "        [3.5817],\n",
      "        [2.3766],\n",
      "        [6.9171],\n",
      "        [1.4521],\n",
      "        [4.9618],\n",
      "        [2.3720],\n",
      "        [4.2588],\n",
      "        [3.2900],\n",
      "        [2.9500],\n",
      "        [2.9923],\n",
      "        [2.7608],\n",
      "        [2.9334],\n",
      "        [4.4630],\n",
      "        [1.7991],\n",
      "        [2.7295],\n",
      "        [2.1201],\n",
      "        [3.6777],\n",
      "        [4.4013],\n",
      "        [3.7858],\n",
      "        [3.2011],\n",
      "        [3.8578],\n",
      "        [3.7483],\n",
      "        [3.6003],\n",
      "        [3.9809],\n",
      "        [2.8419],\n",
      "        [2.5812],\n",
      "        [2.4489],\n",
      "        [3.3856],\n",
      "        [2.1094],\n",
      "        [3.4798],\n",
      "        [3.4064],\n",
      "        [3.0183],\n",
      "        [2.3425],\n",
      "        [3.5436],\n",
      "        [3.1122],\n",
      "        [3.3752],\n",
      "        [2.7070],\n",
      "        [4.4610],\n",
      "        [4.4315],\n",
      "        [2.8705],\n",
      "        [2.2200],\n",
      "        [3.3835],\n",
      "        [2.7828],\n",
      "        [1.8212]], dtype=torch.float64)\n",
      "tensor([[3.2166],\n",
      "        [3.6930],\n",
      "        [2.9745],\n",
      "        [4.5541],\n",
      "        [2.9845],\n",
      "        [2.2104],\n",
      "        [4.2744],\n",
      "        [2.7732],\n",
      "        [2.1028],\n",
      "        [3.5700],\n",
      "        [2.3434],\n",
      "        [1.6698],\n",
      "        [3.8213],\n",
      "        [4.5869],\n",
      "        [2.5105],\n",
      "        [4.2201],\n",
      "        [1.8323],\n",
      "        [2.7104],\n",
      "        [4.4373],\n",
      "        [3.4249],\n",
      "        [3.0700],\n",
      "        [3.0428],\n",
      "        [4.2318],\n",
      "        [2.1074],\n",
      "        [2.6402],\n",
      "        [3.1247],\n",
      "        [2.8364],\n",
      "        [3.9939],\n",
      "        [2.3083],\n",
      "        [2.1169],\n",
      "        [1.8764],\n",
      "        [3.1786],\n",
      "        [2.8410],\n",
      "        [2.8512],\n",
      "        [1.1520],\n",
      "        [3.3954],\n",
      "        [2.3128],\n",
      "        [2.5064],\n",
      "        [3.9126],\n",
      "        [2.9625],\n",
      "        [4.2814],\n",
      "        [3.2740],\n",
      "        [2.5200],\n",
      "        [2.5432],\n",
      "        [1.9902],\n",
      "        [2.7046],\n",
      "        [2.4083],\n",
      "        [3.2798],\n",
      "        [2.2150],\n",
      "        [2.7543]], dtype=torch.float64)\n",
      "tensor([[1.6801],\n",
      "        [3.0262],\n",
      "        [3.1042],\n",
      "        [2.7763],\n",
      "        [3.4645],\n",
      "        [3.5077],\n",
      "        [3.4324],\n",
      "        [3.8353],\n",
      "        [2.0039],\n",
      "        [2.9515],\n",
      "        [3.1746],\n",
      "        [3.4438],\n",
      "        [4.1989],\n",
      "        [3.1266],\n",
      "        [3.2952],\n",
      "        [2.5030],\n",
      "        [3.1455],\n",
      "        [3.7288],\n",
      "        [4.2219],\n",
      "        [3.1616],\n",
      "        [2.4703],\n",
      "        [2.0121],\n",
      "        [2.8743],\n",
      "        [2.0552],\n",
      "        [2.2787],\n",
      "        [3.3124],\n",
      "        [3.3399],\n",
      "        [3.2755],\n",
      "        [3.4726],\n",
      "        [1.6121],\n",
      "        [2.1701],\n",
      "        [3.0130],\n",
      "        [3.1490],\n",
      "        [2.5080],\n",
      "        [1.3032],\n",
      "        [4.3198],\n",
      "        [2.5596],\n",
      "        [2.8123],\n",
      "        [3.4236],\n",
      "        [2.4145],\n",
      "        [3.4035],\n",
      "        [2.5426],\n",
      "        [2.2375],\n",
      "        [3.9730],\n",
      "        [3.2089],\n",
      "        [3.1337],\n",
      "        [3.7126],\n",
      "        [2.7359],\n",
      "        [3.0744],\n",
      "        [4.3138]], dtype=torch.float64)\n",
      "tensor([[4.1229],\n",
      "        [4.4064],\n",
      "        [3.2121],\n",
      "        [2.9560],\n",
      "        [1.8907],\n",
      "        [2.4968],\n",
      "        [2.4466],\n",
      "        [3.4822],\n",
      "        [2.6374],\n",
      "        [3.5201],\n",
      "        [3.8190],\n",
      "        [2.3998],\n",
      "        [4.3551],\n",
      "        [2.0936],\n",
      "        [1.8872],\n",
      "        [3.3900],\n",
      "        [3.5888],\n",
      "        [3.1984],\n",
      "        [2.1288],\n",
      "        [2.2701],\n",
      "        [3.5748],\n",
      "        [3.9215],\n",
      "        [2.1151],\n",
      "        [2.7584],\n",
      "        [2.9003],\n",
      "        [2.2155],\n",
      "        [3.4183],\n",
      "        [2.1427],\n",
      "        [2.6396],\n",
      "        [4.1881],\n",
      "        [1.5401],\n",
      "        [2.8716],\n",
      "        [2.7687],\n",
      "        [1.9975],\n",
      "        [4.0769],\n",
      "        [2.3188],\n",
      "        [3.5706],\n",
      "        [2.0827],\n",
      "        [1.9487],\n",
      "        [3.9889],\n",
      "        [3.3258],\n",
      "        [3.6468],\n",
      "        [3.4090],\n",
      "        [3.0664],\n",
      "        [2.3958],\n",
      "        [2.2514],\n",
      "        [2.8813],\n",
      "        [2.2265],\n",
      "        [2.8161],\n",
      "        [3.4924]], dtype=torch.float64)\n",
      "tensor([[1.4218],\n",
      "        [1.9853],\n",
      "        [1.9137],\n",
      "        [3.6109],\n",
      "        [4.2822],\n",
      "        [3.0875],\n",
      "        [2.3872],\n",
      "        [2.7173],\n",
      "        [2.1141],\n",
      "        [2.7231],\n",
      "        [2.4260],\n",
      "        [4.4566],\n",
      "        [3.1198],\n",
      "        [3.4360],\n",
      "        [3.8720],\n",
      "        [2.7862],\n",
      "        [1.3128],\n",
      "        [4.1102],\n",
      "        [3.2877],\n",
      "        [1.3114],\n",
      "        [3.7988],\n",
      "        [3.5420],\n",
      "        [2.4756],\n",
      "        [2.7793],\n",
      "        [3.4156],\n",
      "        [2.5399],\n",
      "        [1.9518],\n",
      "        [4.5120],\n",
      "        [4.2304],\n",
      "        [3.5315],\n",
      "        [3.7558],\n",
      "        [3.6171],\n",
      "        [3.8581],\n",
      "        [4.3092],\n",
      "        [2.6233],\n",
      "        [3.3835],\n",
      "        [3.3250],\n",
      "        [3.1787],\n",
      "        [1.3787],\n",
      "        [2.1056],\n",
      "        [2.3741],\n",
      "        [4.4202],\n",
      "        [2.0474],\n",
      "        [3.0461],\n",
      "        [3.9132],\n",
      "        [4.5930],\n",
      "        [2.4211],\n",
      "        [3.0396],\n",
      "        [2.0842],\n",
      "        [1.2911]], dtype=torch.float64)\n",
      "tensor([[4.2539],\n",
      "        [3.6036],\n",
      "        [4.2185],\n",
      "        [2.5098],\n",
      "        [1.4380],\n",
      "        [1.8931],\n",
      "        [2.6704],\n",
      "        [2.1353],\n",
      "        [2.6142],\n",
      "        [3.1643],\n",
      "        [3.3882],\n",
      "        [4.1252],\n",
      "        [2.7003],\n",
      "        [2.8705],\n",
      "        [3.3274],\n",
      "        [3.8957],\n",
      "        [2.6867],\n",
      "        [3.7419],\n",
      "        [2.6889],\n",
      "        [3.7493],\n",
      "        [3.8899],\n",
      "        [1.5259],\n",
      "        [3.4273],\n",
      "        [2.4174],\n",
      "        [2.4703],\n",
      "        [2.6631],\n",
      "        [2.6878],\n",
      "        [2.1163],\n",
      "        [3.2750],\n",
      "        [3.5893],\n",
      "        [2.0050],\n",
      "        [2.4700],\n",
      "        [3.5757],\n",
      "        [2.4253],\n",
      "        [1.2137],\n",
      "        [2.1422],\n",
      "        [4.0243],\n",
      "        [2.2457],\n",
      "        [3.0139],\n",
      "        [3.2019],\n",
      "        [2.7566],\n",
      "        [3.6062],\n",
      "        [2.4076],\n",
      "        [2.8280],\n",
      "        [2.5044],\n",
      "        [1.4946],\n",
      "        [2.8481],\n",
      "        [2.2184],\n",
      "        [3.0343],\n",
      "        [1.6254]], dtype=torch.float64)\n",
      "tensor([[3.5701],\n",
      "        [3.3153],\n",
      "        [2.1959],\n",
      "        [2.4064],\n",
      "        [3.4353],\n",
      "        [3.4412],\n",
      "        [3.2154],\n",
      "        [2.6089],\n",
      "        [1.9368],\n",
      "        [2.7406],\n",
      "        [2.8933],\n",
      "        [2.5627],\n",
      "        [3.1540],\n",
      "        [2.1232],\n",
      "        [2.6966],\n",
      "        [3.8879],\n",
      "        [2.9599],\n",
      "        [3.2624],\n",
      "        [4.8121],\n",
      "        [9.4709],\n",
      "        [3.1534],\n",
      "        [3.5321],\n",
      "        [2.1438],\n",
      "        [2.6138],\n",
      "        [2.0838],\n",
      "        [4.0014],\n",
      "        [2.2470],\n",
      "        [2.2326],\n",
      "        [2.6175],\n",
      "        [1.3427],\n",
      "        [1.9983],\n",
      "        [3.3500],\n",
      "        [2.8305],\n",
      "        [1.6989],\n",
      "        [3.7570],\n",
      "        [3.0000],\n",
      "        [4.1429],\n",
      "        [3.0746],\n",
      "        [1.4759],\n",
      "        [2.1922],\n",
      "        [3.8953],\n",
      "        [1.1428],\n",
      "        [3.4734],\n",
      "        [1.7718],\n",
      "        [2.7379],\n",
      "        [1.7019],\n",
      "        [2.7963],\n",
      "        [3.6906],\n",
      "        [2.5582],\n",
      "        [3.2137]], dtype=torch.float64)\n",
      "tensor([[4.9341],\n",
      "        [3.6732],\n",
      "        [2.2394],\n",
      "        [2.7785],\n",
      "        [3.2693],\n",
      "        [3.1992],\n",
      "        [1.5333],\n",
      "        [3.3401],\n",
      "        [2.5814],\n",
      "        [3.0199],\n",
      "        [3.8529],\n",
      "        [3.2509],\n",
      "        [3.5915],\n",
      "        [2.6503],\n",
      "        [3.5617],\n",
      "        [3.7386],\n",
      "        [2.9457],\n",
      "        [2.6283],\n",
      "        [2.1025],\n",
      "        [2.6677],\n",
      "        [3.1996],\n",
      "        [3.6316],\n",
      "        [2.3958],\n",
      "        [2.5851],\n",
      "        [2.1217],\n",
      "        [2.1534],\n",
      "        [3.0100],\n",
      "        [3.6844],\n",
      "        [2.1842],\n",
      "        [3.1981],\n",
      "        [3.1823],\n",
      "        [1.8706],\n",
      "        [1.4718],\n",
      "        [3.0667],\n",
      "        [3.1637],\n",
      "        [2.9743],\n",
      "        [2.9269],\n",
      "        [2.3394],\n",
      "        [2.3674],\n",
      "        [2.0460],\n",
      "        [2.2678],\n",
      "        [2.8580],\n",
      "        [3.3120],\n",
      "        [1.8716],\n",
      "        [2.2063],\n",
      "        [1.7643],\n",
      "        [0.7370],\n",
      "        [2.6758],\n",
      "        [1.9273],\n",
      "        [1.9885]], dtype=torch.float64)\n",
      "tensor([[2.9663],\n",
      "        [3.4165],\n",
      "        [3.6997],\n",
      "        [2.6777],\n",
      "        [2.2163],\n",
      "        [3.1792],\n",
      "        [1.9061],\n",
      "        [2.7121],\n",
      "        [3.3382],\n",
      "        [2.0937],\n",
      "        [4.0476],\n",
      "        [2.0242],\n",
      "        [3.9055],\n",
      "        [2.9881],\n",
      "        [3.7715],\n",
      "        [2.7518],\n",
      "        [3.7447],\n",
      "        [3.0589],\n",
      "        [2.7834],\n",
      "        [2.9025],\n",
      "        [2.6485],\n",
      "        [3.6734],\n",
      "        [3.4394],\n",
      "        [2.3826],\n",
      "        [3.2650],\n",
      "        [1.9367],\n",
      "        [2.7467],\n",
      "        [2.8734],\n",
      "        [2.3118],\n",
      "        [1.8793],\n",
      "        [2.8894],\n",
      "        [3.4874],\n",
      "        [2.0820],\n",
      "        [3.4829],\n",
      "        [2.0703],\n",
      "        [1.8726],\n",
      "        [3.6650],\n",
      "        [2.9719],\n",
      "        [3.1430],\n",
      "        [2.2918],\n",
      "        [3.9102],\n",
      "        [3.2521],\n",
      "        [3.1685],\n",
      "        [2.3380],\n",
      "        [2.4950],\n",
      "        [3.7546],\n",
      "        [3.2417],\n",
      "        [3.7091],\n",
      "        [2.9280],\n",
      "        [2.4659]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1171],\n",
      "        [3.3929],\n",
      "        [3.6341],\n",
      "        [1.9621],\n",
      "        [2.3796],\n",
      "        [2.4244],\n",
      "        [2.5516],\n",
      "        [3.5126],\n",
      "        [1.4117],\n",
      "        [2.9803],\n",
      "        [3.2909],\n",
      "        [3.5089],\n",
      "        [3.3233],\n",
      "        [2.4889],\n",
      "        [2.4826],\n",
      "        [3.7667],\n",
      "        [2.2994],\n",
      "        [3.3102],\n",
      "        [2.7136],\n",
      "        [1.4896],\n",
      "        [3.1763],\n",
      "        [3.9998],\n",
      "        [3.4037],\n",
      "        [3.0235],\n",
      "        [1.5299],\n",
      "        [3.3199],\n",
      "        [3.0438],\n",
      "        [3.8287],\n",
      "        [1.6313],\n",
      "        [2.9846],\n",
      "        [2.6773],\n",
      "        [2.6476],\n",
      "        [1.5575],\n",
      "        [3.2005],\n",
      "        [3.5580],\n",
      "        [1.4425],\n",
      "        [3.4329],\n",
      "        [2.8205],\n",
      "        [4.4753],\n",
      "        [3.0691],\n",
      "        [3.2998],\n",
      "        [2.8003],\n",
      "        [3.0513],\n",
      "        [2.7520],\n",
      "        [3.3027],\n",
      "        [3.4181],\n",
      "        [2.6895],\n",
      "        [1.7232],\n",
      "        [2.6013],\n",
      "        [3.7786]], dtype=torch.float64)\n",
      "tensor([[2.6587],\n",
      "        [2.7941],\n",
      "        [1.0764],\n",
      "        [4.0088],\n",
      "        [2.9899],\n",
      "        [2.4507],\n",
      "        [3.0879],\n",
      "        [2.7722],\n",
      "        [3.3629],\n",
      "        [2.2922],\n",
      "        [3.4970],\n",
      "        [1.7058],\n",
      "        [3.2056],\n",
      "        [3.2959],\n",
      "        [3.0220],\n",
      "        [3.4714],\n",
      "        [2.1433],\n",
      "        [2.3126],\n",
      "        [3.1015],\n",
      "        [2.1833],\n",
      "        [1.3980],\n",
      "        [2.6311],\n",
      "        [2.3358],\n",
      "        [3.5613],\n",
      "        [1.8641],\n",
      "        [2.5116],\n",
      "        [2.2916],\n",
      "        [1.2069],\n",
      "        [3.2598],\n",
      "        [2.2329],\n",
      "        [2.7227],\n",
      "        [2.1558],\n",
      "        [2.6731],\n",
      "        [2.3439],\n",
      "        [2.0489],\n",
      "        [1.3439],\n",
      "        [3.5234],\n",
      "        [3.0818],\n",
      "        [2.7094],\n",
      "        [2.0348],\n",
      "        [2.4386],\n",
      "        [2.5739],\n",
      "        [1.2746],\n",
      "        [1.9647],\n",
      "        [3.5684],\n",
      "        [2.0381],\n",
      "        [1.7505],\n",
      "        [3.8247],\n",
      "        [2.6173],\n",
      "        [2.6650]], dtype=torch.float64)\n",
      "tensor([[5.1461],\n",
      "        [3.0299],\n",
      "        [2.4941],\n",
      "        [2.7297],\n",
      "        [2.4919],\n",
      "        [2.2070],\n",
      "        [3.2829],\n",
      "        [1.4213],\n",
      "        [2.0930],\n",
      "        [2.0635],\n",
      "        [3.1669],\n",
      "        [2.4682],\n",
      "        [4.7805],\n",
      "        [2.5242],\n",
      "        [1.6581],\n",
      "        [3.0612],\n",
      "        [2.6680],\n",
      "        [2.6266],\n",
      "        [2.7984],\n",
      "        [2.6996],\n",
      "        [3.3056],\n",
      "        [3.9488],\n",
      "        [2.9005],\n",
      "        [2.8111],\n",
      "        [3.1335],\n",
      "        [2.8534],\n",
      "        [2.6424],\n",
      "        [1.6872],\n",
      "        [2.2610],\n",
      "        [3.3075],\n",
      "        [3.1055],\n",
      "        [3.1614],\n",
      "        [2.4190],\n",
      "        [2.4225],\n",
      "        [2.5490],\n",
      "        [2.3473],\n",
      "        [2.9916],\n",
      "        [2.9292],\n",
      "        [1.9143],\n",
      "        [2.3552],\n",
      "        [3.0989],\n",
      "        [3.2768],\n",
      "        [2.0845],\n",
      "        [2.2823],\n",
      "        [2.4229],\n",
      "        [3.2323],\n",
      "        [2.3746],\n",
      "        [1.9264],\n",
      "        [2.0842],\n",
      "        [2.7608]], dtype=torch.float64)\n",
      "tensor([[1.7483],\n",
      "        [3.2695],\n",
      "        [1.5743],\n",
      "        [2.2367],\n",
      "        [2.2602],\n",
      "        [2.2496],\n",
      "        [2.8975],\n",
      "        [2.1785],\n",
      "        [2.7787],\n",
      "        [3.0607],\n",
      "        [2.0955],\n",
      "        [2.4804],\n",
      "        [2.3877],\n",
      "        [3.5355],\n",
      "        [3.2635],\n",
      "        [1.5623],\n",
      "        [2.3686],\n",
      "        [3.3570],\n",
      "        [3.6066],\n",
      "        [1.4909],\n",
      "        [3.1253],\n",
      "        [2.0423],\n",
      "        [2.8882],\n",
      "        [2.3533],\n",
      "        [1.7395],\n",
      "        [3.1915],\n",
      "        [2.5379],\n",
      "        [2.8235],\n",
      "        [2.5313],\n",
      "        [2.7671],\n",
      "        [2.9419],\n",
      "        [3.0347],\n",
      "        [2.4318],\n",
      "        [2.0155],\n",
      "        [2.6649],\n",
      "        [2.6191],\n",
      "        [3.0015],\n",
      "        [2.7883],\n",
      "        [2.8710],\n",
      "        [1.9992],\n",
      "        [3.5135],\n",
      "        [3.1181],\n",
      "        [1.9582],\n",
      "        [3.3529],\n",
      "        [3.2397],\n",
      "        [3.7275],\n",
      "        [1.5041],\n",
      "        [3.2547],\n",
      "        [2.2346],\n",
      "        [2.0893]], dtype=torch.float64)\n",
      "tensor([[3.4657],\n",
      "        [3.2217],\n",
      "        [1.5072],\n",
      "        [2.9887],\n",
      "        [2.8054],\n",
      "        [3.5304],\n",
      "        [2.6324],\n",
      "        [3.0021],\n",
      "        [3.2938],\n",
      "        [2.5603],\n",
      "        [2.9120],\n",
      "        [3.3324],\n",
      "        [2.4292],\n",
      "        [1.5925],\n",
      "        [1.8465],\n",
      "        [2.0471],\n",
      "        [2.6064],\n",
      "        [1.9935],\n",
      "        [1.6756],\n",
      "        [1.7681],\n",
      "        [2.5723],\n",
      "        [3.5010],\n",
      "        [2.7820],\n",
      "        [2.1377],\n",
      "        [2.4224],\n",
      "        [2.8935],\n",
      "        [2.7421],\n",
      "        [3.0542],\n",
      "        [3.3061],\n",
      "        [2.8080],\n",
      "        [2.6132],\n",
      "        [1.9690],\n",
      "        [2.8428],\n",
      "        [2.0427],\n",
      "        [1.8799],\n",
      "        [2.7674],\n",
      "        [3.7211],\n",
      "        [2.5586],\n",
      "        [1.7865],\n",
      "        [3.0662],\n",
      "        [2.1667],\n",
      "        [2.1206],\n",
      "        [2.6876],\n",
      "        [2.7524],\n",
      "        [2.7042],\n",
      "        [5.1076],\n",
      "        [3.3481],\n",
      "        [3.4229],\n",
      "        [1.6766],\n",
      "        [2.2519]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/8 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9805],\n",
      "        [2.2383],\n",
      "        [3.0030],\n",
      "        [3.2956],\n",
      "        [1.4099],\n",
      "        [1.6211],\n",
      "        [3.0363],\n",
      "        [2.7771],\n",
      "        [2.8523],\n",
      "        [3.3520],\n",
      "        [3.4745],\n",
      "        [2.3206],\n",
      "        [1.3875],\n",
      "        [2.8555],\n",
      "        [2.5519],\n",
      "        [1.8295],\n",
      "        [1.5723],\n",
      "        [3.4264],\n",
      "        [2.8888],\n",
      "        [2.7412],\n",
      "        [1.6444],\n",
      "        [2.0978],\n",
      "        [2.1197],\n",
      "        [1.5187],\n",
      "        [1.8395],\n",
      "        [1.7247],\n",
      "        [2.1288],\n",
      "        [3.2303],\n",
      "        [2.5168],\n",
      "        [2.6682],\n",
      "        [1.9266],\n",
      "        [3.0519],\n",
      "        [1.2601],\n",
      "        [2.7613],\n",
      "        [2.2674],\n",
      "        [2.2649],\n",
      "        [1.5289],\n",
      "        [2.4770],\n",
      "        [3.3536],\n",
      "        [2.9802],\n",
      "        [2.6635],\n",
      "        [2.7836],\n",
      "        [2.1001],\n",
      "        [2.7934],\n",
      "        [1.8596],\n",
      "        [3.0545],\n",
      "        [2.9964],\n",
      "        [2.2244],\n",
      "        [2.9255],\n",
      "        [2.0886]], dtype=torch.float64)\n",
      "tensor([[4.4118],\n",
      "        [3.2548],\n",
      "        [1.5002],\n",
      "        [2.1162],\n",
      "        [2.7246],\n",
      "        [2.0755],\n",
      "        [1.3078],\n",
      "        [1.7534],\n",
      "        [1.8565],\n",
      "        [1.5969],\n",
      "        [2.4901],\n",
      "        [2.2934],\n",
      "        [1.7609],\n",
      "        [1.0050],\n",
      "        [2.4503],\n",
      "        [2.9178],\n",
      "        [1.7522],\n",
      "        [2.4858],\n",
      "        [2.7803],\n",
      "        [2.0592],\n",
      "        [2.6227],\n",
      "        [2.8000],\n",
      "        [2.4265],\n",
      "        [2.6702],\n",
      "        [2.3942],\n",
      "        [1.7415],\n",
      "        [1.8106],\n",
      "        [1.7754],\n",
      "        [2.6813],\n",
      "        [1.3826],\n",
      "        [2.7220],\n",
      "        [3.6330],\n",
      "        [2.4197],\n",
      "        [2.4145],\n",
      "        [2.8042],\n",
      "        [2.4064],\n",
      "        [2.4313],\n",
      "        [3.1998],\n",
      "        [2.0585],\n",
      "        [2.6600],\n",
      "        [1.5864],\n",
      "        [1.3105],\n",
      "        [2.3901],\n",
      "        [2.6494],\n",
      "        [3.0784],\n",
      "        [2.6436],\n",
      "        [2.3123],\n",
      "        [2.3277],\n",
      "        [2.8626],\n",
      "        [2.5868]], dtype=torch.float64)\n",
      "tensor([[2.5039],\n",
      "        [2.2784],\n",
      "        [1.5068],\n",
      "        [2.2851],\n",
      "        [2.3228],\n",
      "        [2.5481],\n",
      "        [2.0661],\n",
      "        [2.6000],\n",
      "        [2.2929],\n",
      "        [3.1321],\n",
      "        [1.7854],\n",
      "        [1.8530],\n",
      "        [2.5371],\n",
      "        [2.3926],\n",
      "        [2.4531],\n",
      "        [2.3592],\n",
      "        [2.3092],\n",
      "        [3.3437],\n",
      "        [1.3758],\n",
      "        [1.6143],\n",
      "        [2.4526],\n",
      "        [2.5341],\n",
      "        [2.2207],\n",
      "        [2.4326],\n",
      "        [1.9724],\n",
      "        [3.4392],\n",
      "        [2.5938],\n",
      "        [2.2659],\n",
      "        [2.0147],\n",
      "        [1.8496],\n",
      "        [2.0451],\n",
      "        [2.8872],\n",
      "        [2.2702],\n",
      "        [2.5404],\n",
      "        [2.5102],\n",
      "        [2.4293],\n",
      "        [2.3206],\n",
      "        [1.6925],\n",
      "        [3.2285],\n",
      "        [1.9281],\n",
      "        [2.9665],\n",
      "        [2.6090],\n",
      "        [2.6710],\n",
      "        [3.0136],\n",
      "        [1.7781],\n",
      "        [2.4272],\n",
      "        [2.6392],\n",
      "        [2.4653],\n",
      "        [1.3481],\n",
      "        [1.6152]], dtype=torch.float64)\n",
      "tensor([[2.5976],\n",
      "        [2.3492],\n",
      "        [1.3697],\n",
      "        [1.6153],\n",
      "        [1.2620],\n",
      "        [1.4503],\n",
      "        [1.9311],\n",
      "        [2.9501],\n",
      "        [2.3672],\n",
      "        [1.6474],\n",
      "        [1.7181],\n",
      "        [2.6628],\n",
      "        [2.2285],\n",
      "        [2.8737],\n",
      "        [2.0290],\n",
      "        [2.4905],\n",
      "        [1.9227],\n",
      "        [2.4407],\n",
      "        [1.4936],\n",
      "        [1.4053],\n",
      "        [1.9477],\n",
      "        [2.8534],\n",
      "        [2.5744],\n",
      "        [1.3233],\n",
      "        [1.9329],\n",
      "        [2.5118],\n",
      "        [1.7084],\n",
      "        [2.4545],\n",
      "        [1.3473],\n",
      "        [2.3341],\n",
      "        [2.5173],\n",
      "        [2.8752],\n",
      "        [1.3335],\n",
      "        [2.6168],\n",
      "        [2.4740],\n",
      "        [3.1144],\n",
      "        [1.2976],\n",
      "        [2.5762],\n",
      "        [1.9420],\n",
      "        [3.2817],\n",
      "        [3.1341],\n",
      "        [2.0273],\n",
      "        [1.3446],\n",
      "        [2.5373],\n",
      "        [2.7368],\n",
      "        [1.4047],\n",
      "        [1.8075],\n",
      "        [1.7727],\n",
      "        [1.9350],\n",
      "        [1.5598]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2c/_gzbr1y51ws47zfknhxm868h0000gr/T/ipykernel_61384/3182535233.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(Neg) elbo = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melbo_estimate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Obtain score function estimator of the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mvi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtOU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz0_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm0_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msde_sigma_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimegrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'False'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0melbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mELBO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VI_SDE/vp_class/class_tou.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, t0, t1, z0, alpha, beta, m0, r, sigma, timegrid, dN)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VI_SDE/vp_class/class_tou.py\u001b[0m in \u001b[0;36mpath\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VI_SDE/vp_class/class_tou.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(x, dt, t0, alpha, beta, m0, r)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mb_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mbeta\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m  \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm0\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D = 50\n",
    "S = 100\n",
    "learning_rate = 0.00005\n",
    "lr = learning_rate\n",
    "IT = 1000\n",
    "dN = 200\n",
    "z0 = obs[0]\n",
    "\n",
    "# Linear mean function\n",
    "beta_ = torch.tensor([1.])\n",
    "beta_D = beta_.repeat(D, 1)\n",
    "beta_S = beta_.repeat(S, 1)\n",
    "\n",
    "vp_mean = []\n",
    "vp_std = []\n",
    "vp_pts = []\n",
    "\n",
    "elbo_traces = np.empty((len(obs_time) - 1, IT-1))\n",
    "KL_traces = np.empty((len(obs_time) -1 , IT-1))\n",
    "LL_traces = np.empty((len(obs_time) -1 , IT-1))\n",
    "pars_traces = np.empty((3, len(obs_time) - 1, IT))\n",
    "\n",
    "sde_sigma_D = torch.tensor([sde_sigma]).repeat(D, 1)\n",
    "sde_sigma_S = torch.tensor([sde_sigma]).repeat(S, 1)\n",
    "for t in tq.tqdm(range(obs.shape[0]-1)):\n",
    "    # initilize a set of parameters\n",
    "    alpha_ = torch.tensor([0.])\n",
    "    r_ = torch.rand(1) + 4.\n",
    "    if t > 1:\n",
    "        r_ = torch.tensor([4.])\n",
    "    m0_ = torch.randn(1) + obs[t].clone().detach()\n",
    "    \n",
    "    i = 0\n",
    "    for i in range(IT): \n",
    "        alpha_D = alpha_.repeat(D, 1)\n",
    "        r_D = r_.repeat(D, 1)\n",
    "        z0_D = z0.repeat(D, 1)\n",
    "        m0_D = m0_.repeat(D, 1)\n",
    "        # Compute (negative) ELBO\n",
    "        if i > 0:\n",
    "            vi_ = tOU(t0=obs_time[t], t1=obs_time[t+1], z0=z0_D, m0=m0_D, alpha=alpha_D, beta=beta_D, sigma=sde_sigma_D, r=r_D, dN=dN, timegrid = 'False')\n",
    "            elbo_ = ELBO(vi_)\n",
    "            kl_ = elbo_.KL(prior_drift)\n",
    "            LL_ = elbo_.log_prob(obs[t+1].repeat(D, 1), obs_sigma)\n",
    "            elbo_estimate = -1 * (kl_ + LL_)\n",
    "            elbo_traces[t, i-1] = torch.mean(elbo_estimate).clone()\n",
    "            KL_traces[t, i-1] = torch.mean(kl_).clone()\n",
    "            LL_traces[t, i-1] = torch.mean(LL_).clone()\n",
    "            if i % 50 == 1:\n",
    "                print(\"(Neg) elbo = \", torch.nanmean(elbo_estimate).data.numpy())\n",
    "        # Obtain score function estimator of the gradient\n",
    "        vi = tOU(t0=obs_time[t], t1=obs_time[t+1], z0=z0_D, m0=m0_D, alpha=alpha_D, beta=beta_D, sigma=sde_sigma_D, r=r_D, dN=dN, timegrid = 'False')\n",
    "        elbo = ELBO(vi)\n",
    "\n",
    "        gradient = tou_gradient(vi.pts, vi.trj, torch.stack([alpha_D, beta_D, m0_D, r_D, sde_sigma_D]).view(-1, D, 1))\n",
    "#         print(\"scores = \", scores)\n",
    "        f_of_X = -1 * (elbo.log_prob(obs[t+1].repeat(D, 1), obs_sigma) + elbo.KL(prior_drift))\n",
    "#         print(\"Ito = \", elbo.KL_ito(), \"Rest = \", elbo.KL_rest(), \"LL = \", elbo.log_prob(obs[t+1].repeat(D, 1), obs_sigma))\n",
    "#         print(\"f_of_X = \", torch.nanmean(f_of_X))\n",
    "#         print(\"NLL = \", \"KL_Ito = \", \"KL_rest = \")\n",
    "        \n",
    "#         print(\"scores_beta = \", torch.nanmean(scores['beta']), \"scores_alpha = \", torch.nanmean(scores['alpha']))\n",
    "        m0_grad = torch.nanmean(f_of_X * gradient['m0'])\n",
    "        alpha_grad = torch.nanmean(f_of_X * gradient['alpha'])\n",
    "        r_grad = torch.nanmean(f_of_X * gradient['r'])\n",
    "#         print(\"beta_grad = \", beta_grad, \"alpha_grad = \", alpha_grad, \"r_grad = \", r_grad)\n",
    "\n",
    "        # Update the parameter\n",
    "\n",
    "        m0_ -= learning_rate * m0_grad\n",
    "        alpha_ -= learning_rate * alpha_grad\n",
    "        r__ = r_ - learning_rate * r_grad\n",
    "\n",
    "#             It is to ensure r should be strictly positive (i.e. projected gradient method)\n",
    "        while r__ < 0:\n",
    "            r__ = r_ - lr * r_grad\n",
    "            lr *= 0.5\n",
    "        r_ = r__\n",
    "\n",
    "        pars_traces[0, t, i] = alpha_.clone()\n",
    "        pars_traces[1, t, i] = m0_.clone()\n",
    "        pars_traces[2, t, i] = r_.clone()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"alpha = \", alpha_.data.numpy(), \"m0 = \", m0_.data.numpy(), \"r = \", r_.data.numpy())\n",
    "        i += 1\n",
    "#     Compute posteiror mean (based on posterior sample)\n",
    "    posterior = tOU(t0 = obs_time[t], t1 = obs_time[t+1], z0 = z0.repeat(S, 1), m0 = m0_[0].repeat(S, 1), alpha = alpha_.repeat(S,1), beta = beta_S, sigma = sde_sigma_S, r = r_.repeat(S,1), dN = dN, timegrid='True')\n",
    "\n",
    "    \n",
    "    if t > 0:\n",
    "        post_mean_ = posterior.trj.mean(axis=0)[1:]\n",
    "        post_std_ = posterior.trj.std(axis=0)[1:]\n",
    "        post_pts_ = posterior.pts.mean(axis=0)[1:]\n",
    "    else:\n",
    "        post_mean_ = posterior.trj.mean(axis=0)\n",
    "        post_std_ = posterior.trj.std(axis=0)\n",
    "        post_pts_ = posterior.pts.mean(axis=0)\n",
    "    \n",
    "    vp_mean.append(post_mean_.clone().data.numpy())\n",
    "    vp_std.append(post_std_.clone().data.numpy())\n",
    "    vp_pts.append(post_pts_.clone().data.numpy())\n",
    "#     z0 = torch.tensor(obs[t+1])\n",
    "    z0 = post_mean_.clone()[-1]\n",
    "#     print(\"posterior_mean = \", z0)\n",
    "# score.compute_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98123c",
   "metadata": {},
   "source": [
    "Trace plot: ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20, 13))\n",
    "t = 0\n",
    "for ax in ax.ravel()[:-1]:\n",
    "    ax.plot(np.arange(len(elbo_traces[t, :])), elbo_traces[t, :])\n",
    "    ax.set_xlabel(\"iteration\")\n",
    "    ax.set_ylabel(\"Negative ELBO, dt = %d\" % t)\n",
    "    t += 1\n",
    "    \n",
    "plt.suptitle(\"Trace plot: (Negative) ELBO\", size=15, y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be7be2",
   "metadata": {},
   "source": [
    "Trace plot: KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3126db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20, 13))\n",
    "t = 0\n",
    "for ax in ax.ravel()[:-1]:\n",
    "    ax.plot(np.arange(len(KL_traces[t, :])), -1 * KL_traces[t, :])\n",
    "    ax.set_xlabel(\"iteration\")\n",
    "    ax.set_ylabel(\"KL, dt = %d\" % t)\n",
    "    ax.axhline(0, color='red', linestyle='dashed')\n",
    "    t += 1\n",
    "    \n",
    "plt.suptitle(\"Trace plot: KL divergence\", size=15, y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d3c74",
   "metadata": {},
   "source": [
    "Trace plot: NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16035f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20, 13))\n",
    "t = 0\n",
    "for ax in ax.ravel()[:-1]:\n",
    "    ax.plot(np.arange(len(LL_traces[t, :])), -1 * LL_traces[t, :])\n",
    "    ax.set_xlabel(\"iteration\")\n",
    "    ax.set_ylabel(\"(Negative) Log Likelihood, dt = %d\" % t)\n",
    "    t += 1\n",
    "    \n",
    "plt.suptitle(\"Trace plot: (Negative) Log Likeilhood\", size=15, y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73d0e2",
   "metadata": {},
   "source": [
    "Trace plot: parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5803cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=pars_traces.shape[1], ncols=3, figsize=(20, 30), sharex='all')\n",
    "names = [r'$\\alpha$', r'$m0$', r'$r$']\n",
    "for j, ax in enumerate(ax.ravel()):\n",
    "    i = j % 3\n",
    "    t = j // 3\n",
    "    ax.plot(np.arange(pars_traces[i, t, :].shape[0]), pars_traces[i, t, :])\n",
    "    ax.set_title(names[i] + \" at time interval: %d\" % t)\n",
    "    if t == 5:\n",
    "        ax.set_xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8025155",
   "metadata": {},
   "source": [
    "**Posterior approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b463f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_mean = np.concatenate(vp_mean)\n",
    "vi_var = np.concatenate(vp_std)\n",
    "vi_pts = np.concatenate(vp_pts)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(true_sde_pts, true_sde_trj, label=\"underlying SDE\", alpha=0.4)\n",
    "plt.plot(obs_time, obs, 'rx', label='observations')\n",
    "plt.plot(vi_pts, vi_mean, color='black', label='variational mean')\n",
    "plt.fill_between(vi_pts, vi_mean + vi_var, vi_mean - vi_var, alpha=0.3, color='grey', label='variational std')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title(\"Variational Approximation: time-inhomogeneous process with linear mean function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EX03_DW-SDE', 'wb') as f:\n",
    "    pickle.dump(true_sde_pts, f)\n",
    "    pickle.dump(true_sde_trj, f)\n",
    "    pickle.dump(obs, f)\n",
    "    pickle.dump(obs_time, f)\n",
    "    pickle.dump(obs_sigma, f)\n",
    "    pickle.dump(sde_sigma, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
