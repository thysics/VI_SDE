{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591c0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "from functorch import vmap\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043b84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'vp_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de3b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_ou import OU, ou_gradient\n",
    "from class_tou_v4 import tOU, tou_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b69b9",
   "metadata": {},
   "source": [
    "This code applies variational inference based on time-dependent OU processes to the observations drawn from the double well system SDE, as defined below. Note that we have chosen observational noise, i.e. variance of Gaussian noise and SDE variance to be 0.64 and 0.01 repectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22728a",
   "metadata": {},
   "source": [
    "m(t) = $\\alpha$t + $m_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6d11b",
   "metadata": {},
   "source": [
    "1. Simulate prior process, i.e. double-well system whose SDE is given by\n",
    "\n",
    "$dX_{t} = 4X_{t}(1-X^{2}_{t})dt + \\sigma dW_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1791ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EX03_DW_Model', 'rb') as f:\n",
    "    prior = pickle.load(f)\n",
    "    likelihood = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8faa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_drift (s, x_s):\n",
    "    return 4 * x_s * (1 - (x_s ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bd214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sde_pts, true_sde_trj = prior[0], prior[1]\n",
    "obs, obs_time = likelihood[0], likelihood[1]\n",
    "sde_sigma = 0.8 # Variance is higher than the original example\n",
    "obs_sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ca55c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEbCAYAAADNr2OMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABMfElEQVR4nO2deXxcdbn/309mJpM9adN0pwtQylJallJkpyxSEK2it4IXRfQniOLliogVBRVQEXGHC6IsIigWFRGobBJka6GlG4VSutB9S5fsyUxm5vv745wzObMlM8kkM0me9+uVV2bOnJnzTTvnfM6zizEGRVEURUmXglwvQFEURRlYqHAoiqIoGaHCoSiKomSECoeiKIqSESociqIoSkaocCiKoigZocKhKH2MiDwoIk/leh2pyPf1KfmHCocy4BGRGhH5PxHZJCIBEdktIv8WkXNzvbZ8QkQmiYgRkZm5XosysPHmegGKkgX+BpQAXwTWAyOBM4DqXC5KUQYranEoAxoRqQJOA+YbY/5tjNlsjFlijLnDGPOoa79LRWSJiDSJyB4ReUxExrleP9O+Gz9fRN4SkTYReUVExovIGSKyUkSaReQpEal2ve9Be9t3bUunWUQeEJHiLtYsInK9iGywj/O2iFzazd/Z7XFEZI695gMisl9EnhWRI1wf84H9e4n9t74Ud4xrRGS7/f4HRKTE9drpIrLYPm6DiLwhItO6WrMyeFHhUAY6zfbPx0SkqIv9CoHvATOAC4ERwJ+T7PcD4H+BE4FhwF+Am4ArgDOBo4Dvx73nDPtzzwY+CXwY+EkXa7kVyzr6KnAk8GPgtyLykS7ek85xSoFfArPstTYAT4pIof36LPv3HGAMcJHrvacB04BzgE8DnwCuARARL/AE8Kp9/BOBXwHhbtarDFaMMfqjPwP6B+siuh9oBxYBdwAndvOewwEDjLefn2k/P8+1z9X2tuNc274PrHY9fxCoB8pc2y4FAkCpa5+n7MelQBtwWtx6fgks7GK93R4nyXtKsS7up9rPJ9l/z8wkn70V8Lq2/Q54wX483H7fGbn+v9af/PhRi0MZ8Bhj/gaMBT4K/As4GVgsIjc4+4jIcSLyhIhsFpEmYKn90oS4j1vlerzb/v123LaR8e8xxjS7ni/CsnAOSbLcI4Ei4Bnb7dMsIs3AVSn2T/s4InKIiPzJdoE12mstSPI3JuNdY0zI9XwH9t9pjNmPJS7PisjTInKtiByUxmcqgxQVDmVQYIxpN8Y8b4y52RhzMnAf8H0RKRSRUuBZoBX4LHAClrsGrAuvmw73x9qfHb+tN+eN896PAse4fo7Ccj31hieBGuBKLHfSsUCIxL8xGR1xz2P+TmPM5fZnvgx8DHhfRM7r5XqVAYpmVSmDlXexvt9FwBSsmMYNxpgPAETkoi7emylHi0ipMabFfv4hIAhsSLGuADDRGPNito5jB+yPAL5qjKkFy8oi9hwP2r89GR4XAGPMSmAl8BMR+RdwGZYgK0MMFQ5lQGNfMB8D7sdyMzUBM4HrgX8bYxpFZAvWxfpqEbkL6wJ7SxaX4QXuF5GbsVxmtwG/c13goxhjmkTkDuAOERGsO/gyLBGIGGPu7clxRKQN2At8SUS2AuOAn2JZHA57sOIr54nIJqDdGNPQ3R8nIpOxrJh/AtuBg4HpwN3dvVcZnKhwKAOdZmAxVgbQoYAf6+L2J6zsJYwxdSJyGfAjrEymVcC1wDNZWsN/gHeAWqx6kr9hCVcqbsSKP1yHdfFtBFYAt/f0OMaYiIh8Gvg1sBqrnuUb9j7Y+4RE5H+wssS+B7yClRTQHa3AYVgCPcJe+yN0nTmmDGLEGJ0AqCg9RUQeBEYYYy4cDMdRlHTQ4LiiKIqSESociqIoSkaoq0pRFEXJCLU4FEVRlIwYEllVI0aMMJMmTcr1MhRFUQYMb7311l5jTE2y14aEcEyaNImlS5d2v6OiKIoCgIhsTvWauqoURVGUjFDhUBRFUTJChUNRFEXJCBUORVEUJSNUOBRFUZSMUOFQFEXpCbffDrW1sdtqa63tgxwVDkVRlJ5wwgkwb16neNTWWs9POCG36+oHhkQdh6IoStaZPRsWLLDE4qqr4O67reezZ+d6ZX2OWhyKoig9ZfZsSzRuucX6PQREA1Q4FEVRek5trWVp3Hij9Ts+5jFIUeFQFEXpCU5MY8ECuPnmTrfVEBAPFQ5FUZSesGRJbEzDiXksWZLbdfUDQ2Iex8yZM402OVQURUkfEXnLGDMz2WtqcSiKovSC2vf28LuXN+Z6Gf1KXgmHiNwvIntEZHWK188UkQYRWWH/3NTfa1QURXFz+YNL+OHCNexubM/1UvqNvBIO4EFgTjf7vGKMOcb+ubkf1qQoipKSQq91GX13R2OOV9J/5JVwGGNeBvbneh2KoijpUuzzALCnSS2OfOYkEVkpIv8SkaNS7SQiV4jIUhFZWldX15/rUxRlCOFYHHsaAzleSf8x0IRjGTDRGDMD+A3wj1Q7GmPuNcbMNMbMrKlJOjZXURSl17QHwwDsaVLhyEuMMY3GmGb78ULAJyIjcrwsRVGGKOGIoSkQAqDZ/j0UGFDCISKjRUTsx7Ow1r8vt6tSFGWo0tjWEX0cDEdyuJL+Ja+644rIn4EzgREisg34HuADMMbcA3wKuEpEQkAbcLEZChWMiqLkJQ1u4QipcOQEY8wl3bx+J3BnPy1HURSlS9zC0TGELI4B5apSFEXJJxzhEBlaFocKh6IoSg9xhKOmzK/CoXTNvuYArcGhk0GhKEpyGtst4agu86urSuma4299gYv+7/VcL0NRlH7iwdc+YNYPXyASic3FaQ1YNRzDSnwE1OJQUuF8cd7b1ZTjlShKfvH+7iamfvdfbN3fmuulZJ3vP/kue5oCCSm3bR2WcFQU+WIsDmMMTe0dDFZUODJkX0sw10tQlLzkkcWbCYQiPPfu7lwvJYoxhpN//G/+/OaWrHxevFXRGgxT6CmguNATIyqvb9jH0d9/jlfX7c3KcfMNFY4M2dUwdBqZKUq6NAdCLFy9CwC/N38uKwdaO9jR0M63//52jz/D7Z4KhMIxr7UFQxQXeij0FMQExzfUNQNw7yuDc05H/vwPDxD2t6rFoSjxfO1Py6izezUVevLnsrKjvg0An0d6/Bl7Wzp7UAU6Ei2OkkIPPq/QEe4UmLAtNtsGodsOVDgypmUI9aNRlHR544POaQiBPMou2m4Lh9/r6fFnuLveJriqOsK2xeGJsTia2q3rxK5BOtxJhSNDBlojs1+9sI5nbBeCovQVrcFOF04+3Vztt2OSxhh2N7Zz7V9W0BYMd/OuWPY2u4Uj3lXVaXG4YxxOYLytI8xg7IqkwtEFW/a1Mmn+07zpuptyTgrpueUbQyRi+NHCNWze15KdD4zjFy+8z5cffqtPPltRkpFPwuEIWkswzE+eeY+/L9/O02/vzOgz3G1FEoPjIUp8Xvx2jMMRicY269/AGGjvyB8LLFuocHTB4o1W492/LNka3eacFAVZUo7N+1u59+WNXPFQ7y/utWv3cM7P/xM1meNzzhWlP8gnq7zNVaj79CpLMB55Y3OC5dAV9a0u4YgTgeZAiFK/h6JCyxXmCEtToPM9LYOwWFiFowt8Xksc3PnZzXbBTzhiogGw3uDcoWQjzfe7j69m/Z5mdtt+VcfPmoxIxHDxvYvUjaVknVxaHMYYnlm9M3rz5HahORf15VvqmfrdZ9J2IcUIR5zg7KxvZ3RlMaWFVr9Y529vCXTu1xrIzDU2EFDh6ALHqogVjs4vUXMXF+Z0iZrSWTjZnBGWp91ey+9f2cgBVwaY29wGaAqEWLxxv7qxlKzgzqRqCYb52XNrWbm1nr++tY0HX/ug39bx6vq9fPnhZfz8+fcB6/wqL/Jy3ISqhH2dwHl31Ld1nkduV9Xr6/eyryXI2MoiSmyLwzmfncJAsCyO+tYgM37wXIzbeyCjwtEF7fZ/viMcoXCEp1Z1+kfjL8a9OYb7i9ZT3CfvrU+viRGOLz20NGbfQBaOpygOfl/nd6+pPcRvXlzP3Lte47rHVvL9J9/tt3U41oFTve4EryuKfQn7phuzbnBZHH9fto3P3vcGf31rGzc/Zf1dVaWFlPoti8MRjvaOMJ4CsbeFWLRhHw1tHfwuSV3H29saqF27J82/MD9Q4egCx9x08rM37m2hvrWDkw6uBnovHNsOtPLa+uwNMCyMK7xym9hvfrA/pnhxMAbslNwhwKeOH8+sycOpz2Gtk+MliNiq0BIMUVLopbwoUTja07x5amjroKLIEoZn39nNK+v2ct1jK6PH+NRx4ym2LQ4nntEWDDO8tBCwxGSv7YoeUVbIyq31bNrbmQzzfy+t53tPvJPx35pLVDi6wHEf/ef9Oi65dzHv7GgA4ILpY4DMhKOxvSOh7fLH73qdX7zwfpZWS/QOx8GxOK468xAgNq0wGxaOojh0hA3DSwupKPKyrzmXwmH9di7qbcEwxT5PUldwujdP9W0djKooStj+/u5mJo8opbjQE41xOPGMto4w1bZwbD/QxvItBwAYVlLI3Lte48w7Xoqej82BUDRteKCgwtEFLa7A2qKN+9hRb92xHz2uEshMOKZ//zmu+GOsu8h9IYfEwFumlBfFDnR0LI4Z4631uoPlKhxKtgiFI7R1hPF5hFK/N8ZF2t+IbXE4YUmnsnv7gcR4Rnua51t9azCpcADR2EZJEoujuswSjvl/f5u/L9sOxBYEOllercEwzYHQgJrnocLRBfF3KT99di0AYyutL9GjS7aw7UBsS4FIxPCH1zfxkstn6WRvvLS2LmbfQ2pKY57v7eWdWnxhU31rkAKBsVXFADHdOtM10xWlO77yyDIAfJ4CSv3emEym/sYpwnPOOaey+4gx5Qn77m8Jcsm9i3lvV2PKz1u/p5kNdS1UJomRQKdgODGOlkCIZ1bvpDkQoqqkMGH/dbubo4+boxlY1u9cuvgyRYWjC1JlOtWU+wF4Zd1evmqfNA6vb9jH9/75Dp9/YEnUgnDf3W+vb+PC37zC7sZ2qkv9Me/d2xRrgWRKfP78U6t2Ulnsi37pU1kcg7GyVek/nG64Pk8B7VkSDWMMtWv3ZPzddJI+Ol1VIUoLvfzwE0cn7Ltowz4WbdzHTV3EF/64aBMAa3YmF5di20U1uqKIQk8BP3vufb788DICoQjDShLFxu2S+umza2ls74ieiwdaB04bdhWOLkhVuCOu4r/4u6vdLlPUafrmTtu988X1rN7eyIIlWxMu9L018VuDYWYcVBV9vnFvC1UlhZTZd0Pu47UnyW9XlN7QEY5w1hEjo88vOnZc9HGmxaiPL9/O5Q8siSm+TQfnu+wcznFVlfq9CTFAJ5De1TTPMba1nkx4AEp8lsVRXOjh2AlVMSm+w5JYHPGxjJuffDeahNPbOMeO+rZ+uwlU4UjG7bdDbW1MEc9Jm1dx5Rt/ZdmN5wJw938fByR+Odz/+bvt5mhNrgv2v1Zbfs2/L99OazDEx2aMpfa6M4HeC0dLIMS0sRX8fN6M6LaqEh9lduwjxlUVUuFQek8g7nv0kaPHRJ9/ZPoYvjXncICEAUjdsce+6Vq3p7mbPePX4wiHIRIxNLR2RDOelt14bjRgDYnFejc8/naCB8Fx/544eXjS4zmuKoBJ1bGu52SuqvjY4oGWYFS4MnVVvfje7mj33637Wzn5thf5QT+lPqtwJOOEE2DePCavfpPTpozg2Rkh7nziNj6YdGQ0xe78o8dw4fQx7GmK7X7prgDfst9KuXNbHE61+Qd7W9i0r5VSv4fh9hdsf0vvTNWWYIgyvzdqYYAlbH6vh3K/l52udNy2YOeJ3NugvDJ02byvM8YX6IjEWOOF3oLobI5MY2rOefLujtTxh2Q432Vj4Oan3qUpEKLYtgoqi328eN2ZLLjyJKCzsM+xxP/0xpaEPlZtHWGKfAUUFCRvMVTi7xSOccOKY14bUZYoHMlwxCTTkQ1feHApJ9/2Ipc/8Can3V4LwIOvb+qX+GVeCYeI3C8ie0RkdYrXRUR+LSLrRWSViBzXJwuZPRsWLOAbv7+Ri5/8PYf9z//j+e/9ms/Mvyxmt3HDitm0r5XV2xuiRYL7mgOUF3kp93v5+l9W8vPn349xEcW3AalrClJeZJnR+1t6HuMIRwztHRFKCr14XbMHqmw/61HjKnjkjS1RU9ptfcT331GUdPm/2vXRx8Fw7AXL7/VQ5Ivt4ZQO4YiJJqIs2riPUAbWipNiG4pEePD1TQnHriz2ceTYCgAO2DdqdU0BnlixPbrPfa92Vrq32nUgqRjusiqcJBSHmjJ//O4J7GsJRgsRD2TgqnL/m9TGJd30x7C5vBIO4EFgThevnw9MsX+uAO7us5XMns3jJ36Ujzzxe+Sqq7j4W5dx5tSRMbscMqIMgAt/82q0InR3U4DJI0o5+VCrSPDX/17Hf//+jZj3OVlZAEeOraCgQKgp80ddWz3BiceU+j0xA2XKbevj1ENHAPDWZiuf3J1KnKkbQVEc3N9Z5wbEcd+4LY5Mbk4a49Lc2zMQHcfiaO+IRDtYxye5lPg8iMSmw1/z6Iro41ueejd6I9hq14GkotglKmOrYlN2R5R3Ckd5kZd5M8cnvH/F1vro40yC4139m2Sjo0V35JVwGGNeBrpq5jIXeMhYLAaqRGRMF/v3nNpa5i5+kpfmXQl33w21tQm7zHL5PbcdaCMQCvPy+3WMqSxKmr7n3P0fNrqcF79xBo9/5WSuOXsKAOOHFUfbJPQEp/Co1O9lxvgq1zGtO6JLPzQR6Mzcqnd9ud7f1dTj4yqDm2Aowgd7U7f8bwp0RN23R9v1Qk7cz+8tiFocrR3p92KLv/C1BcP84fVNPLVqB4s37usyAOwIlDs1vSlOOAoKhHK/N5q8kgzHBdcWDEdjJA6/ueRYLpk1AYgdkzuuKt5V1SkcP/zE0Uyz679SkYnF0dVMkbl3vcYDfdwfLK+EIw3GAe40i232tgRE5AoRWSoiS+vq6pLtkpraWpg3j+9c/F2WffHrsGABzJuXIB6TRpSy/ofnA9YX6ON3vQ5Y9RjJhMOpLp01eTgH15Rx7IRh0UyP8cOK2ZakSCldHIujpNDD6Moi3r35PO659Pho1XhlsQ+fR6iz77Lc/Xe+9uflPT6uMrj52p+XMfuOl6IztONpbg9x6qEjePEbZ/BZ++bE+e6HwoaRFdbFMxNr2hGOKSMti769I8z3/vkOV/9pORffu5g/Lt6c8r2OW6qtI8xI+47/6CQX7IpiX4KguHHm4zhZWW7KirxRr8Fol/fA/fib502NCipAkbeA0a4iQifO4ubvy7dz1cNvpeWaSxbH+MIpk6OPf/Dku31aUDjQhCNZhCrp7Ycx5l5jzExjzMyamprMjrJkCSxYwN33Xce1H54ajXmwZEnCrl5PAWMri3jzg/3RXO8vnTY5qXA4c49HJPF9Th1dwfb6ti7vgrrCMccdcSop9DJn2ujoHZ+IMKLMH/38hrYODrYLEI+fOKxHx1QGN0s27efZd6wajVTWcHMgRHmRl4NryqKB8S+cal3ARlX6GW8HjOMLZbvCEY5TbPdq/EXyhTWpGwIGXE1Dx1QWM6ayiK/OPjRhv4okvavcOLHItiSuKr+ngCvPOIRfXXwM508b3bndNZ72K/YNm0ORzxOtJAfr5vHN75ydcNx/rd7Fkk0HUq7rj4s28bn73+S9JF6CiuLYWIw7jpltBppwbAMOcj0fD+zI+lGuv94SCzezZ1vbk1Be5Iup35gzbUxSP6PThLAqiag4bi+3zzMTnMytsqLUgbyqksJoG5L6tiATh5cw46CqqLgoikPte3v4r3sWRZ+nqjFobA8lfOc+dfx4PvjxBYwsL2JUeRE+j6RtTb+zo4GNtnXjtPko+/XPOWnzqrgF1lpp83E4FkdrIMSKrfUcNbYioX4DYgctfePcwzjniNj4pWPBN7Z3RDvrOjd+Pm8Bhd4C5h4zLiaLzI2z3Tl0kc/D8LiC35HlRdFiYjepYo6BUJgbn3iHl9+vS+h2DSTcrPZlrGOgCcc/gc/Z2VUfAhqMMZnNgewDKoq90XYhD31hFkBCIB3AW2ALR5L8bqfKNJO5HM+s3skv7SaJjtkd36/KTbnfy476NvY2B2ho66CqpJASn6fLAihlaLKjIfZCn6xxYSAUJhiKJL17j144C4ThpYXsd71/1bZ6Vm9vSHrcj/z61Wgb9tGV1kX12o2F3PnEbVHxOOK9pZbr+IQTou/bUNfMz59bG7VOnD5zqcIhW/d3/n1Xn3VoNP33+jlTrffb59P+lmA0c8rp9OAeX9AdjrVSHGdxOHiTiFpbivPRGUfr5ua5R0Uff/L42OB7YxbmBaUir4RDRP4MLAKmisg2EfmiiHxZRL5s77IQ2AisB34HfCVHS43BrfROZsUph47gpguPjNnPaYNQ6k+8w3cCcJk0H/zyw8v45QvrCEdM1LQu96c2wcuKvLy7s5GZt75AfWsHlcU+Sv2emEJHRYHEC9reJKniUSvXn/pmBaCquJC1u5u4/9UPMMbwsTtf48LfvNrtGhyLY9HE6Vw9dz53PnEbX3/lYb5693cs17HLK/DNx1by6xfX825ca5AvnX5w0s++/ZPTo49FhLMOt270zjvKcj01B8IYY6hv7aCq1DqnHOsg0kVw/nefm8nVLteYk3VV5CuIZjj+z1mdrzvW0Pc/2nmtSFXP1ZjE9TSy3LneVCcIeF82m8wr4TDGXGKMGWOM8Rljxhtj7jPG3GOMucd+3RhjvmqMOcQYc7QxJtFeywHuLKayLi7cR421gnTJ4h/OnUlX2RKp2LK/lWb7S9WVq6rUdYI3tYeoLPZRUuhVi0NJwFMQe2lIdrfr1Cd1JxyVJT5WbK3n5qfeZUNd6gwtN35vQcx5smjidB4+9gKuef1RFp46F2bPZkd9W7TDrDNvY2dcDcPE6pKknz/n6NExzy/90ERW/+A8Dqkpo6TQQ2sgREswTDAciVocjriUdvH3nnvkKK47b2r0eXGh9e/o9RQgImy67SNW3NTGiQGdfcSo6LZkF/yX1u7h7J/9B4C5x4yNbq8uK+Tu/z6OOy+xStrc1tDlDyTGZLNFXgnHQMWp2YDYC7dTaORw68enseDKkxg/LPHL7MQZ0m31DJ13K7PveClqlnZ1EpfFWTpVJbbFkcNupgpc8+hy/vTGlphtrcEQtzz1bo+TJXpLfDeBZDcXUSu3i5sViI3pNbSlvgt2p9lWFvtiUl1P2ryKS5cv5FcnX8ycV/4BtbV84cElfPVPy/i/l9bHxArcySepLvLlcdtFJHrulBR6aQ6E2GkXyzrpxdecPYVn/vc0DhuV2Gk3FR+abF0binzJL7V3feY4fvLJozloeOc1Yd3uxMD3510i4M7OOmxUOecfPYZhdgbXq/Nn8+TVp6a9vp6iwpEFjhzTme5X4go0f+jgahZ9+6zo8+JCT0zthxu/twARMuouWupKE9xR34bfDtqlIr56N2pxZGHeudIztte38cSKHdzw+Nsx7WuOvOlZ7nv1g2h31v6mNc59mcyd2ZRGQgZ01i8B7HGl5YbjGh+6g8KVxb6o6+Wkzau484nbuHrufH5x2qXccPF3Yd48hr3xGgC3P7M2JpZx/MSq6OPSFFXfIsIZh9Xw3Y8ckfBaKBLh0SVbufzBJYjASYdYF/+CAuHw0RUJ+3fFrZ+Yxj+vPoUxlcVJX68u8/PpEybEbPvHih3Uvpc6c8wRycNHlyd4L0aWF3H0+Eo+c6L1ma+sy7AUIU1UOLJAcaGHz5w4gRkHVSX0tBlTWcy4quKYu6dkiAjFPk9GMQ733dSmfS3d3vltiGsYV13mp7TQsjjiT2Klf9joqo849+cvs7uxPSb/vjqNthV9QXxn6GQWh+Oq6iquBp1+eIjtHn3r07EN+dwdDyqLfYysKGLJd87hMwW7uXrufC78389w+SmTeHnc0bBgAbP2boju7447uNNik2VUOfzhC7P4f6clxkBm2unp2w60UV3qj7EGMsXv9TDd5cruCiexBqxU6FQcUmPVtxSkyOiyXrN+f/a+N9M6dqaocGSJH33iaJ746ilJX3vxujNY+b0Pd/sZmQpHyHWx37yvNelcZTff+UhssH50RVE01TC+xbvSP7hbcTS0dfCZ3y2OaYWRq4Fb7nEBlcW+pO5Mp06guxuWSSM6u8a6e7U98NqmmP3cgulkHtaU+1nz2S+zaOJ06poCVJcW0hwI0XbK6fxm5iei+7vnZaRyC6XLbz87M1oZXlnc9d+WTU4/rLPeLF4UnIaJf/7Sh6KFhQVd/JkNSWJS2USFox9wN3vriiKfJ6ZrbXe4XUw7G9q7DVLOmjyc2y7qnCswuqIo6g6obw3qQKf+wm7bD53uGadt/4a6Fk6+7cXorpmkZ2cT93GHlxYmdWdGg+PdCMdkl3C4W90caleGO3S4XFXu9udOIeBho8qjbpoNdc1ETGebD3dBnN/r4cypNQlxjHTxFAhH2hMD+7uPm6MX9QmxIOGSWRM46ZDqaMVzVxbH1FFlKV/LBioceUSRryDtO8xIxNASDHPZSROjqZPdCQfEtkWoKPZGq03P+OlL/OL593uwaiVj7Lb91NYSDEWiPvxVow9L2LU5C6nS+5oDvLFxHx/sbUk7a89tcQwvLUw6DtZpW9OdxXGUK0nEnTEUDEVYv6eZi/7vNRraOmIsjo5I5+NTDh3Ba/PP4vxpo6Nur7W2UHzx1M42Gw4lhR4evHwWb//gvC7X1RUT7dkae5v6d5zrS9HZPJ0CG4kYDrQGGW6nBR8xppzZU2v4sesmMJ4vn3EIP583g8e/cnKf3BCqcOQRpX4vT7+9M9rBtiscl9bYqmLOtqteu7vzAzjjsBpeuPZ0nv/66YhITO73/XGuA6Vv2DjtBDbcdT/Mm8eUu27nzidu4xufuoFFE6fH7DeizJ8Vi+Njd77Gp+9dzOw7XuIrj7zV5b6O+8l93GElhUmnYe5rCVLm98bEFJJR5PNEh4s5MY6R5X627G/lpidWs2xLPf9eszsmeSP+BmpcVTEiErU43rczjw6uKY3pNg3JC2wzxelvlYnrOBtMrC7l8NHlURFtau/gur+uJBwx0cpzv9fDA5fPiqb3J8PrKeCi48Zz7IRhKavbe4MKRx7hBPg+effrvLR2T5cZEZ1t1L3RyWPpmOYiwqEjy5lipxRWuLIykrU/ULJLJGI462f/4exlBQS/dCVH3fdrHj72AubfflXMft88byoVRV6as1Bj4x5nGj+7wc1r6/dy9PefY9GGfTEWxriqIhraOmIK0DrC1ryL+M6xqbjouPHUlPt5bf0+AD5hj5V9fYP1vDkQinFVffO8w5N+jpOh5RT6ja4soqgwMc28twwrLeTMqTXc/qnp3e+cZfw+D8FQhAMtQW78x2r+vsyaFeJ23+UaFY48IuTKKvn8A0sSMyJcvnEnPXLiqjc4+8k/WO/vQWaU2+Loy26aioUT+D5p8yrkt/ew7LKruXT5QsaviJ3Z8snjxlNW5I2ZHtkTMpn1/fqGvQAs23IgemPiKRDOmFqDMbBqa2ebkH+vsZofZlJn4mQWlvu9HDEmNq11b1Mg+v2777KZMXERN04G14ot9RSINa41vglhsl5wPeHBy2cxb+ZB3e+YZfyeAva3BLnl6Xf5x4rOVnzpinR/oMKRR3R0F4hz+cZbAiFO2ryKE+dfReXpJ1HoLeDUKSMyPqa7o6bbLP9gb4sGy/uA/a3BaExjzS9/x6LLruHqufMp/exnYhr5VZcVUlnsiwkm94Q7XRP6usO5cfEUCK2BMOcdNYoNP7qAqXbtgrvDbXEXU/FS4QhHcaGHj0wfExOf2LK/NRqI7qoWyXHHNgVCjK0qpsjnSYi/JOvMMJDw+wp4e3tD1NIAqwXM9PFdz/PoT1Q48ohvuloVJMVp7z5vHlW33cKdT9zG+7++j6mXzGXtLXN6dHfkDqg7wrV8ywFm3/ESD8dVMyu9Z39LkOm73ufqufPZcexJBEMRFk2cjnn0L0zf1Zmc4PMUMKykkPpe9hv6+7JtCdve2LgvIYbQ0NrBvfYUS48IrR2dI1MdF8m+ltjANqTxnXVRaMdCSv1efJ4CbnT1ctt6oI0O+zN9XTQR9BRItPDVqeh214YA0SrqgUr8tESfR1j/owtSFhEm4PJMREnRTbinqHDkEXOmjUnaoz+G2bPhqqsYf+fPePjYCwidcSZAjwNgXtdJGuiw/Kob7X5Cy9II0iupefadXby0NrYCeH9LkN+e+CkWTZzOC2t286t/rwOg4OyzmPvIrwD4uN2LaFiJL6OpcMmIn4MN8Ol7F/Pdf6yO2fav1Tuj1dcFtsXhDDAq8nkoKfTEtFZ3hOfDR44iXRyLwz0Y6W9Xncyk6hK27G8lkIbFAZ19qRxrOd7imDKyb1NR+5r4mqpXv3VWij1T4PJMANHBdO5uwr2l/6pblLQY1l1GSG0t3H03vzr5Yi5dvpC2N1+Dgz6SlWMHwxGOveV5JtmN4brqAqp0TXMgxJV/tDKYvjXncH7yzHvc//mZMULw17dirYEjx1aw6bbO/8uqkkIa20OEwpEYgc+ElmCYqhJfdA6Lw6vr9sY8d198Q+EIzYFQTGeC4aWFSYUjk1kujnC424AcP3EYH50xlrtq10eLA1O1CXEoL/KyqzGxYv0Xn57B/paOHv9b5QvxLutRFUUp9kyByzPBVVdZo6/jugn3loH9LzwI8XkKqHCl1cbEGZw7hwUL+MVpl3L13PmMufLzSeeh94ZN9rxl7ULSc5Zv6bTWfvLMewB84cGlGdVlODNaejqQ519v72Tl1vqY7s0O++NcYO7mmo3tHQRCkZgsverSwhhXVbvtVvJnUKXtd2ZTxAV5q0sLiRjYbM827y4rysn+cyyOu//7OD77oYl84tjxSes6BhrdxjrTwfZMcMst1u8sigaocOQl7lnFMY0J7ZG2zJ5Nmd9L08mn4nks+UjbbKAWR8/5d4rxppnUBTgumZ62g/mZXdB5oDXIe7fM4bgJVdHX4jPo2l1+9V0NVqaUO1Xbsjg6M6gCvbE44ro0O/24nLnm3QW3Z06yGoU619fzjx7DLR+flvY68h13z65UTVG7xfZMcOON1u8s31yqcOQh7nqKGP+tPdJ2Q10zzYEQp0+p6XKkbbrUXndmwoxkIMU0d6U7Gts7+NMbWzjmoKqE19o7whT5CtKq8ndcRT0VDmc2QzhiKPJ5uODoMTGvu63ZQCiM31vA8NLCaJded0X48FJ/zBS/qKuqm+I/N05QuyTOFeVMxtu4twW/t6BbMZpjD1sarDc2TnbZI//vRB68vAdxCZdngptv7nRbZVE8VDjykINHdAb3mttDbN3fGr0bA6IDXdKpFE+HySNKE2aHwOA9MfuatzYdIBiOMP/8xCK2/6yto6TQy7BS19TIyuQ+bOfOPFm7j3Rw3EhOm5H4C3Zje4hX1+3liRXbCXRE8HsLKCn0RAsG3TU+1WWWq8oYw7rdTdzxnGXNOHO408GpfI63KJz5Equ3N6SVSnvk2Ap+97mZ3HBBYkv0wYDjqjpsVHnC/1lauDwTQGfMI4ueCQ2O5yE3XHAE6/Y0sWxLPQdag8y9y5o74A6cQnqV4ukSX0QFqec1K13jBJHHJkmfXLu7iUJPAYePLo/Ovf7H1cm7KvfW4nCa4DnusXgXUV1TO5feZxUeXjLrIIp8HkZVFEVb3sS7qgKhCC3BMPe/9kF0eybZfD6vtW98gZ4z2Cxi0nd9nZtBNtdA47CR5by5aX/SEdNpkcwDMXu2BscHO5UlPr5r57jHt9h2VwJny+KA5CKRyTRCpROnaK8yRZA3GI5ER4YW+Qpi5lW4cdxZmfarWrG1nsUb90Xff8+lxwOJFoe7xXl7RwS/ryAmfdftqnJSXBdt2BdtAJgpToFhfNaTO/02K4HhAc5vP3s8D3/xxJ5ZG/2ECkee4sw5/uIfOseqb9nfGhNc7W6ATiYcYbuq3EVZO1w9jpTuaQ2GuPWpd7nlKWtAUVcW4dxjrF5NycYIOzj1DpkKx8fveo2L711MSyDEyYdUM8OOtZTEZTO5LZlAKEyR1xPjNnOnhp9hz4r40kNLeeFdq93It5O44rrCaYHuiKYbJxtKrVyrgLEnXSD6k/yVtCFOsurXQEckRjiyaXGMqyqOusIunD6GLz20lPV7mjHG9El3zcHIfa98wO9f7XTjxE+DdHPKoSN49Vuz8XYxjafT4kjP8qtrCsQEvJduPsCnXd0E4vs/uQWpsS2E31eQ4J5ycFsJSzcfwOcRrjwjSUJFF1x28iTGDytO6mY676jR3Of6t1PyGxWOPKUiiSgEw+GYeQrpZOb0hFEVRXxsxlhufXoN9a0dA76FQ3/x9vaGhG1Pfe1Uth1opabczyfvXhTzWlfWBnS6lrqzOLbub2XZlgNc8+gKptpdjx0+OmNs9LHjhpo+vpJV2xpiXFWvrt/LiDJ/NMYg0nUFd0/cKJ4C4cN2RlQ8Tu2G0VS+AYEKR57ivsv/r+PH89hb2wh0RPjGgpXR7d0N0OkNzkyDxnYVjnRZt6eZEycP56LjxjFhuHV3P21cJdPGVaY9QMlNobeAQk9Bt63VL7r79WiX2rW7m2JeGxfnFlr3w/NpbOvg+FtfSBCkvc2BaK1Fdzcl8W6v3lLaRzdBSt+QVzEOEZkjImtFZL2IzE/y+pki0iAiK+yfm3Kxzv7GuTNtDYZ50zXEvq8sDugUpaZetvUeKhhj2Lq/lWMnDOPTJ1gjPt0UF3q4/ZPTeeDzJ3Tfj8xFqd9Dazeuqq5am4+Oa1fh8xREXZzx2Vr3XTYzaT8p9+vuz8kmo8r9nH5YDb+++Nisfq7SN+SNzIuIB7gLOBfYBiwRkX8aY96N2/UVY8yF/b7AHDKqwsp/390U2wU0mzGOeFQ4MqMpECIUMdHxnsmYd0Lm3YtL/d5eTQFMNsPB7/VQ6C1gb3Ns25GzDh/JU6t2AiSNvZx9xCiOm1DFsi31bNnfmvB6b/B6CnjoC7Oy+plK35FPFscsYL0xZqMxJgg8CszN8ZryAqeSfF/cid7dyM7e4GRsNbX3bh7EUKG+xfp36rZJZYaUFnp7VMdx8iHV/OriY1K+PnF4CQvf3hmzTUSiFocnRWDfmc3hZFkpQ5O8sTiAccBW1/NtwIlJ9jtJRFYCO4DrjDHv9MfickmncFguies+fBifPH58nx6zPIU7Q0nOAbtpYNaFw+9h/Z7mLvcpkMSGlL/97PHRXlfJOGx0OU+v2pmw3WlEmEo4vvfRI7nqjEOYUN11YF8Z3OSTxZHsmxqfYrEMmGiMmQH8BvhHyg8TuUJElorI0rq61HOWBwIj7CZwTnfS4ycOT3+oSw9RV1VmLLWrrYd14arqCcu21LNxbwu17yVvmgidFeJuumtNnqrNSVE3FkeRz6OioeSVcGwD3E7g8VhWRRRjTKMxptl+vBDwiUjSShljzL3GmJnGmJk1NQPbrHYyTpwq8r7MpnKoKPbhKZBowzslNbsa2qNFf9Wl/m727hnP2zO+k5GsXqSrGhLo7LwbLxCOxeHt5v3K0CafhGMJMEVEJotIIXAx8E/3DiIyWuw8VRGZhbX+ff2+0n7CaSDn+J0Xb7Qyqvoym6rz2AVMGF7Cpr3ZDYIORna5RpeOqcpw6E43/P5zViZTVyNke3KRd24+PHHWivM8mRWjKA55E+MwxoRE5GrgWcAD3G+MeUdEvmy/fg/wKeAqEQkBbcDFxgzeJgUvXz+bfc3BaHtsh77MpnIzqbqEjfZwHSU17pnX2U5YOOfIUcycOCxhgp+bURVFfJDh/5PT+TZiDOceOYrZU0cCEDZOPykVDiU1eSMcEHU/LYzbdo/r8Z3Anf29rlwxprI4aSyjup8K8kZXFrF6R2O/HGugEY4YfvrsWr5w6qSocHQ3ua6nVBb7YqwaN1//ywo+2NvCfx0/ntMPq+Frf16e1mc6FocBfve5zvoM57t10sHVyd6mKECeCYfSPd+ac3i/9Y4aVlLIAXsGg/ariuWVdXXc858NbN3fymF2m4+l3zmnT45VWeLjvV1NSV97fPl2wLI6MqnmdmIc4bh0rIOGl/DCtWdE584rSjLyKcahpEF/zlQeXlpIKGJo1MyqBHbU2xaAQGtHiEJvQUK78GxRVVzY7dzxEr8nabFfKg6usVqifPyYzl5W3H471NZy6Miyzr+lttbariguVDgGCEfZbc+7ajyXbZzuqM5gIsWiIxzhhsffBqxxqG3BcNZ7N7mZMLyY5kCIVdvqU+5z6qEjMsroGlVRxJLvnBM7q/uEE2JHjDojSE/owfhSZVCjwjFA+MuVJ/Ha/LP69ZjDVDiS8ur6vdHHwVCENTsbk05QzBbn27PCV26tT3htysgyzj1yFNPHVzE2w4yumnJ/bJGgM2J03jy46abOudVZnBynDA5UOAYIZX5vdBBOf1GtwpGUxRs6M8D/sWIHSzYdyMhNlClONfrflm1nV0NskLw1GI5mSHVVKZ42s2fDVVfBLbdYv1U0lCSocCgpcS5YB1Q4YkjW4C8Y6ruRp457csXWer77j9Uxr7UEQzGzqc87ahTfmpPZZL4Yamvh7rvhxhut347bSlFcaFaVkpLqMks49qlwxBAIRZg2roINe1qiExn7a8xufPy9NRCOGar028/OpMc4MQ3HPTV7trqrlKSoxaGkpNjnwe8tiDbwUyyCoQh+ryemXUd8k8G+osLljgqGIgTDkewF5pcsiRUJJ+axZEl2Pl8ZNKjFoaRERKguLUxo5z7UCYTC+L0F/do5+MypNby0to5W1yTBt+zGilNGlmXnINdfn7jNsTwUxYVaHEqXDCstVIsjjkAoEu0fBlba8k0XHtmnx3zw8llMG1fB02/v5Ft/XQVYMQ+AU6Yk7fOpKH2GCofSJcNLCzXGEUcwFImpp3n8KyfzhX4ozCzxWQ6Cvyy1xtZsr2+lqsQX475SlP5AhUPpkkBHhJVb61m0YdA2Ic6YgB3jcOjr2SgO8Sm/O+rbGdtPx1YUNyocSpes3W31SPrnyu05Xkn+EOgIx7iq+qua390uzBjD2l1NTNSeUkoOUOFQuuT+z1vpneoO6SQYjvRr6xeHQEdnrcjmfa1sr2/j5EM1vqH0P5pVpXTJ8ROHM66qmLqmQK6XkjcEOixX1SvX92+20aEjy1i00XIZbtxrzSE/ckxFv65BUUAtDiUNRlb42aPCAUB7R5imQAi/r4CDhpdw0PD+cxXNP7+zIvwLDy4FYEI/Hl9RHFQ4lG6pKfPr7HGbHy1cA8C2A/1TKe6m1O/lm+dNjT4v8hUwoqx/hnopipusCIeIqAANYtTi6GTNTmsiYjAU7mbPvuGi48ZFm0/6vR4dsKXkhG4v+CJyl4ikzPkTkSOBxVldlZJXjCwvor61g0COLpb5RIF9ob5l7rRu9uwbxlQWc6s9Q6OlHyvXFcVNOpbCOcAqETnJvVEsvgUsAzb2xeKU/GBkuTUgSAPkcKA1yJyjRjOyIrPZF9lkgp2CG+qvBlmKEkc6wnEM8AzwHxH5sYj4RGQqsAi4DrjMGHNxH65RyTE1KhxR2jr6dtpfOkysLs3p8RWlW+EwxrQZY74GnA98BliNZWXsAqYZY/7St0tUcs3IcuvuWuMc0BYMU5Rj4Sjze6kuLeTacw/L6TqUoUsmdRzvA5uAU4FW4G5jzO6+WJSSX4yssCwOFQ5LOEr6cExsurx147m5XoIyhEkrG0pEPo9labQChwC/BJ4UkXtERO3mQU51aSEFArsbhnZKrjGG1jxwVSlKrkknq+oJ4NfA9caY840xm4wxNwKnAKdjBc5Py8ZiRGSOiKwVkfUiMj/J6yIiv7ZfXyUix2XjuErXeD0FjK0qZuuBxJGpQ4lAKIIx5NxVpSi5Jh2LowqYYYz5rXujMWYJcCzwT+DfvV2IiHiAu7BiKUcCl9ipvm7OB6bYP1cAd/f2uEp6TKwuYdPellwvI6e02UOU8sFVpSi5JB3hONMY80GyF4wxAWPM14Gzs7CWWcB6Y8xGY0wQeBSYG7fPXOAhY7EYqBKRMVk4ttIN08ZWsnJbA2t3NeV6KTmj1Z4vHt/eXFGGGulkVXWbLG6MeSULaxkHbHU932Zvy3QfAETkChFZKiJL6+rqsrC8oc2njh8PwDs7GnK8ktzR1N4BQHGh9gZVhjb51CokWe+EeNFKZx9rozH3GmNmGmNm1tTU9HpxQx2nmV8uejTlC8+9YyURHjG6PMcrUZTckk/CsQ04yPV8PLCjB/sofUCRz8PIcj/bhnCAfNO+FsZVFTNllAqHMrTJJ+FYAkwRkckiUghcjBV4d/NP4HN2dtWHgAZjzM7+XuhQZUSZn/1DeP74/pYg1dqNVlHyZ5CTMSYkIlcDzwIe4H5jzDsi8mX79XuAhcAFwHqsmpLLc7XeoUhViY/61o5cLyNn7G8JMqxEhUNR8kY4AIwxC7HEwb3tHtdjA3y1v9elWFSV+Hh/d3Oul5Ez9rcEObSmLNfLUJSck0+uKiXPqSwupKFtiFscpWpxKIoKh5I2VSU+Glo7SCNDe9DR3hGmNRhmuAqHoqhwKOkzosxPMBwZkgHyffbfXK3CoSgqHEr6TBlp+ffX7Rl6cY4DtnCoq0pRVDiUDJgyyhaO3UOv7YhaHIrSiQqHkjajK4oo93uHZGaV026kvMiX45UoSu5R4VDSRkSYMqqM94egxRHoiABQ5NNTRlH0LFAy4rBR5UMyxhEIOcKhnXEVRYVDyYgpo8rZ3xJkb/PQGiPbbrdU93v1lFEUPQuUjDhoWDEAO+uH1hhZx+Lwe9XiUBQVDiUjnHTUA61Dq5YjELIsjkK1OBRFhUPJjGElVlZR/RBrPfLkSqt7v6cg2UgYRRlaqHAoGVFZbFkc9UPI4th2oJUNdUN73rqiuFHhUDKiyrE4hlB7dScwriiKhQqHkhE+TwEVRd4hlVXV1B7K9RIUJa9Q4VAyZvywErbuHzojZFU4FCUWFQ4lYyYML2GLCoeiDFlUOJSMGVtVzIa6Fj7/wJuEwpFcL6fPcfpUfe2sQ3O8EkXJD1Q4lIypLrMyq15aW0fdEIh17Gywih2/dPrBOV6JouQHKhxKxrhbiw/G7KoVW+t59p1d0ecL397JjIOqqNDOuIoCqHAoPcBdPT0YK8g/ftdrXPnHt6LPdzW0c+xBVblbkKLkGSocSsaU+r3Rxw2DzOJwWos4tHeEaQqEqCn352hFipJ/qHAoGXPuEaP4+jmHAYOv9cgl9y6Oee7Uq4wo08l/iuKQF8IhIsNF5HkRWWf/HpZiv00i8raIrBCRpf29TsWioEC48gwrULxvkAXHl22pjz7eur81OrRKLQ5F6SQvhAOYD/zbGDMF+Lf9PBWzjTHHGGNm9s/SlGQU+TwMK/Gxo2Hwtlc/7fZa/vX2LiqKvHzo4OpcL0dR8oZ8EY65wB/sx38APp67pSjpMqaymJ31bbleRtaIREzCtm0H2phQXUJJoTfJOxRlaJIvwjHKGLMTwP49MsV+BnhORN4SkSv6bXVKUsZWFbN9EAlHczCxQnxHQxvDS9VNpShu+u02SkReAEYneek7GXzMKcaYHSIyEnheRN4zxryc4nhXAFcATJgwIeP1Kt0zdXQZtWv30N4RHhSzuJNliO2ob+P4CUlDbooyZOk3i8MYc44xZlqSnyeA3SIyBsD+vSfFZ+ywf+8BHgdmdXG8e40xM40xM2tqarL/BylMG1tJOGJYu6sp10vJClsPWP235s0cH93WETYML9WMKkVxky+uqn8Cl9mPLwOeiN9BREpFpNx5DHwYWN1vK1QSmDauEoB/rNjO1X9aRjA0sPtWLbczqk6cHBsId2aQKIpikS/CcRtwroisA861nyMiY0Vkob3PKOBVEVkJvAk8bYx5JierVQAYP6yYYSU+HnhtE0+t2hlNXR2oLN9ygINrShk3rDhme5lfA+OK4iYvzghjzD7g7CTbdwAX2I83AjP6eWlKF4gIFxw9hkfe2AIM/El5K7c1cPqUmoRivzLtUaUoMeSLxaEMUNx35/tbBm7fqo5whLqmABOGlzCiLDaLSi0ORYlFhUPpFeWuu/GB3PBwX7O19hHlhVQWx1oYFUUqHIriRoVD6RXlrrvx/S0Dt29VXZPVOqWmzI+IxLzmKZBkb1GUIYsKh9Iryl134y2BgTtita7Zap0ywu5JtejbZ0VfK1VXlaLEoGeE0isKXHfnAzk43hKw1u7EM8ZUFrP21jm8vn5fNO1YURQLtTiUXmHo7O/UHhq4whGwa1CKvJ0V8H6vh9mHp+p+oyhDFxUOpVecemgNnzlxAiLQ3pF+AeB3Hn+bB1/7oA9XlhnOACe/T08JRekOdVUpvaLQW8CPPnE0izbsS9tVtaO+LVr78flTJvfl8tLGET23xaEoSnL09krJCn5vQdoWx0d/82ofryZz1OJQlPTRs0TJCkU+T8K87lTsy1Gh4JMrd7AuRVsUR/T8Xj0lFKU79CxRskKRryBtV9XxE6025cX92Ir9vV2NfO3Py5n/97eTvh4IhSn0FiTUcCiKkogKh5IVinyetF1VjsB0hCMYkzh1L9sYY/jKw8sAaAsmF7dAR4QitTYUJS30TFGyQrHPk7bF0dhuVZiHIobWFBfybLK3OcjGvS0AFBcmt3ICoTD+QTCMSlH6AxUOJSsU+Txp13E0toUosoPQ9W1936akI9xpCaXqHhLoiETXpChK1+iZomQFK8bRvauqIxyhsb2DSdWlQPJxrdnGbQk5FeIJ+4TCmoqrKGmiwqH0nttvZ+q7b8W6qmpr4fbbE3bd1dCOMXD46HIAGvrB4mhzC0cweT+txraQ9qRSlDRR4VB6zwknMO+n3+CYdcut57W1MG8enHBCwq476tsAOGJMBQANbX2fmutYQuV+b8pGjFv2t3LQ8JI+X4uiDAZUOJTeM3s2C2/8Jb98/MdEbrzREo0FC2D27IRddzZYXWg7haPvLY6AbXEcMrKMxvZQQiZXKBxhe30bE1U4FCUtVDiUrLD3hFN4+NgLKLj1Vu6cei5PVU9Nut/2OIujvh9iHI6ramxVEcFQhLaOMO0dYbYdaAWsyYXhiGF0ZVGfr0VRBgMqHEpWmLTqDS5dvpBfnXwxlyx7mk2PPZV0v50NbVQW+xhRVoi3QPrF4nBcVWMqrTG3B1o7uHbBCk79SS3hiImmB1cU62xxRUkHjQYqvae2ljNv+hqXz53PoonTWTxhOr/71bfgrCkJ7qqd9e2MrSpGRKgs9vWTcFgWxxjbojjQEuTF9/YA0NweoqHNinvoiFhFSQ+1OJTes2QJS39yN4smTgdg0cTp3P2VH8OSJQm7bq9vY6x9Aa8s8cXUcby6bi9ffWRZ1qvJnfqSsVWWxbG/JYjfTr39xmMr1OJQlAzRWyyl91x/Pc2rd8LGZdFNSyfPgCtPSth1Z0M7MydZvaoqi300uoTjsgfeJBwx3NI6jeGlhVlbntNmJGpxtAajzQxfWLOHF9ZY1kdFkQqHoqSDWhxKVmhqt9w9H5sxlrMPHxl97qYlEKKhrSN6519V7IsGx9uCYcIRy9J4ae2erK7NKfobP8zKmjrQEqQwSV+qimK9j1KUdMgL4RCR/xKRd0QkIiIzu9hvjoisFZH1IjK/P9eodI0jBnOmjaa8yEtTIDF2UdcUAGBkuXXnP7zUz367xfqP/7Umut+1C1ZmdW3NgQ5KCj0MLy1EBPa3diQXDrU4FCUt8kI4gNXARcDLqXYQEQ9wF3A+cCRwiYgc2T/LU7rjlENH8Nr8s7jg6DHUlPvZ0xhIaHroxBKq7FjCiLJC6poDPLRoEw8t2hzdz31R37S3heff3d2rtTUHQpT5vXgKhKpiHwdaggRDie1RirTJoaKkRV4IhzFmjTFmbTe7zQLWG2M2GmOCwKPA3L5fnZIu42yr4+RDRhAIRXhhze6o+wk6i/0qosLhJxiKcNMT78R8Tomrg+2Zd7zElx5a2quAeVN7iDI7Y6qi2McfF29m24G2Hn+eogx18kI40mQcsNX1fJu9LSkicoWILBWRpXV1dX2+OKWTQ0eWAXD1n5Zzx3Od9wN/fWsb0BlLqC5LHgBvaOsgFI61CPbYbq6e0BwIUW73ofK62uOOrtCCP0XpCf0mHCLygoisTvKTrtWQrCF2yttQY8y9xpiZxpiZNTU1PVu00iNqyv3Rx8+9syv6+IkVOwArmwo6BSYeYyzxcLdDP+322rSP3xGO0NTeYTVZrK2l2WVxHLthBVe+8deEdSqKkj79lkZijDmnlx+xDTjI9Xw8sKOXn6n0Ae5YQbKOs04QetrYSsZWFnHZyZM4f9oYdjW2s72+la//ZSUHWoN4XNZBsphEKn749BoefH0Ty06dwfB585j8X9+h8aRTobaW7z70fa766LcAKNeCP0XpEQPpzFkCTBGRycB24GLgM7ldktIdJUkm7jnbCgqE1799dnT7hOoSXl1nCcS63c3UvhfrYgyGIkmzoeJZsNTyaK6acixnLljADRd+guV7L4bav/Gjy77PovIpQGwQ/rQpIzL8yxRl6JIXwiEinwB+A9QAT4vICmPMeSIyFvi9MeYCY0xIRK4GngU8wP3GmHe6+Fglh5QWemgJhqM1FMYYRODq2YcikmIMHzCs1LJGrnqks5jwtCkjeGXdXva1BKL9ptKhvSNMx+ln8NAx53PNY7+FG29kdfXxsLMRsMTp5W/OZuuBVk45VIVDUdIlL4LjxpjHjTHjjTF+Y8woY8x59vYdxpgLXPstNMYcZow5xBjzw9ytWOmOx796CgBvb29g5dZ6OsIGY4hWbKciWcX4+GGWWKTT1yoYikTnmLcGwzQufI5Lly/k7S/8D9x9NydvWRXdd3t9GxOqS1Q0FCVD8kI4lMHHYaPKo4837WuJ9ovqrlZiWEmicIy1rYzuxsy2BkP8zJXFVb7oFSo/fylXz53Pjmu/DQsWcMMfvs9Jm1d18SmKonRHXriqlMFNkc/DVQ+/BYC/G+Eo8nmoKPLS6GpZ4kzmc7Zt2dfKyAp/gggdedOzMc/Nm0t471e/Z9FqH9cU+2D2bAoeW8B9ry3ir2cfxYmTq3v9tynKUEQtDqXPaWjt4LX1+4DuXVWQ6K5yrJeGtg6MMZz+01qu/ONbKd/vdN+9YszZbJ5+IuDKoJo9m5Lv3sDnTprE1NHlqT5CUZQuUOFQ+pzdje3Rx+kIR1Wcu2pslSUE9a1BAnZa7n/er+PDv/hPTGW6wxdPOzj6+KYnVgPah0pRsokKh9Jn/Oua04DYqu9AR/f1GP9z9qExzyuLfUwYXsILa3bH9L96f3dzNGDuVJpXlfiYN3N8dJ99dhNFFQ5FyR4a41D6jMkjSgHY09RpcTQHEtutx3PW4aNYe+scPtjbQqAjgohw/tGjeeDVTTS2xb7/QGuQ4aWFtNuWyFVnHEJ5EpEo02I/RckaejYpfYbfW0CBxFock0aUpPleD4eProg+nzG+imA4wspt9TH7rdnZyC1PvUtNmdU+xAmYT6wuYfO+1uh+7ip0RVF6hwqH0meICKWFXpZvqQfgVxcfw1mHj+rRZznT++K72l79p+Uxz4t8lvf1f86awjces+Z6zDioqkfHVBQlORrjUPoUZ8ATWFZDT3HqO3Y1WMLxvY8mH8XiWBzudiI3f+yoHh9XUZREVDiUPmXauMro49GVPW9j7gjHm5sOAHBITVk0huLG77WEw+cpSHivoijZQYVD6VOOGmvFKb546uReTdgrL7Im+K2x+0yV+j18dPqYhP0cV1WhtzOmkWruh6IoPUNjHEqfcvGsg1i3p4kvnjq5V59TYI99ddJr/V4Px00clrCfI05uiyNZh15FUXqOWhxKn1JS6OXHF02PiXX0FPdsD0+BcObUkfzlig/FDIRyRMItHF1141UUJXNUOJQBQ7HL1eW4n048uJoXrj0jur2q2NqeztwORVF6hp5dyoCh2LYmLj9lEiPLkwfaq+x5HoUe/WorSl+hZ5cyYHDEoKssqXLbneW4qpxguaIo2UPPKmXAEDFWQ8Nkc8wdnHiGz2P9TtZ+RFGU3qHCoQwYHOEo8ydmScXHv52uueXao0pRso6eVcqAocke5FRd6k947Y0bzqYt2Nk514mBfPmMQ/pncYoyhFDhUAYMTg2HMxHQTXywvLLEx6bbPtIv61KUoYa6qpQBx/hhva8JURSl56jFoQwYHvl/J/Lqur1dBscVRel79AxUBgxHjKngiDEV3e+oKEqfkheuKhH5LxF5R0QiIjKzi/02icjbIrJCRJb25xoVRVEUi3yxOFYDFwG/TWPf2caYvX28HkVRFCUFeSEcxpg1oM3oFEVRBgJ54arKAAM8JyJvicgVXe0oIleIyFIRWVpXV9dPy1MURRn89JvFISIvAKOTvPQdY8wTaX7MKcaYHSIyEnheRN4zxrycbEdjzL3AvQAzZ840PVq0oiiKkkC/CYcx5pwsfMYO+/ceEXkcmAUkFQ5FURSlbxgwrioRKRWRcucx8GGsoLqiKIrSj+SFcIjIJ0RkG3AS8LSIPGtvHysiC+3dRgGvishK4E3gaWPMM7lZsaIoytBFjBn87n8RqQM29/DtI4B8TP/VdWWGriszdF2ZMRjXNdEYU5PshSEhHL1BRJYaY1IWJeYKXVdm6LoyQ9eVGUNtXXnhqlIURVEGDiociqIoSkaocHTPvbleQAp0XZmh68oMXVdmDKl1aYxDURRFyQi1OBRFUZSMUOFQFEVRMkKFIwUiMkdE1orIehGZn+v1OIjI/SKyR0TypmpeRA4SkVoRWWPPVbkm12sCEJEiEXlTRFba6/pBrtfkRkQ8IrJcRJ7K9Vrc5OvcGxGpEpG/ish79nftpDxY01T738n5aRSR/831ugBE5Ov29361iPxZRIqy9tka40hERDzA+8C5wDZgCXCJMebdnC4MEJHTgWbgIWPMtFyvB0BExgBjjDHL7LYwbwEfz/W/l1h9+kuNMc0i4gNeBa4xxizO5bocRORaYCZQYYy5MNfrcRCRTcDMfJt7IyJ/AF4xxvxeRAqBEmNMfY6XFcW+bmwHTjTG9LTgOFtrGYf1fT/SGNMmIguAhcaYB7Px+WpxJGcWsN4Ys9EYEwQeBebmeE0A2N2A9+d6HW6MMTuNMcvsx03AGmBcblcFxqLZfuqzf/LiTklExgMfAX6f67UMBESkAjgduA/AGBPMJ9GwORvYkGvRcOEFikXEC5QAO7L1wSocyRkHbHU930YeXAgHAiIyCTgWeCPHSwGi7qAVwB7geWNMXqwL+CVwPRDJ8TqSkfbcm37kYKAOeMB27/3ebnaaT1wM/DnXiwAwxmwH7gC2ADuBBmPMc9n6fBWO5CQbRZgXd6r5jIiUAX8D/tcY05jr9QAYY8LGmGOA8cAsEcm5e09ELgT2GGPeyvVaUnCKMeY44Hzgq7Z7NNd4geOAu40xxwItQD7FHguBjwGP5XotACIyDMtLMhkYC5SKyKXZ+nwVjuRsAw5yPR9PFs28wYgdQ/gb8Igx5u+5Xk88tlvjJWBOblcCwCnAx+xYwqPAWSLycG6X1Il77g3gzL3JNduAbS6L8a9YQpIvnA8sM8bszvVCbM4BPjDG1BljOoC/Aydn68NVOJKzBJgiIpPtO4mLgX/meE15ix2Evg9YY4z5ea7X4yAiNSJSZT8uxjqZ3svpogBjzLeNMeONMZOwvlsvGmOydjfYG/J17o0xZhewVUSm2pvOBnKerOLiEvLETWWzBfiQiJTY5+fZWLHHrNBvEwAHEsaYkIhcDTwLeID7jTHv5HhZAIjIn4EzgRH2DJPvGWPuy+2qOAX4LPC2HU8AuMEYszD1W/qFMcAf7GyXAmCBMSavUl/zkFHA49a1Bi/wpzyae/M14BH7Zm4jcHmO1wOAiJRgZWBemeu1OBhj3hCRvwLLgBCwnCy2H9F0XEVRFCUj1FWlKIqiZIQKh6IoipIRKhyKoihKRqhwKIqiKBmhwqEoiqJkhAqHoiiKkhEqHIqSI0TkJRG5M9frUJRMUeFQFEVRMkILABUlB4jIg8BlcZsnG2M29f9qFCUzVDgUJQeISCXwL6zeWTfYm+uMMeHcrUpR0kN7VSlKDjDGNIhIEGi1G/gpyoBBYxyKoihKRqhwKIqiKBmhwqEouSOI1bZfUQYUKhyKkjs2YY2znSQiI0REz0dlQKBfVEXJHXdgWR3vAnXAhNwuR1HSQ9NxFUVRlIxQi0NRFEXJCBUORVEUJSNUOBRFUZSMUOFQFEVRMkKFQ1EURckIFQ5FURQlI1Q4FEVRlIxQ4VAURVEy4v8Dpkc48KwlT44AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot paths\n",
    "plt.plot(true_sde_pts,true_sde_trj)\n",
    "plt.plot(obs_time, obs, \"rx\")\n",
    "plt.xlabel(\"t\", fontsize=14)\n",
    "plt.ylabel(\"X\", fontsize=14)\n",
    "plt.title(\"Sample paths\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f40f9",
   "metadata": {},
   "source": [
    "Variational inference: KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff800a",
   "metadata": {},
   "source": [
    "2. Implement Variational inference based on $\\textbf{time-inhomogeneous}$ OU process with SDE:\n",
    "\n",
    "$$dZ_t = [-r(Z_t - m(t)) + m'(t)]dt + \\sigma dW_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6d84b",
   "metadata": {},
   "source": [
    "$$\\mathbb{E}_{P^{Z}}[\\log\\exp{\\frac{dP^{X}}{dP^{Z}}(Z)] = \\frac{1}{2}\\mathbb{E}_{P^{Z}}[\\int_{t_{0}}}^{t_{1}}|\\frac{4Z_{t}(1-Z^{2}_{t}) + r(Z_{t}-m(t))-m'(t)}{\\sigma}|^{2}dt]$$\n",
    "\n",
    "where the relevant functions\n",
    "\n",
    "$$m(t) = \\alpha (B(t, \\beta) - 1) + m_{0}$$\n",
    "\n",
    "$$m'(t) = \\alpha \\beta B(t, \\beta - 1)$$\n",
    "\n",
    "$$B(s, \\beta) = (s + 1)^{\\beta}$$\n",
    "\n",
    "The mean and variance of the process have a tracatble expression: $E(Z_t) = m(t), Var(Z_t) = \\frac{\\sigma^{2}}{2r}(1-e^{-2rt})$\n",
    "\n",
    "Here we consider a variational process with a $\\textbf{linear mean function}$, i.e. $\\beta = 1$, which results in $m(t) = \\alpha t + m_{0}$. Our variational parameters, thus, include $r, \\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063c5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBO:\n",
    "    \"\"\"\n",
    "        ELBO with\n",
    "            variational process (q): time-inhomogeneous OU process\n",
    "            prior process (p): double-well system\n",
    "            \n",
    "        This class computes: - KL(q|p) + NLL(y|z)  where z \\sim q\n",
    "    \"\"\"\n",
    "    def __init__(self, ou):\n",
    "        self.ou = ou\n",
    "        self.alpha = ou.alpha\n",
    "        self.beta = ou.beta\n",
    "        self.r = ou.r\n",
    "        self.sigma = ou.sigma\n",
    "        \n",
    "\n",
    "    def KL(self, prior_drift):\n",
    "        \"\"\"\n",
    "            This function requires the function corresponding to prior drift function\n",
    "        \"\"\"\n",
    "        # Save parameter specification from ou class\n",
    "        alpha, beta, r, sigma = self.alpha, self.beta, self.r, self.sigma\n",
    "        m0 = self.ou.init_state\n",
    "        \n",
    "        def B(s, beta):\n",
    "            return (s+1) ** beta\n",
    "        \n",
    "        def m(s):\n",
    "            return alpha * (B(s, beta) - 1) + m0\n",
    "            \n",
    "        def m_(s):\n",
    "            return alpha * beta * B(s, beta-1)\n",
    "        \n",
    "        t = self.ou.pts - self.ou.pts[:, 0].reshape(-1, 1)\n",
    "        \n",
    "        # Evaluate the drift function of the approximating processes\n",
    "        g_of_x = -r * (self.ou.trj - m(t)) + m_(t)\n",
    "        \n",
    "        # Evaluate the drift function of the model (prior process)\n",
    "        f_of_x = prior_drift(t, self.ou.trj)\n",
    "        \n",
    "        # Compute the term inside the KL divergence\n",
    "        \n",
    "        F_of_X = abs(((f_of_x - g_of_x) / sigma) ** 2)\n",
    "        \n",
    "        return 0.5 * torch.trapezoid(F_of_X, x=t).reshape(-1, 1)\n",
    "         \n",
    "         \n",
    "    def log_prob(self, obs, obs_sigma):\n",
    "        \"\"\"\n",
    "            Compute the log-likelihood\n",
    "            likelihood function is normal density N(obs, var)\n",
    "            obs.shape = D * 1 (D: # of sample)\n",
    "        \"\"\"\n",
    "        def log_pdf(obs, z, obs_sigma):\n",
    "            return ss.norm.logpdf(obs, loc=z, scale=obs_sigma)\n",
    "            \n",
    "        return torch.from_numpy(log_pdf(obs, self.ou.trj[:, -1].reshape(-1, 1), obs_sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0859993",
   "metadata": {},
   "source": [
    "**Variational inference: a piece-wise approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d17552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7deb3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_estimate(s0, sK, pars, sigma, obs, obs_sigma, init_dist, M):\n",
    "    \"\"\"\n",
    "        Returns stochastic estimates of the gradient of the ELBO with respect to parameters including\n",
    "            alpha, r, beta\n",
    "        \n",
    "        M: # of Monte Carlo samples\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    assert obs.shape[0] == 1, \"observation must be 1-d torch.array\"\n",
    "    \n",
    "    # Number of time points drawn between s0 and sK\n",
    "    K = 200\n",
    "    \n",
    "    alpha = pars['alpha']\n",
    "    r = pars['r']\n",
    "    \n",
    "    if 'beta' in pars.keys():\n",
    "        beta = pars['beta']\n",
    "    else:\n",
    "        beta = torch.tensor([1.])\n",
    "    \n",
    "    # Reshape every parameter into (M,1) torch.array\n",
    "    ALPHA = alpha.repeat(M, 1)\n",
    "    BETA = beta.repeat(M, 1)\n",
    "    R = r.repeat(M, 1)\n",
    "    SIGMA = sigma.repeat(M, 1)\n",
    "    OBS = obs.repeat(M, 1)\n",
    "\n",
    "    \n",
    "\n",
    "    # Simulate sample path\n",
    "    # Note that z0 = m0\n",
    "   \n",
    "    vi = tOU(t0=s0, t1=sK, alpha=ALPHA, beta=BETA, r=R, sde_sigma=SIGMA, init_dist = init_dist, timegrid = 'False', dN=K)\n",
    "\n",
    "    # Compute the ELBO \n",
    "    elbo = ELBO(vi)\n",
    "    score_func = tou_gradient(vi.pts, vi.trj, torch.stack([ALPHA, BETA, R]).view(-1, M, 1), SIGMA, init_dist)\n",
    "    f_of_X = -elbo.log_prob(OBS, obs_sigma) + elbo.KL(prior_drift)\n",
    "\n",
    "    # Get stochastic estimate of the gradient with respect to each parameter\n",
    "    alpha_grad = torch.nanmean(f_of_X * score_func['alpha'])\n",
    "    r_grad = torch.nanmean(f_of_X * score_func['r'])\n",
    "    \n",
    "    if 'beta' not in pars.keys():\n",
    "        stochastic_gradient = {'alpha':alpha_grad, 'r':r_grad}\n",
    "    else:\n",
    "        beta_grad = torch.nanmean(f_of_X * score_func['beta'] )\n",
    "        stochastic_gradient = {'alpha':alpha_grad, 'beta':beta_grad, 'r':r_grad}\n",
    "    \n",
    "    \n",
    "    return stochastic_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7364214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaGrad( current_pars, current_grad, past_grad, learning_rate = 0.01, smooth_term = 1e-8):\n",
    "    \"\"\"\n",
    "        Perform one-step gradient descent based on AdaGrad with Gradient Clipping\n",
    "    \"\"\"\n",
    "    assert type(current_pars) == type(current_grad) == type(past_grad) == dict, \"Current_grad must be a dict\"\n",
    "    \n",
    "    \n",
    "    new_pars = {}\n",
    "    for key in current_pars.keys():\n",
    "        if key == 'r':\n",
    "            new_pars[key] = current_pars[key] - learning_rate / np.sqrt(past_grad[key] + smooth_term) * current_grad[key]\n",
    "            value = new_pars[key]\n",
    "            while value <= 0:\n",
    "                value = current_pars[key] - learning_rate / np.sqrt(past_grad[key] + smooth_term) * current_grad[key]\n",
    "                learning_rate *= 0.5\n",
    "            \n",
    "            new_pars[key] = value\n",
    "  \n",
    "        else:\n",
    "            new_pars[key] = current_pars[key] - learning_rate / np.sqrt(past_grad[key] + smooth_term) * current_grad[key]\n",
    "\n",
    "    return new_pars\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d6e367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamStep(g_t, m_t, v_t, beta_1, beta_2, t):\n",
    "    \"\"\"\n",
    "        compute bias corrected moments\n",
    "    \"\"\"\n",
    "#     print(g_t, m_t, v_t, beta_1, beta_2, t)\n",
    "    m_t_next = beta_1 * m_t + (1 - beta_1) * g_t\n",
    "    v_t_next = beta_2 * v_t + (1 - beta_2) * g_t ** 2\n",
    "    \n",
    "    m_t_corrected = m_t_next / (1 - (beta_1 ** t))\n",
    "    v_t_corrected = v_t_next / (1 - (beta_2 ** t))\n",
    "    \n",
    "#     print(m_t_corrected, v_t_corrected)\n",
    "    return m_t_corrected, v_t_corrected\n",
    "\n",
    "def AdamGrad(current_pars, current_grad, prev_moments,  beta_1, beta_2, learning_rate = 0.01, smooth_term = 1e-8):\n",
    "    assert type(current_pars) == type(current_grad) == type(prev_moments) == dict, \"Current_grad must be a dict\"\n",
    "    \"\"\"\n",
    "        Perform one-step Adam gradient descent\n",
    "    \"\"\"\n",
    "    new_pars = {}\n",
    "    for key in current_pars.keys():\n",
    "        if key == 'r':\n",
    "            m_t, v_t = AdamStep(current_grad[key], prev_moments[key][0], prev_moments[key][1], beta_1, beta_2, prev_moments['t'])\n",
    "            new_pars[key] = current_pars[key] - learning_rate / np.sqrt(v_t + smooth_term) * m_t\n",
    "            value = new_pars[key]\n",
    "            while value <= 0:\n",
    "                value = current_pars[key] - learning_rate / np.sqrt(v_t + smooth_term) * m_t\n",
    "                learning_rate *= 0.5\n",
    "            new_pars[key] = value\n",
    "            \n",
    "        else:\n",
    "            m_t, v_t = AdamStep(current_grad[key], prev_moments[key][0], prev_moments[key][1], beta_1, beta_2, prev_moments['t'])\n",
    "            new_pars[key] = current_pars[key] - learning_rate / np.sqrt(v_t + smooth_term) * m_t\n",
    "        \n",
    "        # Save moments for next iteration    \n",
    "        prev_moments[key][0] = m_t\n",
    "        prev_moments[key][1] = v_t\n",
    "    \n",
    "    prev_moments['t'] += 1\n",
    "    \n",
    "    return new_pars\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb65c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad_Descent( current_pars, current_grad, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "        Perform vanila gradient descent step\n",
    "        returns dictionary such that dict[\"name_of_parameter\"] = value after one gradient step\n",
    "    \"\"\"\n",
    "    assert type(current_pars) == type(current_grad) == dict, \"Current_grad must be a dict\"\n",
    "    \n",
    "    \n",
    "    new_pars = {}\n",
    "    for key in current_pars.keys():\n",
    "        if key == 'r':\n",
    "            new_pars[key] = current_pars[key] - learning_rate * current_grad[key]\n",
    "            value = new_pars[key]\n",
    "            while value <= 0:\n",
    "                value = current_pars[key] - learning_rate * current_grad[key]\n",
    "                learning_rate *= 0.5\n",
    "            new_pars[key] = value\n",
    "  \n",
    "        else:\n",
    "            new_pars[key] = current_pars[key] - learning_rate * current_grad[key]\n",
    "\n",
    "    return new_pars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "615146f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PostMoment(t0, tT, alpha, beta, m0, r, sigma, vN):\n",
    "    \"\"\"\n",
    "        Returns mean and variance of the approximate posterior process\n",
    "        Here, we \n",
    "        Note: mean and variance have tractable expressions\n",
    "    \"\"\"\n",
    "    # Get time-grid between s0 and sK\n",
    "    \n",
    "    t = torch.linspace(0, (tT-t0).item(), vN+2)[1:]\n",
    "    \n",
    "    def B(s, beta):\n",
    "        return (s+1) ** beta\n",
    "        \n",
    "    def m(s):\n",
    "        return alpha * (B(s, beta) - 1) + m0\n",
    "    \n",
    "    \n",
    "    mean = m(t)\n",
    "    \n",
    "\n",
    "    def var(s):\n",
    "        return sigma ** 2 / (2 * r) * (1 - torch.exp(-2 * r * s))\n",
    "\n",
    "    var = var(t)\n",
    "        \n",
    "    return t, mean, var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeed2c1",
   "metadata": {},
   "source": [
    "**To be added: 1. parameter update history, 2. elbo, KL, and loglikelihood estimate, 3. randomizing initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b5dc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimize(sde_sigma, obs, obs_time, obs_sigma, M, IT, vN, learning_rate, init_state = \"Random\", Linear = True, Optimizer=\"Adam\", beta_1 = 0.9, beta_2 = 0.999, smooth_term = 1e-8):\n",
    "    \"\"\"\n",
    "        vN: # of time points between in each obs interval on which mean of the approximate posterior process will be evaluated\n",
    "    \"\"\"\n",
    "    assert type(sde_sigma) == torch.Tensor, \"SDE sigma must be a torch.Tensor\"\n",
    "    assert type(obs) == torch.Tensor, \"obs must be a torch.Tensor\"\n",
    "\n",
    "    \n",
    "    if Linear == True:\n",
    "        # Two parameters: alpha, r\n",
    "        init_pars = torch.randn(2)\n",
    "        init_pars[1] = abs(init_pars[1])\n",
    "        \n",
    "    else:\n",
    "        # Three parameters, alpha, beta, r\n",
    "        init_pars = torch.randn(3)\n",
    "        init_pars[2] = abs(init_pars[2])\n",
    "#         init_pars = torch.tensor([-0.01, 1., 2.])\n",
    "        \n",
    "    N_of_Pars = init_pars.shape[0]\n",
    "    T = obs.shape[0]\n",
    "    \n",
    "    v_N = T * (vN+1) - vN\n",
    "    \n",
    "    track_pars = np.zeros((N_of_Pars, T-1, IT))\n",
    "    \n",
    "    VP_PTS = np.zeros(v_N)\n",
    "    VP_MEAN = np.zeros(v_N)\n",
    "    VP_STD = np.zeros(v_N)\n",
    "    \n",
    "    # Intialize the state at the first observation\n",
    "    m0 = obs[0]\n",
    "    VP_MEAN[0] = m0\n",
    "    \n",
    "    past_grad = {'alpha':[], \"r\":[], 'beta':[]}\n",
    "    \n",
    "    for t in tq.tqdm(range(1, T)):\n",
    "        s0 = obs_time[t-1]\n",
    "        sK = obs_time[t]\n",
    "        \n",
    "        if init_state == 'Random':\n",
    "            if t == 1:\n",
    "                init_dist = m0\n",
    "            else:\n",
    "                var = 0.5 * (sde_sigma ** 2) / r\n",
    "                init_dist = Normal(loc=m0, scale= torch.sqrt(var).item())\n",
    "        else:\n",
    "            init_dist = m0\n",
    "            \n",
    "        # Initialize a set of parameters\n",
    "        if Linear == True:\n",
    "            alpha, r = init_pars\n",
    "            current_pars = {'alpha':alpha, 'r':r}\n",
    "            beta = torch.tensor([1.])\n",
    "        else:\n",
    "            alpha, beta, r = init_pars\n",
    "            current_pars = {'alpha':alpha, 'beta':beta, 'r':r}\n",
    "\n",
    "        if Optimizer == \"Adam\":\n",
    "            prev_moments = {key:[0, 0] for key in current_pars.keys()}\n",
    "            prev_moments['t'] = 1\n",
    "            \n",
    "        if Optimizer == \"Ada\":\n",
    "            prev_grad = {key:0 for key in current_pars.keys()}\n",
    "        \n",
    "    \n",
    "#         past_grad = {key:torch.tensor([0.01]) for key in current_pars.keys()}\n",
    "        \n",
    "        for i in range(IT):\n",
    "            if i == 0:\n",
    "                print(prev_moments)\n",
    "            if i % (IT/2) == 0:\n",
    "                print(i, current_pars)\n",
    "            # Take gradient descent algorithm based on AdaGrad\n",
    "            \n",
    "            # Obtain stochastic estimate of the gradients based on score function estimator\n",
    "            current_grad = score_estimate(s0, sK, current_pars, sde_sigma, obs[t], obs_sigma, init_dist, M)\n",
    "\n",
    "            # Take one gradient step based on the AdaGrad\n",
    "            if Optimizer == 'Ada':\n",
    "                current_pars = AdaGrad(current_pars, current_grad, prev_grad, learning_rate, smooth_term = 1e-8)\n",
    "                \n",
    "                # Save the current gradient estimate\n",
    "                for key in current_grad.keys():\n",
    "                    prev_grad[key] += current_grad[key] ** 2\n",
    "                    \n",
    "            elif Optimizer == \"Adam\":\n",
    "                current_pars = AdamGrad(current_pars, current_grad, prev_moments, beta_1, beta_2, learning_rate, smooth_term)\n",
    "                \n",
    "            else:\n",
    "                current_pars = Grad_Descent(current_pars, current_grad, learning_rate)\n",
    "                \n",
    "            for key in current_grad.keys():\n",
    "                past_grad[key].append(current_grad[key]) \n",
    "                    \n",
    "            track_pars[0, t-1, i] = current_pars['alpha'].item()\n",
    "            track_pars[1, t-1, i] = current_pars['r'].item()\n",
    "            \n",
    "            if Linear == False:\n",
    "                track_pars[2, t-1, i] = current_pars['beta'].item()\n",
    "            \n",
    "        alpha = current_pars['alpha']\n",
    "        r = current_pars['r']\n",
    "        if Linear == False:\n",
    "            beta = current_pars['beta']\n",
    "        \n",
    "        # Obtain moments of approximating processes (note that their forms are tractable)\n",
    "        vp_pts, vp_mean, vp_var = get_PostMoment(s0, sK, alpha, beta, m0, r, sde_sigma, vN)\n",
    "        \n",
    "        VP_PTS[(vN+1)*(t-1)+1:(vN+1)*t+1] = obs_time[t-1].item() + vp_pts\n",
    "        VP_MEAN[(vN+1)*(t-1)+1:(vN+1)*t+1] = vp_mean\n",
    "        VP_STD[(vN+1)*(t-1)+1:(vN+1)*t+1] = vp_var\n",
    "        \n",
    "        m0 = vp_mean[-1]\n",
    "        \n",
    "        print(\"observation: \" + str(obs[t].item()) + \" variational mean: \" + str(m0.item()))\n",
    "    return VP_PTS, VP_MEAN, VP_STD, track_pars, past_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303e70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0, 0], 'beta': [0, 0], 'r': [0, 0], 't': 1}\n",
      "0 {'alpha': tensor(-0.2577), 'beta': tensor(0.2641), 'r': tensor(0.5515)}\n",
      "{'alpha': tensor(23.2140, dtype=torch.float64), 'beta': tensor(-24.2428, dtype=torch.float64), 'r': tensor(-52.5906, dtype=torch.float64)}\n",
      "100 {'alpha': tensor(-0.5840, dtype=torch.float64), 'beta': tensor(0.4418, dtype=torch.float64), 'r': tensor(10.9534, dtype=torch.float64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████▋                                       | 1/8 [00:12<01:24, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: 0.7418740051633642 variational mean: 0.34542423381636067\n",
      "{'alpha': [0, 0], 'beta': [0, 0], 'r': [0, 0], 't': 1}\n",
      "0 {'alpha': tensor(-0.2577), 'beta': tensor(0.2641), 'r': tensor(0.5515)}\n",
      "{'alpha': tensor(21.7831, dtype=torch.float64), 'beta': tensor(-23.2615, dtype=torch.float64), 'r': tensor(-9.4848, dtype=torch.float64)}\n",
      "100 {'alpha': tensor(-1.4382, dtype=torch.float64), 'beta': tensor(0.9761, dtype=torch.float64), 'r': tensor(11.0083, dtype=torch.float64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████▎                                 | 2/8 [00:24<01:12, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: -0.8564873337841266 variational mean: -0.9114534258842468\n",
      "{'alpha': [0, 0], 'beta': [0, 0], 'r': [0, 0], 't': 1}\n",
      "0 {'alpha': tensor(-0.2577), 'beta': tensor(0.2641), 'r': tensor(0.5515)}\n",
      "{'alpha': tensor(-16.6850, dtype=torch.float64), 'beta': tensor(17.5255, dtype=torch.float64), 'r': tensor(-41.2838, dtype=torch.float64)}\n",
      "100 {'alpha': tensor(0.4957, dtype=torch.float64), 'beta': tensor(-0.4690, dtype=torch.float64), 'r': tensor(10.9396, dtype=torch.float64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████▉                            | 3/8 [00:36<01:00, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: -1.0673319792395932 variational mean: -1.1098979711532593\n",
      "{'alpha': [0, 0], 'beta': [0, 0], 'r': [0, 0], 't': 1}\n",
      "0 {'alpha': tensor(-0.2577), 'beta': tensor(0.2641), 'r': tensor(0.5515)}\n",
      "{'alpha': tensor(-79.5060, dtype=torch.float64), 'beta': tensor(84.1758, dtype=torch.float64), 'r': tensor(-94.5776, dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "vp_pts, vp_mean, vp_std, vp_pars, vp_grads = Optimize(torch.tensor([sde_sigma]),\\\n",
    "                                                      obs, obs_time, obs_sigma, \\\n",
    "                                                      init_state=\"Random\", M=1000, Linear=False, \\\n",
    "                                                      IT=200, vN=200, learning_rate=0.1, \\\n",
    "                                                      Optimizer=\"Adam\", beta_1 = 0.3, beta_2 = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d74cd",
   "metadata": {},
   "source": [
    "The plot illustrates the history of graident value for each parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88f2a7",
   "metadata": {},
   "source": [
    "for key in vp_grads.keys():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_mean = np.mean(vp_grads['alpha'])\n",
    "r_mean = np.mean(vp_grads['r'])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(vp_grads['alpha'], color='red', label='alpha')\n",
    "plt.axhline(alpha_mean, color='tab:red', linestyle='dashed', label=str(alpha_mean.round(3)))\n",
    "plt.plot(vp_grads['r'], color='blue', label='r')\n",
    "plt.axhline(r_mean, color='tab:blue', linestyle='dashed', label=str(r_mean.round(3)))\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Gradient\")\n",
    "plt.title(\"Gradient value history: vanila gradient descent algorithm\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0064e",
   "metadata": {},
   "source": [
    "We set the gradient value to be max(grad, 1000) based on this figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d42e7",
   "metadata": {},
   "source": [
    "Approximate Posterior process; its mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b464d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(vp_pts, vp_mean, color='black')\n",
    "plt.fill_between(vp_pts, vp_mean + vp_std, vp_mean - vp_std, alpha=0.3, color='grey')\n",
    "plt.plot(true_sde_pts, true_sde_trj, alpha=0.2)\n",
    "plt.plot(obs_time, obs, 'rx')\n",
    "plt.title(\"Approximating process / higher-order polynomial mean function\")\n",
    "plt.ylabel(\"X(t)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4ccad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P, T, IT = vp_pars.shape\n",
    "\n",
    "for t in range(T):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=P, figsize=(20, 5))\n",
    "    names = [r'$\\alpha$', 'r', r\"$\\beta\"]\n",
    "    for j, ax in enumerate(ax.ravel()):\n",
    "        ax.plot(np.arange(IT), vp_pars[j, t, :])\n",
    "        ax.set_title(names[j] + \" at time interval: %d\" % t)\n",
    "        ax.set_xlabel(\"Iterations\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9715b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
