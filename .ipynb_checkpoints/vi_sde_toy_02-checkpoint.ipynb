{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from functorch import vmap\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d7a52",
   "metadata": {},
   "source": [
    "**Class: OU processes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OU:\n",
    "    def __init__(self, t0, t1, z0, alpha, beta, sigma):\n",
    "        self.t0 = t0\n",
    "        self.t1 = t1\n",
    "        self.z0 = z0\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.sigma = sigma\n",
    "        self.pts = torch.sort(torch.cat([torch.DoubleTensor(100).uniform_(t0,t1), torch.tensor([self.t0, self.t1])]))[0]\n",
    "        self.trj, self.dt = self.simulate()\n",
    "        \n",
    "    def simulate(self):\n",
    "        \"\"\"\n",
    "            Simulate an OU process on a set of discrete points\n",
    "        \"\"\"\n",
    "        output = np.empty(len(self.pts))\n",
    "        output[0] = self.z0\n",
    "        interval = self.pts[1:] - self.pts[:-1]\n",
    "        for t in range(1, len(self.pts)):\n",
    "            \n",
    "            # if the distance is too small, variance becomes 0\n",
    "            dt = interval[t-1]\n",
    "            \n",
    "            mean = self.alpha + (output[t-1] - self.alpha) * np.exp(-1 * self.beta * dt)\n",
    "            var = np.sqrt((self.sigma ** 2) * (1 - np.exp(-2 * self.beta * dt)) / (2 * self.beta))\n",
    "            assert var > 0, \"variance is negative, var:%.3f interval: %.3f\" % (var, dt)\n",
    "            output[t] = ss.norm.rvs(loc = mean, scale = var)\n",
    "        return torch.from_numpy(output), interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba92c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = OU(t0 = 0, t1 = 10., z0 = 2., alpha = 3., beta = 1., sigma = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vi.pts, vi.trj, 'rx')\n",
    "plt.title(\"OU: alpha = %.2f\" % vi.alpha + \", beta = %.2f\" % vi.beta + \", sigma = %.2f\" % vi.sigma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f40f9",
   "metadata": {},
   "source": [
    "Variational inference: KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBO:\n",
    "\n",
    "    \"\"\"\n",
    "        Given a simulated variational process, compute the gradient of the ELBO. \n",
    "    \"\"\"\n",
    "    def __init__(self, ou):\n",
    "        self.ou = ou\n",
    "        self.alpha, self.beta, self.sigma = torch.tensor([ou.alpha, ou.beta, ou.sigma])\n",
    "        \n",
    "    def KL_ito(self):\n",
    "        \"\"\"\n",
    "            1. Compute the Riemann approximation to integral in KL divergence\n",
    "            \n",
    "        \"\"\"\n",
    "        # Save parameter specification from ou class\n",
    "        alpha, beta, sigma = self.alpha, self.beta, self.sigma\n",
    "\n",
    "        # Obtain integral term (via Riemann approximation, e.g. trapezoid)\n",
    "        func_kl = vmap(lambda z: 16*(z**6) - 32* (z**4) + (16-(beta**2) - 12*(sigma ** 2))*(z**2) + 2*alpha*(beta**2)*z)\n",
    "\n",
    "        return torch.trapezoid(abs(func_kl(self.ou.trj)), x=self.ou.pts)\n",
    "    \n",
    "    def KL_rest(self):\n",
    "        \"\"\"\n",
    "            2. Compute the rest\n",
    "        \"\"\"\n",
    "\n",
    "        alpha, beta, sigma = self.alpha, self.beta, self.sigma\n",
    "        z0 = self.ou.z0\n",
    "        z1 = self.ou.trj[-1]\n",
    "        t0 = self.ou.t0\n",
    "        t1 = self.ou.t1\n",
    "        \n",
    "        # Obtain the rest \n",
    "        term1 = 1/(2*(sigma)**2) * (alpha**2 * beta**2 + (4+beta)*sigma**2) * (t1-t0)\n",
    "    \n",
    "        def A(u):\n",
    "            return u**4 + ((4+beta) * u**2 / 2) - (alpha * beta * u)\n",
    "\n",
    "        term2 = -1 / (sigma ** 2) * (A(z1) - A(z0))\n",
    "\n",
    "        return term1 + term2\n",
    "    \n",
    "    def log_prob(self, obs):\n",
    "        \"\"\"\n",
    "            Compute the log-likelihood\n",
    "            likelihood function is normal density N(obs, var)\n",
    "        \"\"\"\n",
    "        def log_pdf(obs, z):\n",
    "            return ss.norm.logpdf(obs, loc=z, scale=.1)\n",
    "            \n",
    "        \n",
    "        return log_pdf(obs, self.ou.trj[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8138ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score:\n",
    "    def __init__(self, ou):\n",
    "        self.ou = ou\n",
    "        \n",
    "    def compute_score(self):\n",
    "        \"\"\"\n",
    "            Compute the value of the score function at given parameters\n",
    "            return a dictionary matching each parameter to its gradient\n",
    "        \"\"\"\n",
    "        alpha, beta = Variable(torch.tensor([self.ou.alpha, self.ou.beta]), requires_grad=True)\n",
    "        dt = self.ou.dt\n",
    "        X = self.ou.trj\n",
    "        \n",
    "        def compute_transition(X, dt, alpha, beta, sigma):\n",
    "            \"\"\"\n",
    "            Compute the transition density of the (simulated) path\n",
    "            \"\"\"\n",
    "            term1 = -1/2 * (2 * torch.log(sigma) - torch.log(beta) + torch.log(1 - torch.exp(-2 * beta * dt)))\n",
    "            term2 = -1 * beta * (X[1:] - alpha - (X[:-1] - alpha) * torch.exp(-1 * beta * dt)) ** 2 \n",
    "            term3 = (sigma ** 2) * (1 - torch.exp(-2 * beta * dt))\n",
    "\n",
    "            return torch.sum(term1 + term2/term3)\n",
    "        \n",
    "        NLL = compute_transition(X, dt, alpha, beta, torch.tensor(sigma))\n",
    "        \n",
    "        alpha.retain_grad()\n",
    "        beta.retain_grad()\n",
    "        \n",
    "        NLL.backward()\n",
    "        \n",
    "        \n",
    "#         return {'beta':beta.grad}\n",
    "        return {'beta':beta.grad, 'alpha':alpha.grad}\n",
    "#         return self.beta.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6d11b",
   "metadata": {},
   "source": [
    "Noisy Observations from the SDE:\n",
    "\n",
    "$dX_{t} = 4X_{t}(1-X_{t})dt + \\sigma dW_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time step the SDE: dot X = -mu X + sigma xi, by Euler's method.\n",
    "\n",
    "# Problem setup. \n",
    "# Set model and numerical parameters, and the initial condition.\n",
    "# These are the lines the user might want to vary.\n",
    "tf = 100\n",
    "Nsteps = 1000\n",
    "Npaths = 1\n",
    "X0 = 1\n",
    "mu = 0.75\n",
    "sigma = 0.5\n",
    "\n",
    "# Generate the time grid and solution array\n",
    "t, dt = np.linspace(0,tf,Nsteps+1,retstep=True)\n",
    "X = np.zeros((Nsteps+1,Npaths))\n",
    "root_dt = np.sqrt(dt)\n",
    "  \n",
    "# Time step starting from initial condition\n",
    "X[0,:] = X0;\n",
    "for n in range(Nsteps):\n",
    "    F_of_X = 4 * X[n,:] * (1 - X[n,:])\n",
    "    X[n+1,:] =  X[n,:] + dt * F_of_X + sigma * root_dt * np.random.randn(Npaths)\n",
    "\n",
    "# Plot paths\n",
    "plt.plot(t,X)\n",
    "plt.plot(t[::100], X[::100], \"rx\")\n",
    "plt.xlabel(\"t\", fontsize=14)\n",
    "plt.ylabel(\"X\", fontsize=14)\n",
    "plt.title(\"Sample paths\", fontsize=14)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.random.normal(loc = X[::100], scale = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47737dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t,X)\n",
    "plt.plot(t[::100], obs, \"rx\")\n",
    "plt.xlabel(\"t\", fontsize=14)\n",
    "plt.ylabel(\"X\", fontsize=14)\n",
    "plt.title(\"Noisy Observations\", fontsize=14)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0859993",
   "metadata": {},
   "source": [
    "**Variational inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eddce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_ = 1.\n",
    "beta_ = 2.\n",
    "\n",
    "N = 100\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# for i in tq.tqdm(range(300)):\n",
    "for i in range(300):\n",
    "    alpha_grad = 0.\n",
    "    beta_grad = 0.\n",
    "\n",
    "    for i in range(N):\n",
    "        vi = OU(t0 = 0., t1 = 10., z0 = obs[0][0], alpha = alpha_ , beta = beta_ , sigma = .5)\n",
    "        elbo = ELBO(vi)\n",
    "        score = Score(vi)\n",
    "        \n",
    "        scores = score.compute_score()\n",
    "        f_of_X = -1 * (elbo.log_prob(obs[1][0]) - (elbo.KL_ito() + elbo.KL_rest()))\n",
    "        assert f_of_X != np.nan, \"shit\"\n",
    "\n",
    "        alpha_grad += f_of_X * scores['alpha']\n",
    "        beta_grad += f_of_X * scores['beta']\n",
    "        \n",
    "    alpha_ -= learning_rate * alpha_grad/N\n",
    "    beta_ -= learning_rate * beta_grad/N\n",
    "    \n",
    "    print(\"alpha = \", alpha_, \"beta = \", beta_)\n",
    "# score.compute_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_of_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    posterior = OU(t0 = 0., t1 = 1., z0 = obs[0][0], alpha = alpha_ , beta = beta_ , sigma = .5)\n",
    "    plt.plot(posterior.pts, posterior.trj, 'b')\n",
    "    plt.plot(obs, 'rx')\n",
    "plt.plot(t,X, 'grey', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    posterior = OU(t0 = 0., t1 = 1., z0 = obs[0][0], alpha = alpha_, beta = -0.2, sigma = .5)\n",
    "    plt.plot(posterior.pts, posterior.trj, 'b')\n",
    "    plt.plot(obs[:2], 'rx')\n",
    "plt.plot(t[:100],X[:100], 'grey', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9911da",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_, beta_, obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations at t1 vs posterior mean at t1\n",
    "obs[1], alpha_ + (torch.from_numpy(obs[0]) - alpha_)*torch.exp(-1 * beta_ * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbe78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_moment(init, alpha, beta):\n",
    "    pts = np.linspace(0,1,100)\n",
    "    dt = pts[1:] - pts[:-1]\n",
    "    \n",
    "    mean = [init]\n",
    "        \n",
    "    for i in range(dt.shape[0]):\n",
    "        mean.append(alpha + (mean[i] - alpha)*np.exp(-1 * beta * dt[i]))\n",
    "    \n",
    "    func = lambda t: np.sqrt((alpha ** 2 / (2*beta)) * (1 - np.exp(-2 * beta * t)))\n",
    "    sd = list(map(func, dt))\n",
    "    \n",
    "    return np.array(mean), np.array(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45dc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmean, psd = posterior_moment(obs[0][0], alpha_.data.numpy(), beta_.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t[:100], X[:100])\n",
    "plt.plot(t[:100], pmean)\n",
    "# plt.fill_between(t[1:100], pmean[1:] - psd, pmean[1:] + psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ace7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t[:100], pmean)\n",
    "plt.plot(obs[:2], 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2fa73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
